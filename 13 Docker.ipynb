{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5052f859-6d31-4e2e-8f97-99d3cd301236",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **1.1 – Perché Docker è cruciale nel mondo AI: ambienti riproducibili e isolati**\n",
    "\n",
    "---\n",
    "\n",
    "## **Contesto**\n",
    "\n",
    "Nel mondo dell’AI engineering, il codice raramente vive da solo.\n",
    "Un singolo progetto può includere:\n",
    "\n",
    "* una **CrewAI Flow pipeline** composta da più agenti;\n",
    "* una **base di conoscenza indicizzata** su Qdrant o FAISS;\n",
    "* una **UI Streamlit** o FastAPI per interazione utente;\n",
    "* un **database PostgreSQL** per log, tracciamento e valutazione;\n",
    "* librerie Python ad alta complessità (Torch, Transformers, OpenAI, LangChain, ecc.);\n",
    "* e talvolta anche **accelerazione GPU**.\n",
    "\n",
    "In questo ecosistema complesso, anche un piccolo cambiamento nella versione di Python, Torch o CUDA può **rompere la compatibilità** dell’intero progetto.\n",
    "È qui che entra in gioco Docker.\n",
    "\n",
    "---\n",
    "\n",
    "## **Concetto chiave: riproducibilità e isolamento**\n",
    "\n",
    "### 1. **Riproducibilità**\n",
    "\n",
    "Docker permette di impacchettare tutto ciò che serve per far girare un’applicazione — **codice, dipendenze, librerie, variabili d’ambiente, sistema operativo** — in un’immagine immutabile.\n",
    "Chiunque esegua quell’immagine, su qualunque macchina, ottiene **esattamente lo stesso comportamento**.\n",
    "\n",
    "> **Esempio pratico**\n",
    "> Un flow CrewAI funziona sulla tua macchina, ma non sul server remoto perché il server usa Python 3.10 mentre tu hai 3.11.\n",
    "> Con Docker, entrambi eseguite **la stessa immagine**, basata sullo stesso ambiente (`FROM python:3.11-slim`), e il comportamento sarà identico.\n",
    "\n",
    "### 2. **Isolamento**\n",
    "\n",
    "Ogni container Docker è **un ambiente isolato** dal sistema operativo host e dagli altri container:\n",
    "\n",
    "* Non condivide processi, pacchetti o variabili d’ambiente.\n",
    "* Può avere una rete privata e filesystem dedicato.\n",
    "* Se un container va in crash o consuma troppa RAM, **non impatta gli altri**.\n",
    "\n",
    "Questo isolamento è cruciale in sistemi AI con **più microservizi**:\n",
    "\n",
    "* il backend CrewAI non interferisce con Qdrant,\n",
    "* Qdrant non influisce sul database PostgreSQL,\n",
    "* e ogni parte può essere aggiornata o riavviata indipendentemente.\n",
    "\n",
    "---\n",
    "\n",
    "## **Perché è cruciale per l’AI moderna**\n",
    "\n",
    "### 1. **Gestione delle dipendenze**\n",
    "\n",
    "Progetti AI usano spesso librerie non allineate tra loro:\n",
    "\n",
    "* `torch==2.3.0` richiede una versione specifica di CUDA,\n",
    "* `transformers==4.44` può rompere LangChain se non aggiornato,\n",
    "* `qdrant-client` ha binding Rust/Python sensibili alla versione.\n",
    "\n",
    "Con Docker puoi bloccare **esattamente le versioni** nel Dockerfile, garantendo che il progetto sia stabile nel tempo.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Reproducible Research e MLOps**\n",
    "\n",
    "In MLOps e AI engineering, la **riproducibilità degli esperimenti** è un requisito critico.\n",
    "Con Docker puoi:\n",
    "\n",
    "* rieseguire esattamente una pipeline anche mesi dopo;\n",
    "* distribuire lo stesso ambiente a un collega o server;\n",
    "* garantire che l’esperimento su cui è stato addestrato un modello sia documentato e verificabile.\n",
    "\n",
    "Molte aziende e laboratori (OpenAI, Hugging Face, Meta AI) **versionano i propri ambienti Docker** insieme al codice.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Distribuzione e scalabilità**\n",
    "\n",
    "Un container è un’unità standard, facilmente distribuibile:\n",
    "\n",
    "* Puoi spostarlo da un laptop a un server cloud o a un cluster Kubernetes;\n",
    "* Puoi scalare lo stesso container su più nodi senza riconfigurare nulla;\n",
    "* Ogni microservizio CrewAI (rag, retriever, evaluator, frontend) può essere un container separato.\n",
    "\n",
    "Esempio tipico di stack AI containerizzato:\n",
    "\n",
    "```\n",
    "crew-backend     -> container FastAPI con CrewAI\n",
    "qdrant-db        -> container Qdrant ufficiale\n",
    "postgres-logs    -> container PostgreSQL\n",
    "streamlit-ui     -> container Streamlit con API utente\n",
    "```\n",
    "\n",
    "Con un solo comando:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "tutto l’ambiente prende vita, identico su ogni macchina.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Isolamento GPU e AI workloads**\n",
    "\n",
    "Docker supporta nativamente l’accesso alle GPU tramite:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all\n",
    "```\n",
    "\n",
    "o, in Compose:\n",
    "\n",
    "```yaml\n",
    "deploy:\n",
    "  resources:\n",
    "    reservations:\n",
    "      devices:\n",
    "        - capabilities: [gpu]\n",
    "```\n",
    "\n",
    "Questo permette di:\n",
    "\n",
    "* eseguire modelli AI pesanti in container,\n",
    "* isolare il carico GPU da altri processi,\n",
    "* e distribuire workload AI in cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## **Analogia concettuale**\n",
    "\n",
    "> Pensa a Docker come a un “**laboratorio virtuale sigillato**”.\n",
    "> Dentro ci sono le tue provette (codice, librerie, modelli), il tuo microscopio (framework AI), e perfino il manuale d’uso (Dockerfile).\n",
    "> Nessuno può sporcare il tuo ambiente e tu puoi ricrearlo all’infinito.\n",
    "\n",
    "---\n",
    "\n",
    "## **Esercizio pratico (10 minuti)**\n",
    "\n",
    "1. Lancia un container Python:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it python:3.11 bash\n",
    "   ```\n",
    "2. Installa alcune librerie:\n",
    "\n",
    "   ```bash\n",
    "   pip install crewai qdrant-client\n",
    "   ```\n",
    "3. Esci e rilancia il container: scopri che le librerie **non persistono**.\n",
    "   → Capirai che ogni container è **ephemeral** e **isolato**.\n",
    "4. Rilancia con volume montato:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it -v $(pwd)/app:/app python:3.11 bash\n",
    "   ```\n",
    "\n",
    "   Ora tutto ciò che salvi in `/app` persiste localmente.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d1b00-113e-4c93-a97c-8d26d5aaf7f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.2 – Differenze tra venv, Conda, VM e container**\n",
    "\n",
    "Nel mondo dell’AI engineering esistono diversi modi per isolare un ambiente di sviluppo o di esecuzione. Prima di capire a fondo Docker, è fondamentale distinguere tra **ambienti virtuali (venv, Conda)** e **macchine virtuali (VM)**, così da comprendere dove si colloca la containerizzazione.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Virtualenv e venv**\n",
    "\n",
    "Gli ambienti virtuali in Python (creati con `venv` o `virtualenv`) sono **isolatori di pacchetti**: permettono di avere versioni di librerie diverse da quelle del sistema operativo, ma non isolano il sistema vero e proprio.\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install crewai qdrant-client\n",
    "```\n",
    "\n",
    "In questo caso:\n",
    "\n",
    "* L’ambiente virtuale **usa sempre lo stesso Python** dell’host;\n",
    "* Tutto gira **sullo stesso sistema operativo**;\n",
    "* Non puoi controllare la versione di OS, CUDA o driver GPU;\n",
    "* Se aggiorni globalmente una libreria come `torch`, potresti rompere un altro progetto.\n",
    "\n",
    "È utile per **sviluppo locale**, ma non garantisce **riproducibilità perfetta**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Conda environment**\n",
    "\n",
    "Conda è uno strumento più avanzato, molto diffuso in ambito data science.\n",
    "Può gestire non solo librerie Python, ma anche **pacchetti di sistema** (come `ffmpeg`, `libtorch`, `cuda`).\n",
    "\n",
    "```bash\n",
    "conda create -n crewai python=3.11\n",
    "conda activate crewai\n",
    "conda install pytorch cudatoolkit=12.1 -c pytorch\n",
    "```\n",
    "\n",
    "Conda risolve molti problemi di compatibilità, ma:\n",
    "\n",
    "* Gli ambienti restano **legati al sistema operativo**;\n",
    "* Non è portabile tra sistemi (un env Linux non gira su Windows);\n",
    "* Le versioni dei driver e delle librerie native (CUDA, cuDNN, Rust) restano dipendenti dall’host.\n",
    "\n",
    "In altre parole, **Conda isola le librerie, non il sistema**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Virtual Machines (VM)**\n",
    "\n",
    "Le macchine virtuali (VM) isolano tutto: sistema operativo, kernel, driver, file system.\n",
    "Ogni VM è un computer completo, con un suo OS e risorse dedicate (CPU, RAM, disco).\n",
    "\n",
    "Vantaggi:\n",
    "\n",
    "* Isolamento totale.\n",
    "* Puoi avere sistemi operativi diversi sull’host (es. Linux su Windows).\n",
    "\n",
    "Svantaggi:\n",
    "\n",
    "* Ogni VM pesa **diversi GB**;\n",
    "* L’avvio è lento;\n",
    "* Consuma molta memoria e CPU;\n",
    "* Duplicare o aggiornare ambienti è costoso.\n",
    "\n",
    "Per esempio, se un progetto CrewAI richiede 4 microservizi in VM, ognuno con un OS Linux, avresti 4 sistemi completi da mantenere, aggiornare e gestire: un incubo in produzione.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Docker container**\n",
    "\n",
    "Docker rappresenta un **punto di equilibrio perfetto** tra i due mondi:\n",
    "\n",
    "* Leggero come un ambiente virtuale;\n",
    "* Isolato come una macchina virtuale.\n",
    "\n",
    "I container non contengono un sistema operativo completo: condividono il **kernel dell’host**, ma mantengono filesystem, processi e librerie isolati.\n",
    "Questo riduce drasticamente i tempi di avvio e il consumo di risorse.\n",
    "\n",
    "### Esempio:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11-slim bash\n",
    "```\n",
    "\n",
    "Questo comando:\n",
    "\n",
    "* Scarica un’immagine contenente Linux minimale + Python 3.11;\n",
    "* Avvia un container isolato;\n",
    "* In meno di 1 secondo sei dentro un sistema pulito.\n",
    "\n",
    "Puoi poi installare CrewAI, Qdrant, LangChain o Streamlit senza toccare il tuo sistema locale.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Differenze riassuntive**\n",
    "\n",
    "| Caratteristica         | venv / virtualenv | Conda         | Virtual Machine           | Docker Container             |\n",
    "| ---------------------- | ----------------- | ------------- | ------------------------- | ---------------------------- |\n",
    "| Isolamento OS          | ❌                 | ❌             | ✅                         | ✅ (parziale, condiviso)      |\n",
    "| Peso                   | 🔹 Leggero        | 🔹 Medio      | ⚫ Pesante                 | 🔹 Leggero                   |\n",
    "| Avvio                  | Immediato         | Immediato     | Lento (minuti)            | Istantaneo                   |\n",
    "| Portabilità            | ❌                 | ❌             | ✅ (con immagine)          | ✅                            |\n",
    "| GPU accesso diretto    | ✅ (locale)        | ✅             | ⚠️ complesso              | ✅ (via driver NVIDIA/ROCm)   |\n",
    "| Riproducibilità totale | ❌                 | ⚠️ Parziale   | ✅                         | ✅                            |\n",
    "| Uso ideale             | Dev locale        | ML lab locale | Sistemi legacy o completi | Produzione AI e microservizi |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Esempio pratico**\n",
    "\n",
    "Immagina di dover distribuire un sistema AI composto da:\n",
    "\n",
    "* `CrewAI` backend per l’orchestrazione,\n",
    "* `Qdrant` per la ricerca vettoriale,\n",
    "* `Streamlit` come interfaccia utente.\n",
    "\n",
    "### Con venv:\n",
    "\n",
    "Ogni sviluppatore deve installare manualmente Python, CrewAI, Qdrant, Streamlit, configurare le porte e i database — altissimo rischio di errore.\n",
    "\n",
    "### Con Docker:\n",
    "\n",
    "Basta clonare il progetto e lanciare:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "Tutto si avvia in container separati, già configurati.\n",
    "L’ambiente sarà identico per ogni persona e ogni server.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Analogia semplice**\n",
    "\n",
    "* **venv**: come usare scatole per tenere separati gli oggetti sulla stessa scrivania.\n",
    "* **VM**: come avere scrivanie diverse in stanze diverse.\n",
    "* **Docker**: come avere scatole sigillate identiche, che puoi spostare ovunque e aprire ovunque, già pronte all’uso.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550baa4-7aa9-435e-8620-6d0c6f59332a",
   "metadata": {},
   "source": [
    "\n",
    "# **1.3 – Architettura Docker: client, daemon, immagini, container e registry**\n",
    "\n",
    "Per comprendere davvero Docker — e non solo “usarlo” — bisogna capirne la **struttura interna**: come comunica, chi fa cosa e dove avviene l’esecuzione reale dei container.\n",
    "Molti sviluppatori usano Docker per anni senza conoscere la differenza tra *client* e *daemon*: questo punto serve a eliminare quella confusione, così da lavorare in modo consapevole e sicuro.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. L’architettura generale**\n",
    "\n",
    "Docker è composto da **quattro elementi principali**:\n",
    "\n",
    "1. **Docker Client** → l’interfaccia con cui tu interagisci.\n",
    "2. **Docker Daemon (dockerd)** → il motore che esegue davvero i container.\n",
    "3. **Docker Images** → i “modelli” o blueprint dei container.\n",
    "4. **Docker Containers** → le istanze in esecuzione delle immagini.\n",
    "5. **Docker Registry** → il magazzino remoto dove le immagini vengono salvate e condivise.\n",
    "\n",
    "Tutti questi componenti lavorano insieme come un sistema client-server.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Il Client**\n",
    "\n",
    "Il **client** è tutto ciò che usi per comunicare con Docker:\n",
    "\n",
    "* il comando `docker` nel terminale,\n",
    "* o l’interfaccia grafica Docker Desktop.\n",
    "\n",
    "Quando scrivi:\n",
    "\n",
    "```bash\n",
    "docker run python:3.11\n",
    "```\n",
    "\n",
    "il client **non esegue direttamente** il container.\n",
    "In realtà, invia una richiesta API al Daemon Docker in background (dockerd), che è il vero motore.\n",
    "\n",
    "Docker Client può anche collegarsi a un daemon remoto, ad esempio su un server cloud:\n",
    "\n",
    "```bash\n",
    "export DOCKER_HOST=ssh://user@server\n",
    "```\n",
    "\n",
    "In questo modo, puoi controllare container su un’altra macchina come se fossero locali.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Il Daemon (dockerd)**\n",
    "\n",
    "Il **Docker Daemon** è il processo che:\n",
    "\n",
    "* riceve comandi dal client,\n",
    "* scarica immagini,\n",
    "* crea, avvia e ferma container,\n",
    "* gestisce volumi, reti e log.\n",
    "\n",
    "È lui a parlare con il kernel del sistema operativo per impostare **namespaces**, **cgroups**, e filesystem copy-on-write.\n",
    "\n",
    "In pratica, è il “cuore” del sistema Docker.\n",
    "\n",
    "Su Linux gira come processo di sistema, su macOS e Windows è incapsulato all’interno di una VM leggera (perché Docker richiede kernel Linux).\n",
    "\n",
    "---\n",
    "\n",
    "### Esempio di flusso reale:\n",
    "\n",
    "Quando esegui:\n",
    "\n",
    "```bash\n",
    "docker run -d -p 8000:8000 --name crew_backend crewai:latest\n",
    "```\n",
    "\n",
    "accade in realtà questo:\n",
    "\n",
    "1. Il client Docker invia la richiesta al daemon (`dockerd`).\n",
    "2. Il daemon controlla se l’immagine `crewai:latest` esiste localmente.\n",
    "\n",
    "   * Se no, la scarica dal registry.\n",
    "3. Crea un container a partire dall’immagine.\n",
    "4. Isola il processo, assegna rete, volumi e risorse.\n",
    "5. Avvia il container e monitora il suo stato.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Le Immagini**\n",
    "\n",
    "Un’immagine è un **pacchetto immutabile** che contiene:\n",
    "\n",
    "* un sistema operativo minimale (es. Debian Slim),\n",
    "* tutte le dipendenze necessarie,\n",
    "* e il tuo codice (CrewAI, Qdrant, Streamlit, ecc.).\n",
    "\n",
    "Ogni immagine è composta da **layer**, ognuno dei quali rappresenta una modifica:\n",
    "\n",
    "* layer di base (es. Python),\n",
    "* layer con le librerie installate,\n",
    "* layer con il codice dell’applicazione.\n",
    "\n",
    "Esempio di Dockerfile semplificato:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Quando la build parte, ogni comando crea un layer.\n",
    "Docker li **mette in cache**, quindi se non modifichi `requirements.txt`, non ricostruisce tutto da zero.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. I Container**\n",
    "\n",
    "Il **container** è l’istanza in esecuzione di un’immagine.\n",
    "È un processo isolato, con il suo filesystem, rete e risorse dedicate.\n",
    "\n",
    "Concettualmente:\n",
    "\n",
    "* un’immagine è come una **classe** in programmazione;\n",
    "* un container è **un oggetto** istanziato da quella classe.\n",
    "\n",
    "Puoi avere più container dalla stessa immagine:\n",
    "\n",
    "```bash\n",
    "docker run -d --name crewai1 crewai:latest\n",
    "docker run -d --name crewai2 crewai:latest\n",
    "```\n",
    "\n",
    "Entrambi eseguono lo stesso codice, ma in ambienti separati.\n",
    "\n",
    "I container sono **ephemeral**: se li elimini (`docker rm`), spariscono, ma puoi sempre ricrearli dalla stessa immagine.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Il Registry**\n",
    "\n",
    "Il **registry** è un archivio remoto per immagini Docker.\n",
    "I più noti sono:\n",
    "\n",
    "* **Docker Hub** (pubblico),\n",
    "* **GitHub Container Registry (GHCR)**,\n",
    "* **GitLab Container Registry**,\n",
    "* o registry privati aziendali (es. AWS ECR, Azure Container Registry).\n",
    "\n",
    "Il registry è per le immagini ciò che GitHub è per il codice:\n",
    "ti permette di **versionare**, **condividere** e **distribuire** in modo centralizzato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker build -t myorg/crewai-backend:1.0 .\n",
    "docker push myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "Ora chiunque, da un’altra macchina, può eseguire:\n",
    "\n",
    "```bash\n",
    "docker run myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "e avrà esattamente il tuo ambiente.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Schema riassuntivo**\n",
    "\n",
    "```\n",
    "┌────────────────────────────┐\n",
    "│        Docker Client       │\n",
    "│ (CLI / Docker Desktop UI)  │\n",
    "└────────────┬───────────────┘\n",
    "             │ API REST\n",
    "┌────────────▼───────────────┐\n",
    "│       Docker Daemon        │\n",
    "│     (dockerd in Linux)     │\n",
    "│  ┌───────────────┬────────┐│\n",
    "│  │   Images      │   Vol. ││\n",
    "│  │   Containers  │   Net. ││\n",
    "│  └───────────────┴────────┘│\n",
    "└────────────┬────────────────\n",
    "             │ Pull / Push\n",
    "┌────────────▼───────────────┐\n",
    "│       Docker Registry      │\n",
    "│ (Docker Hub / GHCR / ECR)  │\n",
    "└────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Come si lega all’AI engineering**\n",
    "\n",
    "Capire l’architettura Docker serve anche a **diagnosticare errori frequenti** in ambienti AI:\n",
    "\n",
    "* Se un container non parte, non è “Docker rotto”: è il daemon che non riceve o non riesegue il processo.\n",
    "* Se un’immagine non viene trovata, il problema è nel registry o nei permessi di push/pull.\n",
    "* Se un volume non si monta, è la gestione del layer filesystem del daemon.\n",
    "\n",
    "In pipeline AI con CrewAI, Qdrant e Streamlit, tutto ruota intorno a questo flusso:\n",
    "\n",
    "* il **client** (Compose o CLI) invia la configurazione;\n",
    "* il **daemon** crea i servizi come container isolati;\n",
    "* le **immagini** rappresentano ogni microservizio AI;\n",
    "* i **registry** custodiscono le versioni deployabili.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizio pratico (15 minuti)**\n",
    "\n",
    "1. Esegui:\n",
    "\n",
    "   ```bash\n",
    "   docker run hello-world\n",
    "   ```\n",
    "\n",
    "   Poi verifica cosa accade nel daemon con:\n",
    "\n",
    "   ```bash\n",
    "   docker ps -a\n",
    "   docker images\n",
    "   docker info\n",
    "   ```\n",
    "2. Scarica manualmente un’immagine:\n",
    "\n",
    "   ```bash\n",
    "   docker pull python:3.11-slim\n",
    "   ```\n",
    "\n",
    "   e osserva i layer scaricati.\n",
    "3. Ispeziona l’immagine:\n",
    "\n",
    "   ```bash\n",
    "   docker inspect python:3.11-slim\n",
    "   ```\n",
    "\n",
    "Capirai come **client**, **daemon** e **registry** interagiscono nel mondo reale.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd26bc2-61db-4ad0-921f-c4dc480924b1",
   "metadata": {},
   "source": [
    "\n",
    "# **1.4 – Come Docker gestisce librerie pesanti (Torch, CUDA, ROCm, Transformers)**\n",
    "\n",
    "Quando si containerizza un’applicazione AI, non si parla più solo di Python e dipendenze leggere.\n",
    "L’ambiente deve spesso includere:\n",
    "\n",
    "* **PyTorch** o **TensorFlow**, librerie enormi con binding nativi in C++ o CUDA;\n",
    "* **CUDA Toolkit** o **ROCm**, per l’accelerazione su GPU NVIDIA o AMD;\n",
    "* **Transformers** e modelli LLM, spesso di diversi GB di peso.\n",
    "\n",
    "Docker può gestire tutto questo in modo efficiente, ma serve capire come funziona “sotto il cofano”.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Docker e le librerie native**\n",
    "\n",
    "Una libreria come `torch` non è solo Python puro: include componenti compilati in C/C++ e spesso richiede l’accesso diretto a driver e device hardware.\n",
    "\n",
    "Nel sistema host, queste librerie vengono installate con il supporto nativo del sistema operativo (es. `/usr/lib/cuda`).\n",
    "Nel container, invece, **non esiste nulla di preinstallato**: devi fornire tu l’ambiente completo.\n",
    "\n",
    "Docker lo risolve in due modi:\n",
    "\n",
    "1. usando **immagini base specifiche per GPU**, già predisposte da NVIDIA o AMD;\n",
    "2. esponendo i **driver GPU dell’host** al container tramite un layer d’integrazione (NVIDIA Container Toolkit o ROCm runtime).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Immagini base NVIDIA e CUDA**\n",
    "\n",
    "NVIDIA mantiene immagini ufficiali con CUDA e PyTorch preconfigurati, ad esempio:\n",
    "\n",
    "* `nvidia/cuda`\n",
    "* `pytorch/pytorch`\n",
    "* `tensorflow/tensorflow`\n",
    "\n",
    "Queste immagini contengono:\n",
    "\n",
    "* il sistema operativo base (Ubuntu o Debian),\n",
    "* CUDA Toolkit (compilatori, librerie, runtime),\n",
    "* i driver utente per l’accelerazione GPU,\n",
    "* e a volte anche PyTorch preinstallato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Quando esegui il container, puoi dare accesso alla GPU dell’host:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all my-ai-container\n",
    "```\n",
    "\n",
    "Il container non ha bisogno di driver NVIDIA interni: utilizza quelli **già presenti sull’host**, esposti attraverso il toolkit.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. NVIDIA Container Toolkit**\n",
    "\n",
    "Il **NVIDIA Container Toolkit** è ciò che permette a Docker di parlare con la GPU.\n",
    "Funziona come un ponte tra il sistema host e il container.\n",
    "\n",
    "Installazione (Linux):\n",
    "\n",
    "```bash\n",
    "sudo apt install -y nvidia-container-toolkit\n",
    "sudo systemctl restart docker\n",
    "```\n",
    "\n",
    "Dopo questa configurazione, puoi:\n",
    "\n",
    "* lanciare container con GPU accessibile (`--gpus all`);\n",
    "* monitorare la GPU dal container (`nvidia-smi`);\n",
    "* eseguire modelli Torch e TensorFlow accelerati.\n",
    "\n",
    "Senza questo toolkit, Docker non può accedere alle GPU dell’host, perché il kernel non “vede” i device.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. ROCm e GPU AMD**\n",
    "\n",
    "Per GPU AMD, il meccanismo è simile ma basato su **ROCm** (Radeon Open Compute).\n",
    "AMD fornisce immagini ufficiali con supporto ROCm preinstallato, ad esempio:\n",
    "\n",
    "* `rocm/pytorch`\n",
    "* `rocm/tensorflow`\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM rocm/pytorch:latest\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "CMD [\"python\", \"train.py\"]\n",
    "```\n",
    "\n",
    "L’host deve avere i driver ROCm installati e accessibili.\n",
    "Docker non gestisce direttamente la GPU AMD: la espone come device `/dev/kfd` o `/dev/dri`, e il container la utilizza tramite i runtime ROCm interni.\n",
    "\n",
    "Avvio:\n",
    "\n",
    "```bash\n",
    "docker run --device=/dev/kfd --device=/dev/dri my-rocm-container\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Transformers e modelli di grandi dimensioni**\n",
    "\n",
    "Le librerie **Transformers** e **Diffusers** di Hugging Face portano un’altra sfida: i modelli sono enormi (GB di pesi binari), spesso scaricati da remoto.\n",
    "\n",
    "Best practice:\n",
    "\n",
    "* monta una **cache condivisa** per i modelli, per non riscaricarli a ogni build;\n",
    "* non includere i pesi dentro l’immagine Docker;\n",
    "* usa un volume dedicato o un percorso esterno.\n",
    "\n",
    "Esempio in Compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  crewai:\n",
    "    build: .\n",
    "    volumes:\n",
    "      - ./models:/root/.cache/huggingface\n",
    "```\n",
    "\n",
    "In questo modo:\n",
    "\n",
    "* i modelli restano persistenti anche se ricrei il container;\n",
    "* più container possono condividere la stessa cache.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Dimensioni delle immagini e ottimizzazione**\n",
    "\n",
    "Quando si aggiungono PyTorch, CUDA e Transformers, le immagini possono facilmente superare i **5–10 GB**.\n",
    "Per ottimizzarle:\n",
    "\n",
    "1. **Usa multi-stage build**\n",
    "\n",
    "   * Compila o installa solo ciò che serve in un primo stage.\n",
    "   * Copia solo i binari finali nello stage runtime.\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel as build\n",
    "   RUN pip install crewai qdrant-client\n",
    "\n",
    "   FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "   COPY --from=build /opt/conda /opt/conda\n",
    "   CMD [\"python\", \"main.py\"]\n",
    "   ```\n",
    "\n",
    "2. **Evita apt inutili**\n",
    "\n",
    "   * Ogni `RUN apt-get install` crea un layer.\n",
    "   * Pulisci la cache (`rm -rf /var/lib/apt/lists/*`).\n",
    "\n",
    "3. **Usa immagini “slim” o “runtime”**\n",
    "\n",
    "   * Le immagini `-devel` contengono compilatori e header (necessari solo in build).\n",
    "   * In produzione basta `-runtime`.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Testare GPU e librerie in container**\n",
    "\n",
    "Per verificare che Docker stia usando correttamente la GPU:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all --rm pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime nvidia-smi\n",
    "```\n",
    "\n",
    "Output atteso:\n",
    "\n",
    "```\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.40       Driver Version: 550.40       CUDA Version: 12.1     |\n",
    "| GPU Name: RTX 4090      Memory Usage: 2345MiB / 24576MiB                    |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "Poi, per testare Torch:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "→ `True`\n",
    "\n",
    "Questo conferma che il container accede ai driver GPU host e può eseguire modelli accelerati.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Integrazione con CrewAI e Qdrant**\n",
    "\n",
    "Quando costruisci pipeline reali con **CrewAI**, **Qdrant** e **LLM**, separa sempre i componenti:\n",
    "\n",
    "* il container “AI compute” (PyTorch, Transformers, CUDA/ROCm);\n",
    "* il container “vector DB” (Qdrant o Milvus);\n",
    "* e il container “interface” (Streamlit o FastAPI).\n",
    "\n",
    "Questo approccio:\n",
    "\n",
    "* evita conflitti tra librerie native (Torch, Rust, SQLite, ecc.),\n",
    "* riduce le dimensioni di ciascun container,\n",
    "* permette di scalare indipendentemente il componente AI compute.\n",
    "\n",
    "Esempio di Compose parziale:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  ai-compute:\n",
    "    build: ./ai\n",
    "    deploy:\n",
    "      resources:\n",
    "        reservations:\n",
    "          devices:\n",
    "            - capabilities: [gpu]\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "  streamlit:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Riepilogo concettuale**\n",
    "\n",
    "| Elemento                                    | Ruolo in Docker                                          | Note                                                     |\n",
    "| ------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n",
    "| **PyTorch / TensorFlow**                    | Librerie Python con binding C/CUDA                       | Devono essere installate su immagini compatibili con GPU |\n",
    "| **CUDA / ROCm**                             | Layer di accesso GPU                                     | Esposto dal sistema host, non incluso nei container      |\n",
    "| **Transformers / Diffusers**                | Framework LLM e modelli                                  | Gestire cache e volumi condivisi                         |\n",
    "| **NVIDIA Container Toolkit / ROCm runtime** | Ponte hardware → container                               | Necessario per esporre device GPU                        |\n",
    "| **Best practice**                           | Usa immagini preconfigurate, multi-stage e cache modelli | Evita build pesanti e duplicazione di dati               |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dab0bb-b62c-40bb-b5af-7a9c6fd12f54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.5 – Setup ambiente (Windows): installazione Docker Desktop e configurazione GPU (NVIDIA o ROCm)**\n",
    "\n",
    "Su Windows, Docker non viene eseguito nativamente: lavora all’interno di una macchina virtuale Linux gestita dal **motore WSL 2 (Windows Subsystem for Linux)**.\n",
    "Questo è il componente che permette a Docker di avere un vero kernel Linux e quindi di eseguire correttamente container basati su immagini come `python:3.11-slim`, `pytorch/pytorch`, o `qdrant/qdrant`.\n",
    "\n",
    "L’obiettivo di questo setup è garantire:\n",
    "\n",
    "* un’installazione pulita e stabile di Docker Desktop;\n",
    "* l’attivazione di **WSL 2** e del **kernel Linux**;\n",
    "* il corretto **accesso alla GPU** (NVIDIA o AMD) da parte dei container;\n",
    "* la possibilità di eseguire stack AI completi (CrewAI + Qdrant + Streamlit) con accelerazione hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Prerequisiti di sistema**\n",
    "\n",
    "### Requisiti minimi\n",
    "\n",
    "* **Windows 10** (versione 2004 o superiore) oppure **Windows 11**\n",
    "* **64 bit**\n",
    "* **CPU con virtualizzazione hardware abilitata** (Intel VT-x o AMD-V)\n",
    "* Almeno **8 GB di RAM** (consigliati 16 GB per AI)\n",
    "* Connessione Internet per scaricare immagini e tool\n",
    "\n",
    "### Requisiti GPU\n",
    "\n",
    "* **Per NVIDIA:** driver 470+ e toolkit CUDA 11 o superiore\n",
    "* **Per AMD:** driver ROCm 6.0+ con supporto a HIP (solo Windows 11 attualmente sperimentale)\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Installazione di WSL 2**\n",
    "\n",
    "WSL 2 è il motore Linux su cui Docker Desktop si appoggia.\n",
    "Per installarlo:\n",
    "\n",
    "Apri **PowerShell come Amministratore** e digita:\n",
    "\n",
    "```bash\n",
    "wsl --install\n",
    "```\n",
    "\n",
    "Questo comando:\n",
    "\n",
    "* attiva i componenti “Piattaforma macchina virtuale” e “Sottosistema Windows per Linux”;\n",
    "* installa automaticamente Ubuntu come distribuzione predefinita;\n",
    "* abilita il kernel Linux.\n",
    "\n",
    "Dopo il riavvio, verifica che tutto sia attivo:\n",
    "\n",
    "```bash\n",
    "wsl -l -v\n",
    "```\n",
    "\n",
    "Dovresti vedere un output simile a:\n",
    "\n",
    "```\n",
    "  NAME      STATE           VERSION\n",
    "* Ubuntu    Running         2\n",
    "```\n",
    "\n",
    "Se `VERSION` è 1, aggiorna con:\n",
    "\n",
    "```bash\n",
    "wsl --set-version Ubuntu 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Installazione di Docker Desktop**\n",
    "\n",
    "1. Vai al sito ufficiale:\n",
    "   🔗 [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)\n",
    "2. Scarica **Docker Desktop for Windows**.\n",
    "3. Durante l’installazione, **assicurati di selezionare “Use WSL 2 based engine”**.\n",
    "4. Dopo l’installazione, riavvia il sistema.\n",
    "5. Avvia Docker Desktop e apri il terminale PowerShell o Ubuntu WSL per testare:\n",
    "\n",
    "   ```bash\n",
    "   docker run hello-world\n",
    "   ```\n",
    "\n",
    "   Se il messaggio dice “Hello from Docker!”, l’installazione è riuscita.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Configurazione GPU – NVIDIA**\n",
    "\n",
    "Per usare PyTorch o TensorFlow con accelerazione GPU all’interno di container, serve il **NVIDIA Container Toolkit**.\n",
    "\n",
    "### Passaggi\n",
    "\n",
    "1. Assicurati che i driver NVIDIA siano aggiornati:\n",
    "\n",
    "   * Apri `nvidia-smi` nel prompt.\n",
    "     Se restituisce un output valido, i driver sono attivi.\n",
    "\n",
    "2. Installa **NVIDIA Container Toolkit** (dalla WSL Ubuntu):\n",
    "\n",
    "   ```bash\n",
    "   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n",
    "   curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n",
    "   curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n",
    "     sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
    "   sudo apt-get update\n",
    "   sudo apt-get install -y nvidia-container-toolkit\n",
    "   sudo systemctl restart docker\n",
    "   ```\n",
    "\n",
    "3. Verifica:\n",
    "\n",
    "   ```bash\n",
    "   docker run --rm --gpus all nvidia/cuda:12.1-base nvidia-smi\n",
    "   ```\n",
    "\n",
    "   Se compare la tua GPU, Docker è configurato per CUDA.\n",
    "\n",
    "4. Ora puoi eseguire modelli CrewAI o Torch nel container:\n",
    "\n",
    "   ```bash\n",
    "   docker run --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "   ```\n",
    "\n",
    "   Output atteso: `True`\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Configurazione GPU – AMD (ROCm)**\n",
    "\n",
    "> ⚠️ Su Windows il supporto ROCm via Docker è ancora **sperimentale**.\n",
    "> Si consiglia di usare **Ubuntu WSL** con ROCm installato o, meglio, una macchina Linux nativa.\n",
    "\n",
    "Per sistemi che supportano ROCm (es. RX 7900 XTX, MI 210, ecc.):\n",
    "\n",
    "1. Installa driver ROCm per Windows 11:\n",
    "   🔗 [https://www.amd.com/en/developer/resources/rocm.html](https://www.amd.com/en/developer/resources/rocm.html)\n",
    "2. Installa Docker Desktop come sopra.\n",
    "3. Apri WSL Ubuntu e verifica la presenza dei device:\n",
    "\n",
    "   ```bash\n",
    "   ls /dev | grep kfd\n",
    "   ```\n",
    "4. Avvia container ROCm:\n",
    "\n",
    "   ```bash\n",
    "   docker run --device=/dev/kfd --device=/dev/dri rocm/pytorch:latest\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Test finale**\n",
    "\n",
    "Una volta completata l’installazione:\n",
    "\n",
    "```bash\n",
    "docker run hello-world\n",
    "docker run -it python:3.11-slim bash\n",
    "```\n",
    "\n",
    "Se entrambi i comandi funzionano, Docker e WSL 2 sono configurati correttamente.\n",
    "\n",
    "Per GPU:\n",
    "\n",
    "* Verifica CUDA: `docker run --gpus all nvidia/cuda:12.1-base nvidia-smi`\n",
    "* Oppure PyTorch: `docker run --gpus all pytorch/pytorch python -c \"import torch; print(torch.cuda.is_available())\"`\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Consigli pratici per progetti AI**\n",
    "\n",
    "* **Disattiva “Use Windows containers”**: assicurati che Docker Desktop usi container **Linux-based**.\n",
    "* **Assegna risorse adeguate** (Settings → Resources):\n",
    "  CPU ≥ 4 core, RAM ≥ 8 GB, GPU enabled.\n",
    "* **Condividi le directory di lavoro** (Settings → Resources → File Sharing): aggiungi la cartella del progetto.\n",
    "* **Evita di costruire immagini dentro WSL** se usi IDE Windows: costruiscile da terminale Docker Desktop o da VS Code + Docker Extension per mantenere il contesto coerente.\n",
    "* **Aggiorna WSL regolarmente**:\n",
    "\n",
    "  ```bash\n",
    "  wsl --update\n",
    "  ```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab8e22-fa05-40ee-8b5f-398616d2fd39",
   "metadata": {},
   "source": [
    "# **1.6 – Comandi base e ciclo di vita di un container**\n",
    "\n",
    "Quando esegui un container, Docker lo tratta come un **processo isolato**: può essere avviato, messo in pausa, riavviato o rimosso.\n",
    "Per gestirlo, Docker fornisce una serie di comandi CLI che ti permettono di **controllare ogni fase del suo ciclo di vita**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Concetto di ciclo di vita**\n",
    "\n",
    "Un container nasce da un’immagine ed esegue un processo principale (il *command* o *entrypoint* definito nel Dockerfile).\n",
    "Dalla creazione alla rimozione, può passare attraverso vari stati:\n",
    "\n",
    "```\n",
    "created → running → stopped → removed\n",
    "```\n",
    "\n",
    "Ogni fase è gestita da comandi specifici, che vediamo subito.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `docker ps` – Visualizzare i container attivi**\n",
    "\n",
    "Mostra la lista dei container attualmente in esecuzione.\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "```\n",
    "CONTAINER ID   IMAGE                  COMMAND                  STATUS         PORTS                  NAMES\n",
    "f2a45b8c11df   qdrant/qdrant:latest   \"/usr/bin/qdrant\"        Up 5 minutes   6333/tcp, 6334/tcp    qdrant_db\n",
    "d3a21ce6c442   crewai:latest          \"python main.py\"         Up 2 minutes   8080/tcp              crew_backend\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker ps -a` → mostra **tutti i container**, anche quelli stoppati.\n",
    "* `docker ps -q` → mostra solo gli ID (utile negli script).\n",
    "* `docker ps --filter \"status=exited\"` → filtra per stato.\n",
    "\n",
    " *Uso tipico in AI pipelines:*\n",
    "Verificare che `qdrant`, `crewai` e `streamlit` siano effettivamente attivi in uno stack multi-container.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `docker exec` – Entrare o eseguire comandi dentro un container**\n",
    "\n",
    "Permette di eseguire un comando in un container già in esecuzione, o di aprire una shell interattiva.\n",
    "\n",
    "```bash\n",
    "docker exec -it <container_name> bash\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker exec -it crew_backend bash\n",
    "```\n",
    "\n",
    "Ora sei “dentro” il container come se fosse un piccolo Linux isolato.\n",
    "Puoi navigare, leggere log, o testare Python:\n",
    "\n",
    "```bash\n",
    "python\n",
    "import crewai\n",
    "```\n",
    "\n",
    "### Varianti:\n",
    "\n",
    "* `docker exec crew_backend ls /app` → esegue un singolo comando e restituisce l’output.\n",
    "* `-i` = interattivo (input), `-t` = terminale (TTY).\n",
    "\n",
    " *Esempio pratico:*\n",
    "Se il container `crewai` non risponde, puoi entrare e controllare il file `/app/main.py` o la presenza delle chiavi `.env`.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `docker logs` – Leggere i log del container**\n",
    "\n",
    "Mostra l’output standard (`stdout` e `stderr`) del processo principale del container.\n",
    "È uno dei comandi più usati per il debugging.\n",
    "\n",
    "```bash\n",
    "docker logs crew_backend\n",
    "```\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "```\n",
    "[INFO] CrewAI server started on port 8080\n",
    "[INFO] Connected to Qdrant at qdrant_db:6333\n",
    "[WARNING] Missing OpenAI API key - using fallback model\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker logs -f crew_backend` → *follow mode*, segue in tempo reale i log (come `tail -f`).\n",
    "* `docker logs --since 10m crew_backend` → mostra solo gli ultimi 10 minuti.\n",
    "* `docker logs -n 50 crew_backend` → ultimi 50 log lines.\n",
    "\n",
    " *Uso tipico:*\n",
    "Quando un microservizio AI fallisce all’avvio, questo comando mostra errori di import, di connessione o di chiavi API mancanti.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `docker inspect` – Analizzare in profondità container o immagini**\n",
    "\n",
    "Fornisce tutte le informazioni tecniche di un container o di un’immagine in formato JSON.\n",
    "È fondamentale per capire configurazioni, reti, volumi e variabili d’ambiente.\n",
    "\n",
    "```bash\n",
    "docker inspect crew_backend\n",
    "```\n",
    "\n",
    "Output (estratto semplificato):\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"Id\": \"d3a21ce6c442...\",\n",
    "    \"State\": { \"Status\": \"running\", \"Pid\": 1342 },\n",
    "    \"Mounts\": [\n",
    "      { \"Source\": \"/home/michael/app\", \"Destination\": \"/app\" }\n",
    "    ],\n",
    "    \"NetworkSettings\": {\n",
    "      \"IPAddress\": \"172.18.0.3\",\n",
    "      \"Ports\": { \"8080/tcp\": [{ \"HostPort\": \"8080\" }] }\n",
    "    },\n",
    "    \"Config\": {\n",
    "      \"Env\": [\"OPENAI_API_KEY=sk-...\", \"MODE=production\"],\n",
    "      \"Cmd\": [\"python\", \"main.py\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker inspect --format='{{.NetworkSettings.IPAddress}}' crew_backend`\n",
    "  → mostra solo l’IP interno.\n",
    "* `docker inspect -f '{{.Config.Env}}' crew_backend`\n",
    "  → mostra le variabili d’ambiente.\n",
    "\n",
    " *Uso tipico:*\n",
    "Scoprire su quale rete interna è connesso un container CrewAI per permettere a Streamlit o Qdrant di comunicare correttamente.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Comandi complementari del ciclo di vita**\n",
    "\n",
    "### Avvio e stop container\n",
    "\n",
    "```bash\n",
    "docker start crew_backend\n",
    "docker stop crew_backend\n",
    "```\n",
    "\n",
    "### Riavvio rapido\n",
    "\n",
    "```bash\n",
    "docker restart crew_backend\n",
    "```\n",
    "\n",
    "### Creazione e rimozione\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_backend crewai:latest\n",
    "docker rm crew_backend\n",
    "```\n",
    "\n",
    " *Nota:* un container rimosso non cancella l’immagine da cui è stato creato.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Visualizzare immagini e volumi**\n",
    "\n",
    "Per vedere le immagini salvate localmente:\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "```\n",
    "\n",
    "Per vedere i volumi (dove risiedono i dati persistenti):\n",
    "\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "Esempio tipico in uno stack CrewAI:\n",
    "\n",
    "```\n",
    "REPOSITORY          TAG       SIZE\n",
    "crewai              latest    2.3GB\n",
    "qdrant/qdrant       v1.10.0   650MB\n",
    "python              3.11-slim 140MB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico (20 minuti)**\n",
    "\n",
    "1. Avvia un container Python:\n",
    "\n",
    "   ```bash\n",
    "   docker run -d --name pytest python:3.11-slim sleep 300\n",
    "   ```\n",
    "2. Verifica che sia attivo:\n",
    "\n",
    "   ```bash\n",
    "   docker ps\n",
    "   ```\n",
    "3. Entra nel container:\n",
    "\n",
    "   ```bash\n",
    "   docker exec -it pytest bash\n",
    "   ```\n",
    "4. Installa qualcosa al suo interno (es. `pip install numpy`), poi esci.\n",
    "5. Leggi i log:\n",
    "\n",
    "   ```bash\n",
    "   docker logs pytest\n",
    "   ```\n",
    "6. Ispeziona:\n",
    "\n",
    "   ```bash\n",
    "   docker inspect pytest\n",
    "   ```\n",
    "7. Ferma e rimuovi:\n",
    "\n",
    "   ```bash\n",
    "   docker stop pytest\n",
    "   docker rm pytest\n",
    "   ```\n",
    "\n",
    "Questo ciclo ti mostra come **nascita, esecuzione e distruzione** di un container avvengono in modo trasparente e controllato.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Riepilogo pratico**\n",
    "\n",
    "| Comando                | Funzione principale                  | Uso tipico               |\n",
    "| ---------------------- | ------------------------------------ | ------------------------ |\n",
    "| `docker ps`            | Elenca container attivi              | Controllo dello stato    |\n",
    "| `docker exec`          | Entra o esegue comandi nel container | Debug o test rapido      |\n",
    "| `docker logs`          | Legge i log del container            | Diagnosi di errori       |\n",
    "| `docker inspect`       | Mostra configurazione completa       | Analisi rete, env, mount |\n",
    "| `docker start/stop/rm` | Gestione ciclo di vita               | Riavvio, cleanup         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d290372-c08f-4f52-95f3-a9ec7627f53a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.7 – Gestione ambienti AI interattivi (`docker run -it python:3.11 bash`)**\n",
    "\n",
    "Molti sviluppatori AI lavorano con ambienti virtuali o notebook locali, ma questo spesso porta a conflitti tra versioni di librerie, Python o CUDA.\n",
    "Con Docker puoi creare **ambienti di sviluppo temporanei e isolati**, pronti all’uso, perfetti per testare rapidamente nuove librerie, modelli o configurazioni di CrewAI.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Concetto di ambiente interattivo**\n",
    "\n",
    "Un container Docker può essere usato in due modi:\n",
    "\n",
    "* come **servizio**, in esecuzione continua (es. un backend CrewAI, un database Qdrant);\n",
    "* oppure come **ambiente interattivo**, dove lavori dentro una shell Linux pulita, come se fosse una macchina virtuale leggera.\n",
    "\n",
    "Il comando chiave è:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11 bash\n",
    "```\n",
    "\n",
    "Vediamo cosa succede in dettaglio.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Analisi del comando**\n",
    "\n",
    "| Parte         | Significato                                                        |\n",
    "| ------------- | ------------------------------------------------------------------ |\n",
    "| `docker run`  | crea e avvia un container basato su un’immagine                    |\n",
    "| `-i`          | abilita l’input interattivo (stdin aperto)                         |\n",
    "| `-t`          | assegna un terminale TTY per interazione umana                     |\n",
    "| `python:3.11` | immagine base ufficiale di Python (Debian + Python 3.11)           |\n",
    "| `bash`        | comando da eseguire all’avvio del container (avvia una shell Bash) |\n",
    "\n",
    "Il risultato è un prompt interattivo dentro un sistema Linux minimale, con Python già installato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```\n",
    "root@0a3b82f3d87c:/# python\n",
    "Python 3.11.9 (main, May 10 2024, 10:11:00)\n",
    ">>> import sys\n",
    ">>> sys.version\n",
    "'3.11.9'\n",
    "```\n",
    "\n",
    "Ora sei **dentro un container** isolato dal tuo sistema Windows o macOS, e tutto ciò che fai (installazioni, file, modifiche) resta confinato lì dentro.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Caratteristiche di un ambiente interattivo Docker**\n",
    "\n",
    "1. **Pulito:** ogni container parte sempre dallo stesso stato iniziale.\n",
    "2. **Isolato:** non interferisce con librerie o file dell’host.\n",
    "3. **Temporaneo:** se lo chiudi senza salvare, sparisce (utile per test rapidi).\n",
    "4. **Reproducibile:** puoi ricrearlo identico in ogni momento.\n",
    "5. **Leggero:** avvio in meno di un secondo.\n",
    "\n",
    " È perfetto per testare rapidamente:\n",
    "\n",
    "* librerie nuove (`pip install crewai qdrant-client`);\n",
    "* modelli (`from transformers import pipeline`);\n",
    "* bug di compatibilità (`import torch; torch.cuda.is_available()`).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Lavorare dentro il container**\n",
    "\n",
    "Una volta dentro la shell:\n",
    "\n",
    "```bash\n",
    "root@0a3b82f3d87c:/#\n",
    "```\n",
    "\n",
    "Puoi usare comandi Linux e Python normalmente:\n",
    "\n",
    "```bash\n",
    "apt update && apt install nano -y\n",
    "pip install crewai qdrant-client langchain\n",
    "python\n",
    "```\n",
    "\n",
    "Tutto funzionerà come in un vero sistema Linux, ma:\n",
    "\n",
    "* i file restano **solo nel container**;\n",
    "* quando esci (`exit` o `Ctrl+D`), il container si ferma;\n",
    "* al riavvio sarà “vuoto” se non hai salvato nulla su un volume (vedremo tra poco come farlo).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Uscire e rientrare**\n",
    "\n",
    "Esci con:\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "Il container resta fermo ma non scompare.\n",
    "Puoi vederlo con:\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "E rientrare con:\n",
    "\n",
    "```bash\n",
    "docker start -ai <container_id>\n",
    "```\n",
    "\n",
    "oppure eliminarlo:\n",
    "\n",
    "```bash\n",
    "docker rm <container_id>\n",
    "```\n",
    "\n",
    " *Consiglio*: dai un nome ai tuoi container per non confonderli:\n",
    "\n",
    "```bash\n",
    "docker run -it --name crew_env python:3.11 bash\n",
    "```\n",
    "\n",
    "Poi puoi riprenderlo facilmente:\n",
    "\n",
    "```bash\n",
    "docker start -ai crew_env\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Montare una cartella locale (persistenza)**\n",
    "\n",
    "Per evitare che tutto vada perso alla chiusura, puoi **montare una directory dell’host** nel container:\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash   # su Windows PowerShell\n",
    "```\n",
    "\n",
    "oppure\n",
    "\n",
    "```bash\n",
    "docker run -it -v $(pwd):/app python:3.11 bash # su Linux/macOS\n",
    "```\n",
    "\n",
    "Ora la cartella corrente del tuo computer è visibile in `/app` dentro il container.\n",
    "Puoi crearci file, script o notebook:\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "nano test.py\n",
    "python test.py\n",
    "```\n",
    "\n",
    "Tutto resta salvato anche dopo l’uscita, perché i file vivono nel filesystem dell’host.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Eseguire Python direttamente**\n",
    "\n",
    "Puoi saltare la shell e avviare Python in un solo step:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11\n",
    "```\n",
    "\n",
    "oppure eseguire un comando singolo:\n",
    "\n",
    "```bash\n",
    "docker run --rm python:3.11 python -c \"print('Hello AI World')\"\n",
    "```\n",
    "\n",
    "L’opzione `--rm` elimina automaticamente il container una volta terminato.\n",
    "\n",
    " *Utile per test rapidi di librerie CrewAI, LangChain, HuggingFace o Qdrant-client senza installarle localmente.*\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Testare la GPU in un ambiente interattivo**\n",
    "\n",
    "Se hai configurato NVIDIA Container Toolkit:\n",
    "\n",
    "```bash\n",
    "docker run -it --gpus all pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime bash\n",
    "```\n",
    "\n",
    "Poi dentro:\n",
    "\n",
    "```bash\n",
    "python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "→ `True` significa che Docker sta usando la tua GPU correttamente.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Pulizia e gestione**\n",
    "\n",
    "Dopo aver terminato gli esperimenti, puoi pulire facilmente:\n",
    "\n",
    "```bash\n",
    "docker ps -a            # mostra tutti i container\n",
    "docker rm <id>          # rimuove un container\n",
    "docker images           # mostra immagini\n",
    "docker rmi python:3.11  # rimuove un’immagine se vuoi liberare spazio\n",
    "```\n",
    "\n",
    " *Docker Desktop mostra tutto anche graficamente, utile per i primi tempi.*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **11. In sintesi**\n",
    "\n",
    "| Azione                       | Comando                           |\n",
    "| ---------------------------- | --------------------------------- |\n",
    "| Avvia ambiente interattivo   | `docker run -it python:3.11 bash` |\n",
    "| Assegna un nome al container | `--name crew_env`                 |\n",
    "| Monta una directory locale   | `-v %cd%:/app`                    |\n",
    "| Riaccedi al container        | `docker start -ai crew_env`       |\n",
    "| Elimina container e immagine | `docker rm` / `docker rmi`        |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8d414-7e4a-4edb-9f43-0b208bdd5414",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **Docker – Recap dei Comandi Fondamentali**\n",
    "\n",
    "| **Comando**                                                      | **Funzione**                                              | **Esempio pratico / Descrizione**                                       |\n",
    "| ---------------------------------------------------------------- | --------------------------------------------------------- | ----------------------------------------------------------------------- |\n",
    "| `docker run <img>`                                               | Crea e avvia un container da un’immagine                  | `docker run hello-world` → esegue un test di installazione              |\n",
    "| `docker run -it <img> bash`                                      | Avvia un container **interattivo** con terminale          | `docker run -it python:3.11 bash` → entra in un ambiente Python isolato |\n",
    "| `docker run -it --name <nome>`                                   | Crea container con nome personalizzato                    | `docker run -it --name crew_env python:3.11 bash`                       |\n",
    "| `docker run --rm <img>`                                          | Esegue container temporaneo e lo elimina alla chiusura    | `docker run --rm python:3.11 python -c \"print('Hello')\"`                |\n",
    "| `docker run -v <path_host>:<path_container>`                     | Monta una cartella locale dentro il container             | `docker run -it -v %cd%:/app python:3.11 bash`                          |\n",
    "| `docker run --gpus all <img>`                                    | Espone GPU NVIDIA/AMD al container                        | `docker run --gpus all pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime`   |\n",
    "| `docker ps`                                                      | Mostra i container attivi                                 | `docker ps` → elenca solo quelli in esecuzione                          |\n",
    "| `docker ps -a`                                                   | Mostra tutti i container, inclusi quelli fermati          | Utile per controllare container creati o terminati                      |\n",
    "| `docker exec -it <container> bash`                               | Apre shell Bash dentro un container attivo                | `docker exec -it crew_backend bash`                                     |\n",
    "| `docker exec <container> <cmd>`                                  | Esegue un singolo comando dentro un container             | `docker exec crew_backend ls /app`                                      |\n",
    "| `docker logs <container>`                                        | Mostra i log standard del container                       | `docker logs -f crew_backend` → segue in tempo reale i log              |\n",
    "| `docker inspect <container>`                                     | Mostra info dettagliate (rete, mount, env, porte)         | `docker inspect qdrant_db`                                              |\n",
    "| `docker inspect -f '{{.NetworkSettings.IPAddress}}' <container>` | Estrae solo l’IP interno del container                    | utile per connessioni manuali tra servizi                               |\n",
    "| `docker images`                                                  | Elenca tutte le immagini salvate localmente               | Mostra repository, tag, dimensione e ID                                 |\n",
    "| `docker pull <img>`                                              | Scarica un’immagine dal registry (Docker Hub, GHCR, ecc.) | `docker pull python:3.11-slim`                                          |\n",
    "| `docker build -t <nome>:<tag> .`                                 | Crea un’immagine a partire da un Dockerfile               | `docker build -t crewai-backend:1.0 .`                                  |\n",
    "| `docker tag <img> <registry>/<repo>:<tag>`                       | Aggiunge un tag per pushare un’immagine                   | `docker tag crewai:1.0 myorg/crewai:1.0`                                |\n",
    "| `docker push <repo>`                                             | Carica un’immagine sul registry remoto                    | `docker push myorg/crewai:1.0`                                          |\n",
    "| `docker start <container>`                                       | Riavvia un container fermato                              | `docker start crew_backend`                                             |\n",
    "| `docker stop <container>`                                        | Ferma un container attivo                                 | `docker stop crew_backend`                                              |\n",
    "| `docker restart <container>`                                     | Riavvia il container (stop + start)                       | utile per applicare aggiornamenti                                       |\n",
    "| `docker rm <container>`                                          | Rimuove un container fermo                                | `docker rm crew_backend`                                                |\n",
    "| `docker rmi <image>`                                             | Rimuove un’immagine locale                                | `docker rmi python:3.11-slim`                                           |\n",
    "| `docker volume ls`                                               | Elenca i volumi persistenti                               | utile per dataset, modelli o DB                                         |\n",
    "| `docker network ls`                                              | Elenca le reti Docker                                     | utile per capire come comunicano i microservizi                         |\n",
    "| `docker compose up -d`                                           | Avvia più container definiti in `docker-compose.yml`      | `docker compose up -d` → lancia CrewAI + Qdrant + Streamlit             |\n",
    "| `docker compose down`                                            | Ferma e rimuove tutti i container dello stack             | Cleanup completo di uno stack AI                                        |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120d9fe-a5db-4aa3-a201-a66268bfeb28",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **Esercizi sui comandi base Docker**\n",
    "\n",
    "---\n",
    "\n",
    "##  **SEZIONE 1 – TRACCE (per esercitarsi in autonomia)**\n",
    "\n",
    "### 🔹 **Esercizio 1 – Primo container interattivo**\n",
    "\n",
    "Crea un container interattivo basato su `python:3.11`, entra al suo interno, installa qualche libreria AI (es. `crewai` e `qdrant-client`), e verifica che funzioni.\n",
    "Chiudi il container e scopri se al riavvio le librerie sono ancora presenti.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 2 – Persistenza tramite volume**\n",
    "\n",
    "Ripeti l’esercizio 1, ma questa volta monta una cartella locale in `/app` dentro il container, salva un file Python e verifica che resti sul disco anche dopo aver chiuso il container.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 3 – Creare e rinominare container**\n",
    "\n",
    "Crea due container basati su `python:3.11`:\n",
    "\n",
    "* uno con il nome `crew_test`\n",
    "* uno con il nome `qdrant_test`\n",
    "\n",
    "Elenca i container, fermali e rimuovili entrambi.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 4 – Esaminare container attivi**\n",
    "\n",
    "Esegui un container in background (`-d`) basato su `python:3.11-slim` che esegua il comando:\n",
    "\n",
    "```bash\n",
    "python -c \"import time; [print('running...') or time.sleep(2) for _ in range(5)]\"\n",
    "```\n",
    "\n",
    "Poi:\n",
    "\n",
    "1. Controlla che sia attivo.\n",
    "2. Leggi i log del container.\n",
    "3. Ispeziona la sua configurazione (IP, comando, stato).\n",
    "4. Attendi che termini e verifica lo stato con `docker ps -a`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 5 – Interagire con un container esistente**\n",
    "\n",
    "Crea un container in background con:\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_env python:3.11 sleep 300\n",
    "```\n",
    "\n",
    "Poi:\n",
    "\n",
    "* entra dentro il container con `docker exec -it`;\n",
    "* crea un file `test.txt`;\n",
    "* leggi il contenuto dall’host senza entrare nel container;\n",
    "* infine fermalo e rimuovilo.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 6 – Analisi dettagliata**\n",
    "\n",
    "Crea un container basato su `python:3.11`, assegnagli un nome (`analyze_me`) e avvialo.\n",
    "Usa `docker inspect` per:\n",
    "\n",
    "1. Estrarre il suo indirizzo IP interno;\n",
    "2. Verificare il comando di avvio;\n",
    "3. Controllare se ha variabili d’ambiente predefinite.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 7 – Pulizia e gestione immagini**\n",
    "\n",
    "1. Elenca le immagini presenti sul tuo sistema.\n",
    "2. Cancella le immagini che non ti servono.\n",
    "3. Rimuovi tutti i container non più in uso.\n",
    "4. Pulisci il sistema con `docker system prune`.\n",
    "5. Controlla quanto spazio hai liberato.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#  **SEZIONE 2 – SOLUZIONI GUIDATE PASSO PASSO**\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 1 – Primo container interattivo**\n",
    "\n",
    "**1. Avvia il container:**\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11 bash\n",
    "```\n",
    "\n",
    "**2. All’interno:**\n",
    "\n",
    "```bash\n",
    "pip install crewai qdrant-client\n",
    "python -c \"import crewai, qdrant_client; print('ok')\"\n",
    "```\n",
    "\n",
    "**3. Esci:**\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "**4. Controlla lo stato:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "Il container è fermo ma ancora presente.\n",
    "Riavvialo:\n",
    "\n",
    "```bash\n",
    "docker start -ai <container_id>\n",
    "```\n",
    "\n",
    "Verifica: le librerie **non sono più installate** — il container è effimero.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 2 – Persistenza tramite volume**\n",
    "\n",
    "**1. Avvia il container con volume montato:**\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash\n",
    "```\n",
    "\n",
    "(su Linux/macOS: `-v $(pwd):/app`)\n",
    "\n",
    "**2. All’interno del container:**\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "echo \"print('Hello from Docker')\" > hello.py\n",
    "python hello.py\n",
    "```\n",
    "\n",
    "**3. Esci e controlla nella cartella locale:**\n",
    "Il file `hello.py` è rimasto → la persistenza funziona.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 3 – Creare e rinominare container**\n",
    "\n",
    "**1. Crea i container:**\n",
    "\n",
    "```bash\n",
    "docker run -it --name crew_test python:3.11 bash\n",
    "docker run -it --name qdrant_test python:3.11 bash\n",
    "```\n",
    "\n",
    "(esci subito da entrambi con `exit`)\n",
    "\n",
    "**2. Elenca i container:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "**3. Ferma e rimuovi:**\n",
    "\n",
    "```bash\n",
    "docker stop crew_test qdrant_test\n",
    "docker rm crew_test qdrant_test\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 4 – Esaminare container attivi**\n",
    "\n",
    "**1. Esegui in background:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name test_logger python:3.11-slim python -c \"import time; [print('running...') or time.sleep(2) for _ in range(5)]\"\n",
    "```\n",
    "\n",
    "**2. Controlla stato:**\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "**3. Leggi log:**\n",
    "\n",
    "```bash\n",
    "docker logs test_logger\n",
    "```\n",
    "\n",
    "**4. Ispeziona:**\n",
    "\n",
    "```bash\n",
    "docker inspect test_logger\n",
    "```\n",
    "\n",
    "**5. Dopo 10 secondi:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "Il container avrà `STATUS: Exited`.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 5 – Interagire con un container esistente**\n",
    "\n",
    "**1. Avvia container in background:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_env python:3.11 sleep 300\n",
    "```\n",
    "\n",
    "**2. Entra dentro:**\n",
    "\n",
    "```bash\n",
    "docker exec -it crew_env bash\n",
    "```\n",
    "\n",
    "**3. Crea file:**\n",
    "\n",
    "```bash\n",
    "echo \"Docker test OK\" > /tmp/test.txt\n",
    "exit\n",
    "```\n",
    "\n",
    "**4. Leggi contenuto da host:**\n",
    "\n",
    "```bash\n",
    "docker exec crew_env cat /tmp/test.txt\n",
    "```\n",
    "\n",
    "**5. Ferma e rimuovi:**\n",
    "\n",
    "```bash\n",
    "docker stop crew_env\n",
    "docker rm crew_env\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 6 – Analisi dettagliata**\n",
    "\n",
    "**1. Crea container:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name analyze_me python:3.11 sleep 60\n",
    "```\n",
    "\n",
    "**2. Estrarre IP:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.NetworkSettings.IPAddress}}' analyze_me\n",
    "```\n",
    "\n",
    "**3. Comando di avvio:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.Config.Cmd}}' analyze_me\n",
    "```\n",
    "\n",
    "**4. Variabili d’ambiente:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.Config.Env}}' analyze_me\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 7 – Pulizia e gestione immagini**\n",
    "\n",
    "**1. Elenca immagini e container:**\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "**2. Cancella tutto ciò che non serve:**\n",
    "\n",
    "```bash\n",
    "docker rm $(docker ps -aq)\n",
    "docker rmi $(docker images -q)\n",
    "```\n",
    "\n",
    "**3. Pulizia generale:**\n",
    "\n",
    "```bash\n",
    "docker system prune -af\n",
    "```\n",
    "\n",
    "**4. Controlla spazio:**\n",
    "\n",
    "```bash\n",
    "docker system df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff3bc-c9c1-4bbf-9122-da8517d59d2c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.8 – Persistenza notebook/data (`-v`, `--mount`, `--network`)**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema della volatilità nei container**\n",
    "\n",
    "Per impostazione predefinita, i container Docker sono **temporanei**.\n",
    "Se li elimini, tutto ciò che era stato scritto dentro (file, notebook, database, modelli scaricati) sparisce.\n",
    "Questo comportamento è ottimo per test e build pulite, ma in progetti AI è **inaccettabile**:\n",
    "\n",
    "* vogliamo mantenere **dataset e notebook** tra sessioni,\n",
    "* salvare **cache di modelli Hugging Face**,\n",
    "* preservare **indici vettoriali di Qdrant** o **file SQLite di CrewAI**.\n",
    "\n",
    "Docker offre due modi principali per salvare i dati:\n",
    "\n",
    "* **Volumi** (gestiti da Docker, con `-v` o `--mount`)\n",
    "* **Bind mount** (collega una cartella dell’host)\n",
    "\n",
    "Vediamoli nel dettaglio.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Persistenza con `-v` (bind mount)**\n",
    "\n",
    "Il metodo più semplice e immediato per rendere persistenti i dati è collegare una **cartella locale dell’host** a una directory del container.\n",
    "\n",
    "### Esempio:\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash   # Windows PowerShell\n",
    "```\n",
    "\n",
    "oppure su Linux/macOS:\n",
    "\n",
    "```bash\n",
    "docker run -it -v $(pwd):/app python:3.11 bash\n",
    "```\n",
    "\n",
    "All’interno del container, tutto ciò che scrivi in `/app` viene salvato nella tua directory locale.\n",
    "\n",
    "### Test rapido:\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "echo \"print('Persistente!')\" > test.py\n",
    "exit\n",
    "```\n",
    "\n",
    "Il file `test.py` esiste ancora nel tuo computer locale.\n",
    "\n",
    " **Uso tipico in AI:**\n",
    "\n",
    "* salvare notebook Jupyter (`.ipynb`);\n",
    "* scrivere output JSON o CSV di CrewAI;\n",
    "* mantenere la cache Hugging Face (`/root/.cache/huggingface`).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Persistenza con `--mount` (volumi gestiti da Docker)**\n",
    "\n",
    "`--mount` è un metodo più moderno e leggibile rispetto a `-v`.\n",
    "Offre maggiore controllo e chiarezza, soprattutto negli script o nei file Compose.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```bash\n",
    "docker run -it --mount type=bind,source=%cd%,target=/app python:3.11 bash\n",
    "```\n",
    "\n",
    "Equivalente a `-v %cd%:/app`, ma più esplicito e robusto.\n",
    "Puoi anche montare **volumi gestiti da Docker**, non solo cartelle locali.\n",
    "\n",
    "### Esempio con volume Docker:\n",
    "\n",
    "```bash\n",
    "docker volume create crew_data\n",
    "docker run -it --mount source=crew_data,target=/app python:3.11 bash\n",
    "```\n",
    "\n",
    "Tutto ciò che salvi in `/app` è conservato nel volume, anche se elimini il container.\n",
    "Puoi elencare i volumi:\n",
    "\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "e ispezionarli:\n",
    "\n",
    "```bash\n",
    "docker volume inspect crew_data\n",
    "```\n",
    "\n",
    " **Uso tipico in AI:**\n",
    "\n",
    "* salvare database Qdrant (`/qdrant/storage`),\n",
    "* dati CrewAI (`/data`),\n",
    "* cache modelli condivisa tra più container.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Differenza tra `-v` e `--mount`**\n",
    "\n",
    "| Caratteristica  | `-v`                   | `--mount`                               |\n",
    "| --------------- | ---------------------- | --------------------------------------- |\n",
    "| Sintassi        | più corta              | più leggibile e sicura                  |\n",
    "| Tipo            | supporta bind e volume | supporta bind, volume e tmpfs           |\n",
    "| Specificità     | stringa unica          | parametri chiari (type, source, target) |\n",
    "| Consigliato per | uso rapido             | ambienti complessi o Compose file       |\n",
    "\n",
    " In produzione e in file `docker-compose.yml`, **usa sempre `--mount`** o la forma YAML di `volumes:`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Persistenza di notebook e dati**\n",
    "\n",
    "Se vuoi eseguire **Jupyter Notebook in container**, devi montare la directory del progetto:\n",
    "\n",
    "```bash\n",
    "docker run -it -p 8888:8888 -v %cd%:/notebooks jupyter/base-notebook\n",
    "```\n",
    "\n",
    "Apri il browser su `localhost:8888` e troverai tutti i tuoi file locali visibili in `/notebooks`.\n",
    "\n",
    "Ogni notebook salvato lì resta anche dopo il riavvio del container.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Persistenza dei modelli AI**\n",
    "\n",
    "Le librerie Hugging Face salvano modelli scaricati in:\n",
    "\n",
    "```\n",
    "~/.cache/huggingface\n",
    "```\n",
    "\n",
    "Se vuoi evitare di riscaricarli ogni volta, monta la cache come volume persistente:\n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "  -v %USERPROFILE%\\.cache\\huggingface:/root/.cache/huggingface \\\n",
    "  pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime bash\n",
    "```\n",
    "\n",
    "Ora ogni container condividerà la stessa cache dei modelli.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Persistenza di database e vector store**\n",
    "\n",
    "### Qdrant:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "```\n",
    "\n",
    "Il volume `qdrant_data` mantiene l’indice vettoriale anche dopo il riavvio.\n",
    "\n",
    "### PostgreSQL (es. per CrewAI logs):\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 5432:5432 \\\n",
    "  -v pg_data:/var/lib/postgresql/data \\\n",
    "  -e POSTGRES_PASSWORD=crewpass \\\n",
    "  postgres:15\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Reti personalizzate (`--network`)**\n",
    "\n",
    "In un progetto AI multi-container, serve spesso far comunicare i servizi tra loro (es. CrewAI → Qdrant → Streamlit).\n",
    "Per farlo Docker offre le **reti bridge personalizzate**.\n",
    "\n",
    "### Creare una rete:\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "```\n",
    "\n",
    "### Eseguire container collegati alla stessa rete:\n",
    "\n",
    "```bash\n",
    "docker run -d --name qdrant --network ai_net qdrant/qdrant:v1.10.0\n",
    "docker run -it --name crew_backend --network ai_net python:3.11 bash\n",
    "```\n",
    "\n",
    "Ora, da dentro `crew_backend`, puoi connetterti a `qdrant` usando:\n",
    "\n",
    "```python\n",
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "```\n",
    "\n",
    " *Non serve conoscere l’IP*, Docker risolve automaticamente i nomi dei container come host DNS.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizi pratici**\n",
    "\n",
    "### 🔹 **Esercizio 1 – Volume locale**\n",
    "\n",
    "1. Crea una cartella `C:\\docker_test`.\n",
    "2. Avvia un container con:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it -v C:\\docker_test:/app python:3.11 bash\n",
    "   ```\n",
    "3. Dentro `/app`, crea `test.py` e scrivi qualcosa.\n",
    "4. Chiudi, verifica che il file sia rimasto nella cartella locale.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 2 – Volume Docker**\n",
    "\n",
    "1. Crea volume:\n",
    "\n",
    "   ```bash\n",
    "   docker volume create crew_data\n",
    "   ```\n",
    "2. Avvia container:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it --mount source=crew_data,target=/data python:3.11 bash\n",
    "   ```\n",
    "3. Crea file `/data/persist.txt`.\n",
    "4. Esci e rimuovi il container.\n",
    "5. Avvia un nuovo container con lo stesso volume e verifica che il file esista ancora.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 3 – Rete condivisa**\n",
    "\n",
    "1. Crea rete:\n",
    "\n",
    "   ```bash\n",
    "   docker network create ai_net\n",
    "   ```\n",
    "2. Avvia Qdrant:\n",
    "\n",
    "   ```bash\n",
    "   docker run -d --name qdrant --network ai_net qdrant/qdrant:v1.10.0\n",
    "   ```\n",
    "3. Avvia Python backend:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it --network ai_net python:3.11 bash\n",
    "   ```\n",
    "4. Dentro Python:\n",
    "\n",
    "   ```python\n",
    "   from qdrant_client import QdrantClient\n",
    "   client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "   print(client.get_collections())\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Riepilogo**\n",
    "\n",
    "| Comando / Opzione               | Funzione                             | Esempio tipico AI                      |\n",
    "| ------------------------------- | ------------------------------------ | -------------------------------------- |\n",
    "| `-v host:container`             | Collega cartella locale (bind mount) | Notebook, codice sorgente              |\n",
    "| `--mount source=...,target=...` | Volume gestito da Docker             | Cache modelli, database, indici Qdrant |\n",
    "| `docker volume create <name>`   | Crea volume persistente              | `docker volume create crew_data`       |\n",
    "| `docker network create <name>`  | Crea rete personalizzata             | `docker network create ai_net`         |\n",
    "| `--network <name>`              | Collega container alla stessa rete   | `--network ai_net`                     |\n",
    "| `docker volume ls`              | Mostra volumi                        | Verifica storage CrewAI                |\n",
    "| `docker network ls`             | Mostra reti                          | Debug connessioni tra container        |\n",
    "\n",
    "---\n",
    "\n",
    "Docker non è solo “un contenitore”: è un **ecosistema di filesystem, reti e processi**.\n",
    "Per un AI Engineer, capire come usare `-v`, `--mount` e `--network` significa saper costruire **pipeline CrewAI e RAG persistenti**, scalabili e interconnesse in modo professionale.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8a185-6049-44ea-b5c7-a8ca3223d88e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.1 – Cos’è un Dockerfile**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Definizione**\n",
    "\n",
    "Un **Dockerfile** è un semplice **file di testo** che contiene **le istruzioni** per costruire un’immagine Docker.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* descrive **passo dopo passo** come creare un ambiente completo (sistema operativo, librerie, codice, comandi d’avvio);\n",
    "* Docker lo “legge” e, seguendo quelle istruzioni, costruisce un’immagine pronta all’uso;\n",
    "* quell’immagine può poi essere eseguita su qualsiasi computer o server con Docker installato, **sempre nello stesso modo**.\n",
    "\n",
    "È, a tutti gli effetti, **la ricetta dell’ambiente di esecuzione**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Analogia**\n",
    "\n",
    "Pensa al Dockerfile come a una **ricetta di cucina**:\n",
    "\n",
    "* Ogni riga è un ingrediente o un’azione (es. “installa Python”, “copia il codice”).\n",
    "* Docker è il cuoco che la legge e prepara il piatto (l’immagine).\n",
    "* L’immagine finale è il **piatto pronto** (un ambiente completo e isolato).\n",
    "* Quando “servi il piatto” (cioè lanci un container), Docker prende quell’immagine e la esegue come un piccolo sistema operativo in miniatura.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Perché serve**\n",
    "\n",
    "Nel mondo AI o software moderno, lavorare su progetti complessi come:\n",
    "\n",
    "* **CrewAI** (più agenti, librerie AI, dipendenze pesanti),\n",
    "* **LangChain** (diverse versioni di pacchetti),\n",
    "* **Qdrant** o **PostgreSQL** (database separati),\n",
    "* **Streamlit** o **FastAPI** (frontend e API),\n",
    "\n",
    "significa dover gestire decine di librerie e ambienti.\n",
    "Un Dockerfile risolve questo problema: crea un ambiente **standardizzato e replicabile**, che chiunque può ricostruire con un solo comando.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Come funziona**\n",
    "\n",
    "Docker legge il Dockerfile **dall’alto verso il basso**.\n",
    "Ogni istruzione crea un “**layer**” dell’immagine: un piccolo pezzo di filesystem.\n",
    "L’insieme di questi layer forma l’immagine finale.\n",
    "\n",
    "Esempio semplificato:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Vediamolo in parole:\n",
    "\n",
    "1. **FROM python:3.11-slim** → usa come base un sistema Linux con Python 3.11 già installato.\n",
    "2. **WORKDIR /app** → imposta la directory di lavoro.\n",
    "3. **COPY . .** → copia i file del progetto nel container.\n",
    "4. **RUN pip install -r requirements.txt** → installa le librerie.\n",
    "5. **CMD [\"python\", \"main.py\"]** → definisce il comando da eseguire quando il container parte.\n",
    "\n",
    "Il risultato sarà un’immagine Docker con:\n",
    "\n",
    "* Python 3.11\n",
    "* tutte le librerie del progetto\n",
    "* il codice copiato\n",
    "* pronta per avviarsi con `python main.py`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Creare e usare un Dockerfile**\n",
    "\n",
    "1. Crea un file chiamato `Dockerfile` (senza estensione).\n",
    "2. Scrivi le istruzioni dentro.\n",
    "3. Costruisci l’immagine con:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t nome-immagine .\n",
    "   ```\n",
    "\n",
    "   (`-t` = tag, `.` = directory corrente dove si trova il Dockerfile)\n",
    "4. Avvia un container da quell’immagine:\n",
    "\n",
    "   ```bash\n",
    "   docker run nome-immagine\n",
    "   ```\n",
    "\n",
    "Esempio completo:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai-backend .\n",
    "docker run -it crewai-backend\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Struttura tipica**\n",
    "\n",
    "Ogni Dockerfile segue un ordine logico:\n",
    "\n",
    "| Sezione        | Istruzione                 | Funzione                                                  |\n",
    "| -------------- | -------------------------- | --------------------------------------------------------- |\n",
    "| Base           | `FROM`                     | Sceglie l’immagine di partenza (es. Python, Node, Ubuntu) |\n",
    "| Setup          | `RUN`                      | Esegue comandi (es. installazioni, aggiornamenti)         |\n",
    "| Copia codice   | `COPY` / `ADD`             | Copia file dal computer nel container                     |\n",
    "| Configurazione | `ENV`, `WORKDIR`, `EXPOSE` | Imposta variabili e directory                             |\n",
    "| Avvio          | `CMD` / `ENTRYPOINT`       | Definisce il comando di esecuzione                        |\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Differenza tra immagine e container**\n",
    "\n",
    "* Il **Dockerfile** costruisce l’**immagine** (il modello).\n",
    "* Da quell’immagine si possono creare più **container** (le istanze in esecuzione).\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai:latest .\n",
    "docker run -d --name crew1 crewai:latest\n",
    "docker run -d --name crew2 crewai:latest\n",
    "```\n",
    "\n",
    "→ stesso ambiente, due container indipendenti.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico**\n",
    "\n",
    "1. Crea una nuova cartella:\n",
    "\n",
    "   ```\n",
    "   docker_test/\n",
    "   ├── Dockerfile\n",
    "   └── main.py\n",
    "   ```\n",
    "2. In `main.py` scrivi:\n",
    "\n",
    "   ```python\n",
    "   print(\"Hello from Docker!\")\n",
    "   ```\n",
    "3. In `Dockerfile`:\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM python:3.11-slim\n",
    "   WORKDIR /app\n",
    "   COPY . .\n",
    "   CMD [\"python\", \"main.py\"]\n",
    "   ```\n",
    "4. Costruisci e avvia:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t hello-docker .\n",
    "   docker run hello-docker\n",
    "   ```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Hello from Docker!\n",
    "```\n",
    "\n",
    "Ora hai creato la tua prima immagine personalizzata.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. In sintesi**\n",
    "\n",
    "| Concetto             | Descrizione                                                   |\n",
    "| -------------------- | ------------------------------------------------------------- |\n",
    "| Dockerfile           | File di testo con istruzioni per costruire un ambiente Docker |\n",
    "| Immagine             | L’ambiente creato a partire dal Dockerfile                    |\n",
    "| Container            | L’istanza in esecuzione dell’immagine                         |\n",
    "| `docker build`       | Crea l’immagine                                               |\n",
    "| `docker run`         | Esegue il container                                           |\n",
    "| `FROM`               | Base del sistema                                              |\n",
    "| `RUN`, `COPY`, `CMD` | Istruzioni principali                                         |\n",
    "\n",
    "---\n",
    "\n",
    "Un Dockerfile è quindi **il cuore di ogni progetto containerizzato**.\n",
    "Nei prossimi punti impareremo:\n",
    "\n",
    "* come ottimizzarlo per AI (ridurre peso e tempi di build),\n",
    "* come gestire dipendenze, cache e volumi,\n",
    "* e come scrivere Dockerfile modulari per pipeline CrewAI reali.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ddb26-0897-4a66-9c9f-b3f8982b52de",
   "metadata": {},
   "source": [
    "\n",
    "# **2.2 – Istruzioni fondamentali del Dockerfile**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. `FROM` – l’immagine di base**\n",
    "\n",
    "È **sempre la prima riga** di un Dockerfile.\n",
    "Serve per specificare **da quale sistema operativo o ambiente di partenza** costruire la tua immagine.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "```\n",
    "\n",
    "→ parte da Debian “slim” con Python 3.11 già installato.\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "```\n",
    "\n",
    "→ parte da un ambiente già pronto per PyTorch con CUDA e cuDNN.\n",
    "\n",
    "### Regole:\n",
    "\n",
    "* puoi usare **immagini ufficiali** (es. python, node, ubuntu) o personalizzate;\n",
    "* è possibile **cambiare base** in base al progetto (CPU-only o GPU);\n",
    "* ogni immagine base contiene già un piccolo sistema Linux.\n",
    "\n",
    " *Best practice per AI:*\n",
    "\n",
    "* per ambienti CPU: `python:3.11-slim`;\n",
    "* per GPU NVIDIA: `pytorch/pytorch:<ver>-cuda<xx>-runtime`;\n",
    "* per GPU AMD: `rocm/pytorch:latest`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `WORKDIR` – directory di lavoro**\n",
    "\n",
    "Definisce **la cartella in cui verranno eseguiti tutti i comandi successivi** (come `RUN`, `COPY`, `CMD`, ecc.).\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "→ Tutti i comandi successivi verranno eseguiti come se fossi dentro `/app`.\n",
    "\n",
    "Puoi definirne più d’uno:\n",
    "\n",
    "```dockerfile\n",
    "WORKDIR /usr/src\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "→ il secondo sovrascrive il primo (come un `cd`).\n",
    "\n",
    " *Best practice:*\n",
    "Usa sempre `WORKDIR` e **non** `/` o directory di sistema per scrivere i tuoi file.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `COPY` – copia file dall’host al container**\n",
    "\n",
    "Serve per trasferire file e cartelle dal tuo computer (host) all’interno dell’immagine.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "→ copia tutti i file della directory corrente nel container (nella `WORKDIR`).\n",
    "\n",
    "Puoi anche essere più specifico:\n",
    "\n",
    "```dockerfile\n",
    "COPY requirements.txt .\n",
    "COPY src/ ./src\n",
    "```\n",
    "\n",
    " *Suggerimenti:*\n",
    "\n",
    "* escludi file inutili con `.dockerignore` (es. `.git`, `__pycache__`, `venv`, `data/`);\n",
    "* mantieni ordine: prima copia i file di dipendenze (`requirements.txt`), poi il codice.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `RUN` – esegue comandi durante la build**\n",
    "\n",
    "`RUN` viene eseguito **mentre si costruisce l’immagine**, non quando il container parte.\n",
    "Serve per installare librerie, creare directory, aggiornare pacchetti, ecc.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "RUN apt-get update && apt-get install -y git\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "```\n",
    "\n",
    "Ogni `RUN` crea un **nuovo layer** dell’immagine.\n",
    "\n",
    " *Ottimizzazione:*\n",
    "\n",
    "* combina più comandi con `&&` per ridurre i layer;\n",
    "* pulisci la cache di apt per alleggerire l’immagine:\n",
    "\n",
    "  ```dockerfile\n",
    "  RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*\n",
    "  ```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `ENV` – definisce variabili d’ambiente**\n",
    "\n",
    "Le variabili definite con `ENV` sono visibili **dentro il container** a runtime.\n",
    "Molto utile per chiavi API, configurazioni o impostazioni di Python.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV OPENAI_API_KEY=\"sk-xxxxx\"\n",
    "```\n",
    "\n",
    "Puoi anche dichiararle tutte insieme:\n",
    "\n",
    "```dockerfile\n",
    "ENV PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PYTHONUNBUFFERED=1 \\\n",
    "    PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "```\n",
    "\n",
    " *Best practice per AI:*\n",
    "\n",
    "* imposta sempre `PYTHONUNBUFFERED=1` → output immediato nei log;\n",
    "* evita di scrivere chiavi sensibili nel Dockerfile → passa le variabili con `-e` nel `docker run`.\n",
    "\n",
    "Esempio runtime:\n",
    "\n",
    "```bash\n",
    "docker run -e OPENAI_API_KEY=$OPENAI_API_KEY crewai-backend\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. `EXPOSE` – documenta le porte usate**\n",
    "\n",
    "Serve per **indicare quale porta interna del container** viene usata dal servizio.\n",
    "Non apre realmente la porta, ma aiuta Docker a sapere come mappare correttamente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "EXPOSE 8080\n",
    "```\n",
    "\n",
    "→ Il container comunica sulla porta 8080.\n",
    "Poi, quando lo lanci:\n",
    "\n",
    "```bash\n",
    "docker run -p 8080:8080 crewai-backend\n",
    "```\n",
    "\n",
    "la porta 8080 del container è raggiungibile come `localhost:8080`.\n",
    "\n",
    " *Best practice:*\n",
    "\n",
    "* API backend: 8000 o 8080\n",
    "* Qdrant: 6333\n",
    "* Streamlit: 8501\n",
    "\n",
    "---\n",
    "\n",
    "## **7. `CMD` – comando di avvio del container**\n",
    "\n",
    "È il comando che viene eseguito **quando il container parte**.\n",
    "Ogni immagine può avere **un solo CMD**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Alternative:\n",
    "\n",
    "```dockerfile\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "CMD [\"streamlit\", \"run\", \"ui/Home.py\", \"--server.port\", \"8501\"]\n",
    "```\n",
    "\n",
    " *Regole:*\n",
    "\n",
    "* se nel `docker run` specifichi un comando manuale, questo **sovrascrive** il CMD;\n",
    "\n",
    "  ```bash\n",
    "  docker run myimage python other_script.py\n",
    "  ```\n",
    "* il CMD deve sempre essere l’ultimo comando del Dockerfile;\n",
    "* usa la sintassi **JSON array** (non shell) per evitare errori di parsing.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. `ENTRYPOINT` – comando fisso di avvio**\n",
    "\n",
    "Simile a `CMD`, ma **non può essere sovrascritto** facilmente.\n",
    "Serve per rendere “eseguibile” il container.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"main.py\"]\n",
    "```\n",
    "\n",
    "→ di default esegue `python main.py`, ma puoi fare:\n",
    "\n",
    "```bash\n",
    "docker run myimage other.py\n",
    "```\n",
    "\n",
    "→ eseguirà `python other.py`.\n",
    "\n",
    " *Regola generale:*\n",
    "\n",
    "* usa `ENTRYPOINT` se vuoi rendere il container eseguibile (CLI tool, script);\n",
    "* usa `CMD` per applicazioni (server, API).\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Altri comandi utili (cenni rapidi)**\n",
    "\n",
    "| Comando       | Funzione                                                            |\n",
    "| ------------- | ------------------------------------------------------------------- |\n",
    "| `ADD`         | Come `COPY`, ma può scaricare URL o scompattare archivi             |\n",
    "| `LABEL`       | Aggiunge metadati all’immagine (autore, versione)                   |\n",
    "| `USER`        | Imposta l’utente che esegue i comandi (non root per sicurezza)      |\n",
    "| `ARG`         | Variabili disponibili solo durante la build (es. `ARG PY_VER=3.11`) |\n",
    "| `ONBUILD`     | Comandi che si attivano solo in immagini derivate                   |\n",
    "| `HEALTHCHECK` | Controlla lo stato del container periodicamente                     |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Esercizio pratico: costruire un Dockerfile completo**\n",
    "\n",
    "1. Crea una cartella `myapp/`\n",
    "\n",
    "   ```\n",
    "   myapp/\n",
    "   ├── Dockerfile\n",
    "   ├── requirements.txt\n",
    "   └── app.py\n",
    "   ```\n",
    "\n",
    "2. In `requirements.txt`:\n",
    "\n",
    "   ```\n",
    "   fastapi==0.114.0\n",
    "   uvicorn==0.30.6\n",
    "   ```\n",
    "\n",
    "3. In `app.py`:\n",
    "\n",
    "   ```python\n",
    "   from fastapi import FastAPI\n",
    "   app = FastAPI()\n",
    "\n",
    "   @app.get(\"/\")\n",
    "   def hello():\n",
    "       return {\"msg\": \"Hello from Docker!\"}\n",
    "   ```\n",
    "\n",
    "4. In `Dockerfile`:\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM python:3.11-slim\n",
    "   WORKDIR /app\n",
    "   COPY requirements.txt .\n",
    "   RUN pip install --no-cache-dir -r requirements.txt\n",
    "   COPY . .\n",
    "   EXPOSE 8080\n",
    "   CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "   ```\n",
    "\n",
    "5. Costruisci e lancia:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t fastapi-demo .\n",
    "   docker run -p 8080:8080 fastapi-demo\n",
    "   ```\n",
    "\n",
    "6. Apri [http://localhost:8080](http://localhost:8080)\n",
    "   → dovresti vedere:\n",
    "   `{\"msg\": \"Hello from Docker!\"}`\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Riepilogo**\n",
    "\n",
    "| Istruzione   | Scopo                      | Esempio                               |\n",
    "| ------------ | -------------------------- | ------------------------------------- |\n",
    "| `FROM`       | Base dell’immagine         | `FROM python:3.11-slim`               |\n",
    "| `WORKDIR`    | Directory di lavoro        | `WORKDIR /app`                        |\n",
    "| `COPY`       | Copia file nel container   | `COPY . .`                            |\n",
    "| `RUN`        | Esegue comandi di build    | `RUN pip install -r requirements.txt` |\n",
    "| `ENV`        | Imposta variabili ambiente | `ENV PYTHONUNBUFFERED=1`              |\n",
    "| `EXPOSE`     | Documenta porte            | `EXPOSE 8080`                         |\n",
    "| `CMD`        | Comando di avvio           | `CMD [\"python\", \"main.py\"]`           |\n",
    "| `ENTRYPOINT` | Comando fisso di avvio     | `ENTRYPOINT [\"python\"]`               |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefa521-a0c6-4337-bd19-7ee71b48bb48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.3 – Multi-Stage Build: spiegazione semplice e chiara**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema da cui nasce**\n",
    "\n",
    "Quando crei un’immagine Docker, spesso hai **due momenti distinti**:\n",
    "\n",
    "1. **La costruzione (build)**\n",
    "   dove installi compilatori, scarichi repository da Git, compili estensioni, ecc.\n",
    "   → serve molta roba (pacchetti di sviluppo, tool, file temporanei).\n",
    "\n",
    "2. **L’esecuzione (runtime)**\n",
    "   dove ti serve solo il risultato finale: il tuo programma e le librerie già pronte.\n",
    "   → tutto il resto (tool, cache, file temporanei) è inutile e appesantisce l’immagine.\n",
    "\n",
    "---\n",
    "\n",
    "###  Senza multi-stage\n",
    "\n",
    "Se fai tutto nello stesso Dockerfile, ti ritrovi un’immagine **enorme** e piena di file inutili.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Risultato:\n",
    "\n",
    "* immagine da **2-3 GB**,\n",
    "* dentro ci sono compilatori, header file, cache pip…\n",
    "* e tutto ciò non serve più a runtime.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. L’idea del multi-stage build**\n",
    "\n",
    "Docker ti permette di dividere la build in **più “fasi” (stages)**.\n",
    "Ogni stage ha la sua immagine base e il suo ambiente.\n",
    "Alla fine puoi **prendere solo quello che ti serve** e buttar via tutto il resto.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* uno **stage builder** fa tutto il lavoro pesante (installa, compila, crea file).\n",
    "* uno **stage finale (runtime)** parte pulito e riceve **solo i file utili** dal builder.\n",
    "\n",
    "---\n",
    "\n",
    "###  Esempio semplice\n",
    "\n",
    "```dockerfile\n",
    "# STAGE 1 – Builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# STAGE 2 – Runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build /app\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* La prima parte (`AS builder`) crea un’immagine temporanea chiamata *builder*.\n",
    "* Installa lì tutte le dipendenze.\n",
    "* La seconda parte (`FROM ... AS runtime`) crea l’immagine finale.\n",
    "* `COPY --from=builder` prende solo ciò che serve dal primo stage.\n",
    "* Il risultato finale è **pulito, piccolo e pronto all’uso**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Cosa succede dentro Docker**\n",
    "\n",
    "Quando Docker costruisce questo file:\n",
    "\n",
    "1. Crea il primo stage (`builder`), installa tutto.\n",
    "2. Poi **scarta** quell’immagine, ma conserva i file copiati.\n",
    "3. Costruisce la seconda immagine (`runtime`), che contiene solo quei file.\n",
    "\n",
    "→ Risultato: la seconda immagine non ha compilatori, cache o file temporanei.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Vantaggi pratici**\n",
    "\n",
    "| Vantaggio                | Descrizione                                       |\n",
    "| ------------------------ | ------------------------------------------------- |\n",
    "| **Immagini più leggere** | Eviti di includere tool di build e cache pip      |\n",
    "| **Build più pulite**     | Separi logica di build da logica di esecuzione    |\n",
    "| **Più sicurezza**        | Meno tool e pacchetti = meno vulnerabilità        |\n",
    "| **Facile da mantenere**  | Ogni fase ha uno scopo chiaro                     |\n",
    "| **Ottimo per CI/CD**     | Puoi riusare gli stessi stage in pipeline diverse |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Esempio reale – Python con librerie AI**\n",
    "\n",
    "Supponiamo di voler costruire un’immagine per un progetto CrewAI o LangChain.\n",
    "Serve scaricare molte dipendenze Python, alcune anche da Git.\n",
    "\n",
    "Ecco come useresti un multi-stage build semplice:\n",
    "\n",
    "```dockerfile\n",
    "# FASE 1 — Builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "\n",
    "# Installa git e altri strumenti solo qui\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends git build-essential\n",
    "\n",
    "# Copia le dipendenze e installale in una directory temporanea\n",
    "COPY requirements.txt .\n",
    "RUN pip install --target=/build/deps -r requirements.txt\n",
    "\n",
    "# FASE 2 — Runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "\n",
    "# Copia solo i file delle librerie già installate\n",
    "COPY --from=builder /build/deps /usr/local/lib/python3.11/site-packages\n",
    "\n",
    "# Copia il codice dell’app\n",
    "COPY . .\n",
    "\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    " Risultato:\n",
    "\n",
    "* L’immagine finale contiene solo Python + le librerie installate + il tuo codice.\n",
    "* Tutti i tool di build e la cache pip **restano nel builder e vengono scartati**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Multi-stage = più di due fasi**\n",
    "\n",
    "Puoi avere anche 3 o più fasi se vuoi separare meglio i compiti.\n",
    "Esempio tipico per un’app AI con API:\n",
    "\n",
    "1. **builder** → prepara le dipendenze (pip o poetry).\n",
    "2. **api-builder** → costruisce file statici o script ottimizzati.\n",
    "3. **runtime** → esegue l’app (FastAPI o Streamlit).\n",
    "\n",
    "Docker ti permette di copiare file da qualunque fase:\n",
    "\n",
    "```dockerfile\n",
    "COPY --from=api-builder /dist /app\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Come dare un nome alle fasi**\n",
    "\n",
    "Ogni fase ha un nome definito da `AS`.\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "...\n",
    "FROM python:3.11-slim AS runtime\n",
    "COPY --from=builder /build /app\n",
    "```\n",
    "\n",
    "Il nome è utile per dire a Docker **da quale stage copiare i file**.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico – Creiamo due immagini a confronto**\n",
    "\n",
    "### A) Dockerfile semplice (senza multi-stage)\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN apt-get update && apt-get install -y git && pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### B) Dockerfile multi-stage\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "RUN apt-get update && apt-get install -y git\n",
    "COPY requirements.txt .\n",
    "RUN pip install --target=/build/deps -r requirements.txt\n",
    "\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build/deps /usr/local/lib/python3.11/site-packages\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### Confronto\n",
    "\n",
    "| Aspetto              | A) Singolo stage | B) Multi-stage         |\n",
    "| -------------------- | ---------------- | ---------------------- |\n",
    "| Dimensione immagine  | 2-3 GB           | ~800 MB                |\n",
    "| Contiene build-tools | ✅ sì             | ❌ no                   |\n",
    "| Sicurezza            | minore           | maggiore               |\n",
    "| Portabilità          | limitata         | alta                   |\n",
    "| Tempo rebuild        | più lento        | più rapido (cache pip) |\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Come si costruisce**\n",
    "\n",
    "Comando identico:\n",
    "\n",
    "```bash\n",
    "docker build -t myapp:latest .\n",
    "```\n",
    "\n",
    "Docker capisce automaticamente che ci sono più fasi e costruisce solo l’ultima (salvando cache intermedia).\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Cosa ricordare**\n",
    "\n",
    "| Concetto                                | Spiegazione                                   |\n",
    "| --------------------------------------- | --------------------------------------------- |\n",
    "| Ogni `FROM` crea una nuova fase         | Le fasi possono avere nomi (`AS builder`)     |\n",
    "| `COPY --from=`                          | Copia file da una fase all’altra              |\n",
    "| Lo stage finale è l’immagine che rimane | Tutto il resto viene eliminato                |\n",
    "| Obiettivo                               | separare build “pesante” da runtime “leggero” |\n",
    "| Beneficio principale                    | immagini più piccole, sicure e veloci         |\n",
    "\n",
    "---\n",
    "\n",
    " **In sintesi**\n",
    "\n",
    "* Il multi-stage non cambia cosa fa Docker, ma **come lo organizza**.\n",
    "* È il modo corretto di costruire immagini **professionali**, soprattutto nel mondo AI.\n",
    "* Ti permette di preparare ambienti complessi (Torch, Transformers, CrewAI, Qdrant) e distribuire solo ciò che serve per l’esecuzione.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78675233-6449-4ff4-9a23-b61ae55c3197",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.4 – ENTRYPOINT per comandi complessi**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. A cosa serve `ENTRYPOINT`**\n",
    "\n",
    "Quando costruisci un’immagine, devi dire a Docker **che cosa fare quando il container parte**.\n",
    "Puoi farlo in due modi:\n",
    "\n",
    "* con `CMD`\n",
    "* con `ENTRYPOINT`\n",
    "\n",
    "Entrambi indicano **il comando di avvio**, ma con una differenza importante:\n",
    "\n",
    "| Comando      | Può essere sovrascritto da `docker run` | Tipico uso                                     |\n",
    "| ------------ | --------------------------------------- | ---------------------------------------------- |\n",
    "| `CMD`        | ✅ sì                                    | eseguire un’app o uno script semplice          |\n",
    "| `ENTRYPOINT` | ❌ no (di default)                       | rendere il container un *programma* eseguibile |\n",
    "\n",
    " `ENTRYPOINT` rende l’immagine “comportarsi” come un comando.\n",
    "Ad esempio, se hai un tool AI che esegue analisi o scraping, vuoi lanciare:\n",
    "\n",
    "```bash\n",
    "docker run my-ai-analyzer input.txt\n",
    "```\n",
    "\n",
    "e far sì che il container esegua qualcosa tipo:\n",
    "\n",
    "```bash\n",
    "python analyze.py input.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Due sintassi possibili**\n",
    "\n",
    "### a) **Exec form (raccomandata)**\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "→ Docker esegue direttamente il processo come se fosse nativo (senza shell).\n",
    "\n",
    "### b) **Shell form**\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT python main.py\n",
    "```\n",
    "\n",
    "→ viene eseguito dentro `/bin/sh -c`, utile se ti servono operatori shell (`&&`, `|`, `;`), ma meno sicuro e meno efficiente.\n",
    "\n",
    " *Best practice*: usa **exec form** (lista JSON) per applicazioni reali, shell form solo per script d’avvio complessi.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. ENTRYPOINT + CMD = combinazione potente**\n",
    "\n",
    "Puoi usare **entrambi**.\n",
    "Docker combina `ENTRYPOINT` e `CMD`:\n",
    "\n",
    "* `ENTRYPOINT` definisce **il programma principale**,\n",
    "* `CMD` definisce **gli argomenti di default**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "CMD [\"--help\"]\n",
    "```\n",
    "\n",
    "→ se lanci:\n",
    "\n",
    "```bash\n",
    "docker run myapp\n",
    "```\n",
    "\n",
    "esegue:\n",
    "`python main.py --help`\n",
    "\n",
    "Ma se lanci:\n",
    "\n",
    "```bash\n",
    "docker run myapp --version\n",
    "```\n",
    "\n",
    "esegue:\n",
    "`python main.py --version`\n",
    "\n",
    "> Docker sostituisce **solo gli argomenti del CMD**, non l’ENTRYPOINT.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **4. ENTRYPOINT + script Bash per comandi complessi**\n",
    "\n",
    "Spesso ti serve eseguire più cose all’avvio (es. inizializzare modelli, verificare database, poi avviare CrewAI).\n",
    "In questo caso puoi usare uno **script shell** come entrypoint.\n",
    "\n",
    "### a) Dockerfile\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install crewai qdrant-client\n",
    "COPY entrypoint.sh /entrypoint.sh\n",
    "RUN chmod +x /entrypoint.sh\n",
    "ENTRYPOINT [\"/entrypoint.sh\"]\n",
    "```\n",
    "\n",
    "### b) `entrypoint.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e  # interrompe se c’è un errore\n",
    "\n",
    "echo \"🧠 Inizializzazione CrewAI...\"\n",
    "python setup_models.py\n",
    "\n",
    "echo \"🗄️  Controllo connessione Qdrant...\"\n",
    "python check_qdrant.py\n",
    "\n",
    "echo \"🚀 Avvio server principale...\"\n",
    "exec python main.py \"$@\"\n",
    "```\n",
    "\n",
    " `exec` è importante: sostituisce il processo Bash con Python, evitando che Docker perda i log o il PID del processo principale.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. ENTRYPOINT con comandi concatenati**\n",
    "\n",
    "Puoi anche combinare comandi multipli direttamente nel Dockerfile, ma solo se necessario:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"/bin/bash\", \"-c\", \"python prepare.py && python main.py\"]\n",
    "```\n",
    "\n",
    "Tuttavia, **non è consigliato** per progetti complessi — molto meglio usare uno script dedicato come visto sopra.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Personalizzare i parametri in `docker run`**\n",
    "\n",
    "Con `ENTRYPOINT`, puoi passare argomenti extra da linea di comando.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "CMD [\"--help\"]\n",
    "```\n",
    "\n",
    "Puoi cambiare i parametri:\n",
    "\n",
    "```bash\n",
    "docker run myapp --input=data.txt --verbose\n",
    "```\n",
    "\n",
    "→ Docker esegue `python main.py --input=data.txt --verbose`\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Esempio complesso: FastAPI + CrewAI orchestrato**\n",
    "\n",
    "Ecco un esempio realistico per un progetto AI con più servizi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "COPY entrypoint.sh /entrypoint.sh\n",
    "RUN chmod +x /entrypoint.sh  #change mode to x, executable\n",
    "ENTRYPOINT [\"/entrypoint.sh\"]\n",
    "```\n",
    "\n",
    "`entrypoint.sh`:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \" Avvio Qdrant (in background)...\"\n",
    "docker-entrypoint.sh qdrant &\n",
    "\n",
    "echo \" Avvio CrewAI Server...\"\n",
    "exec uvicorn app.main:app --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "In Compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  crewai:\n",
    "    build: .\n",
    "    ports: [\"8080:8080\"]\n",
    "    depends_on: [qdrant]\n",
    "```\n",
    "\n",
    "> Lo script fa partire prima Qdrant, poi CrewAI, in modo ordinato e monitorabile.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Differenze tra ENTRYPOINT e CMD (recap)**\n",
    "\n",
    "| Aspetto                         | `ENTRYPOINT`                           | `CMD`                                    |\n",
    "| ------------------------------- | -------------------------------------- | ---------------------------------------- |\n",
    "| Scopo                           | definisce **il programma principale**  | definisce **gli argomenti di default**   |\n",
    "| Sovrascrizione con `docker run` | ❌ no (a meno di usare `--entrypoint`)  | ✅ sì                                     |\n",
    "| Sintassi preferita              | JSON array                             | JSON array                               |\n",
    "| Tipico uso                      | CLI, script di startup, orchestrazione | impostare default o parametri            |\n",
    "| Posizione                       | 1 sola per Dockerfile                  | 1 sola (spesso combinata con ENTRYPOINT) |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a6b76-666e-4f60-9f38-0f34015f8b9b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.5 – Caching layer e `.dockerignore` nei progetti CrewAI**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema reale**\n",
    "\n",
    "I progetti AI (e in particolare CrewAI) hanno due caratteristiche:\n",
    "\n",
    "1. **Dipendenze pesanti**\n",
    "   Torch, Transformers, LangChain, Qdrant-client, OpenAI SDK, ecc.\n",
    "   Ogni `pip install` può impiegare minuti e scaricare centinaia di MB.\n",
    "\n",
    "2. **File locali numerosi e inutili per la build**\n",
    "   cartelle `.git`, `.venv`, `models/`, `__pycache__/`, `data/`, `.env` → inutili nell’immagine.\n",
    "\n",
    "Senza caching e `.dockerignore`, ogni modifica nel codice fa **ripartire tutto da zero**,\n",
    "ricostruendo anche le librerie pesanti e copiando file superflui.\n",
    "Il risultato?\n",
    "\n",
    "* tempi di build lunghi (anche >10 minuti),\n",
    "* immagini da diversi GB,\n",
    "* scarsa portabilità.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cos’è la cache di Docker**\n",
    "\n",
    "Docker costruisce un’immagine **a layer**: ogni istruzione (`FROM`, `RUN`, `COPY`, ecc.) crea un “pezzo” del filesystem.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "* Se **requirements.txt non cambia**, Docker può riutilizzare la cache del layer `RUN pip install`.\n",
    "* Ma se lo modifichi o se `COPY . .` viene prima, **Docker rigenera tutto da zero**.\n",
    "\n",
    " Quindi **l’ordine delle istruzioni conta moltissimo** per la cache.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Best practice per la cache (ordine corretto)**\n",
    "\n",
    "Ordina sempre così:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "# 1️⃣ Copia SOLO requirements (cambia raramente)\n",
    "COPY requirements.txt .\n",
    "\n",
    "# 2️⃣ Installa dipendenze (caching pip)\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --upgrade pip \\\n",
    " && pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 3️⃣ Copia il codice del progetto (cambia spesso)\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "* **`COPY requirements.txt .`**: viene eseguito solo se requirements cambia → cache efficace.\n",
    "* **`COPY . .`**: viene eseguito dopo → evita di invalidare l’installazione pip per ogni piccolo update del codice.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **4. Cos’è `.dockerignore` e perché è fondamentale**\n",
    "\n",
    "`.dockerignore` funziona come `.gitignore`:\n",
    "indica a Docker **quali file NON copiare nel contesto di build** (cioè la directory che Docker invia al demone).\n",
    "\n",
    "Se Docker deve analizzare 5 GB di dati in `data/` o `models/`,\n",
    "li invierà tutti ogni volta, rallentando la build anche se non servono.\n",
    "\n",
    "### Esempio tipico\n",
    "\n",
    "```\n",
    ".git\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "venv/\n",
    ".env\n",
    ".cache/\n",
    "dist/\n",
    "build/\n",
    "models/\n",
    "data/\n",
    "node_modules/\n",
    "outputs/\n",
    "logs/\n",
    "```\n",
    "\n",
    " *Note per CrewAI*:\n",
    "\n",
    "* **`models/`**: non includere mai modelli HF o checkpoint pesanti → montali come volume.\n",
    "* **`data/`**: includila solo se serve nel runtime (dataset statici o demo).\n",
    "* **`.env`**: contiene chiavi API → escludilo sempre per sicurezza.\n",
    "* **`__pycache__/`** e `.pyc` → inutili.\n",
    "* **`node_modules/`** → solo se hai interfaccia React/Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Esempio reale di `.dockerignore` per progetto CrewAI completo**\n",
    "\n",
    "```\n",
    "# File temporanei e di sistema\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "*.log\n",
    ".DS_Store\n",
    "\n",
    "# Ambienti locali\n",
    "venv/\n",
    ".env\n",
    ".venv/\n",
    ".cache/\n",
    "__pypackages__/\n",
    "\n",
    "# Repositori e build\n",
    ".git\n",
    ".gitignore\n",
    "build/\n",
    "dist/\n",
    "*.egg-info/\n",
    "\n",
    "# Dati pesanti\n",
    "models/\n",
    "data/\n",
    "outputs/\n",
    "logs/\n",
    "*.csv\n",
    "*.zip\n",
    "*.tar.gz\n",
    "\n",
    "# Frontend\n",
    "node_modules/\n",
    "npm-debug.log\n",
    "yarn-error.log\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "```\n",
    "\n",
    " In questo modo Docker copia **solo il codice e i file essenziali**,\n",
    "riducendo drasticamente la dimensione del contesto di build.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Come testare l’effetto del `.dockerignore`**\n",
    "\n",
    "Puoi vedere quali file vengono effettivamente inclusi nel contesto:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai-backend .\n",
    "```\n",
    "\n",
    "Durante la build, Docker stampa:\n",
    "\n",
    "```\n",
    "Sending build context to Docker daemon  12.5MB\n",
    "```\n",
    "\n",
    "→ se prima erano 2GB e ora 12MB, `.dockerignore` sta funzionando.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Cache + .dockerignore = performance reale**\n",
    "\n",
    "| Azione                             | Senza ottimizzazione | Con cache + .dockerignore |\n",
    "| ---------------------------------- | -------------------- | ------------------------- |\n",
    "| Prima build                        | 6–8 minuti           | 6–8 minuti                |\n",
    "| Rebuild dopo piccolo cambio codice | 6–8 minuti           | 15–30 secondi             |\n",
    "| Dimensione immagine                | ~2–3 GB              | ~800 MB                   |\n",
    "| Contesto inviato a Docker          | >1 GB                | ~10–20 MB                 |\n",
    "| Rischio di leak `.env`             | alto                 | nullo                     |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Montare cache persistenti per modelli**\n",
    "\n",
    "Per modelli AI pesanti (es. Transformers, Sentence-Embeddings), **non scaricarli ogni volta**.\n",
    "Usa un volume per la cache HuggingFace:\n",
    "\n",
    "```bash\n",
    "docker run -p 8080:8080 \\\n",
    "  -v $PWD/models:/root/.cache/huggingface \\\n",
    "  crewai-backend\n",
    "```\n",
    "\n",
    "Così:\n",
    "\n",
    "* i modelli vengono scaricati una sola volta;\n",
    "* i container successivi li riutilizzano;\n",
    "* l’immagine rimane leggera e veloce da distribuire.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Errori comuni (e come evitarli)**\n",
    "\n",
    "| Errore                      | Causa                                   | Soluzione                     |\n",
    "| --------------------------- | --------------------------------------- | ----------------------------- |\n",
    "| Ogni build reinstalla tutto | `COPY . .` prima del `pip install`      | inverti l’ordine              |\n",
    "| Build lentissima            | contesto enorme (manca `.dockerignore`) | crea `.dockerignore` completo |\n",
    "| Modelli dentro l’immagine   | copia di `models/` o `data/`            | usa volume montato            |\n",
    "| `.env` incluso              | non ignorato                            | aggiungilo a `.dockerignore`  |\n",
    "| Cache pip non usata         | mancanza `--mount=type=cache`           | abilita BuildKit              |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. In sintesi**\n",
    "\n",
    "| Obiettivo                           | Soluzione                                        |\n",
    "| ----------------------------------- | ------------------------------------------------ |\n",
    "| Evitare reinstallazioni inutili     | Copia requirements prima del codice              |\n",
    "| Riutilizzare librerie già scaricate | Usa `--mount=type=cache,target=/root/.cache/pip` |\n",
    "| Evitare file inutili nel contesto   | Usa `.dockerignore` completo                     |\n",
    "| Evitare modelli nell’immagine       | Monta `~/.cache/huggingface` come volume         |\n",
    "| Build più veloci e pulite           | Struttura Dockerfile con caching consapevole     |\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Prova pratica (5 minuti)**\n",
    "\n",
    "1. Crea un file `Dockerfile` con l’ordine corretto e cache pip.\n",
    "2. Crea `.dockerignore` con le regole sopra.\n",
    "3. Fai due build:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t test-cache .\n",
    "   docker build -t test-cache .\n",
    "   ```\n",
    "4. Osserva i tempi: la seconda build deve essere **istantanea** se non hai modificato `requirements.txt`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5b643-ec31-4455-9560-f04fac43167b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 2.6 – Reti per microservizi AI\n",
    "\n",
    "## (FastAPI backend ↔ Qdrant ↔ Streamlit UI)\n",
    "\n",
    "## 1) Concetto chiave: rete bridge + DNS interno\n",
    "\n",
    "* I container **sulla stessa rete Docker** si vedono per **nome di servizio** (DNS interno).\n",
    "* Non serve conoscere l’IP: dal backend puoi chiamare `http://qdrant:6333` invece di `http://172.18.0.3:6333`.\n",
    "* Esporre porte sull’host (`-p`) serve solo se **vuoi accedere da fuori** (es. browser).\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Setup “a mano” (senza Compose)\n",
    "\n",
    "### Crea una rete dedicata\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "```\n",
    "\n",
    "### Avvia Qdrant su quella rete\n",
    "\n",
    "```bash\n",
    "docker run -d --name qdrant \\\n",
    "  --network ai_net \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "```\n",
    "\n",
    "### Avvia il backend FastAPI (CrewAI) sulla stessa rete\n",
    "\n",
    "```bash\n",
    "docker run -d --name backend \\\n",
    "  --network ai_net \\\n",
    "  -p 8080:8080 \\\n",
    "  -e QDRANT_HOST=qdrant \\\n",
    "  -e QDRANT_PORT=6333 \\\n",
    "  myorg/crewai-backend:latest\n",
    "```\n",
    "\n",
    "Nel codice (Python):\n",
    "\n",
    "```python\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\n",
    "  host=os.getenv(\"QDRANT_HOST\", \"qdrant\"),\n",
    "  port=int(os.getenv(\"QDRANT_PORT\", 6333))\n",
    ")\n",
    "```\n",
    "\n",
    "### Avvia Streamlit UI collegata al backend\n",
    "\n",
    "```bash\n",
    "docker run -d --name ui \\\n",
    "  --network ai_net \\\n",
    "  -p 8501:8501 \\\n",
    "  -e API_BASE_URL=http://backend:8080 \\\n",
    "  myorg/streamlit-ui:latest\n",
    "```\n",
    "\n",
    "Nella UI:\n",
    "\n",
    "```python\n",
    "import os, requests\n",
    "API = os.getenv(\"API_BASE_URL\", \"http://backend:8080\")\n",
    "resp = requests.get(f\"{API}/health\").json()\n",
    "```\n",
    "\n",
    "> Risultato: i tre container **si risolvono per nome** (qdrant, backend, ui) e parlano tra loro senza dover conoscere IP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86649358-4a17-4451-bcfe-45b56ba5be65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5b7e5a4-c141-4f37-a31a-ce9e87eb7586",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Cosa sono le wheels in Python\n",
    "\n",
    "Una *wheel* (`.whl`) è un **pacchetto binario precompilato** di una libreria Python.\n",
    "Rappresenta il formato di distribuzione moderno e ottimizzato che `pip` può installare direttamente, senza la necessità di compilare codice sorgente durante l’installazione.\n",
    "\n",
    "Le wheels sono il successore dei vecchi pacchetti sorgente (`.tar.gz`, chiamati *source distributions* o *sdist*) e permettono di ridurre drasticamente i tempi di installazione.\n",
    "\n",
    "---\n",
    "\n",
    "## Differenza tra wheel e source package\n",
    "\n",
    "Quando si esegue un’installazione con `pip`, ad esempio:\n",
    "\n",
    "```bash\n",
    "pip install numpy\n",
    "```\n",
    "\n",
    "`pip` cerca su PyPI due possibili tipi di pacchetti:\n",
    "\n",
    "1. **Wheel (`.whl`)**\n",
    "   Contiene il codice Python già compilato e pronto per la versione specifica di Python e per il sistema operativo.\n",
    "   L’installazione è immediata.\n",
    "\n",
    "2. **Source Distribution (`.tar.gz`)**\n",
    "   Contiene solo il sorgente del pacchetto.\n",
    "   Per installarlo, `pip` deve compilare il codice, operazione che richiede la presenza di compilatori e librerie di sistema (ad esempio `gcc`, `build-essential`, `python3-dev`).\n",
    "   È più lento e più soggetto a errori di compilazione.\n",
    "\n",
    "---\n",
    "\n",
    "## Struttura di una wheel\n",
    "\n",
    "Esempio di nome di file:\n",
    "\n",
    "```\n",
    "torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl\n",
    "```\n",
    "\n",
    "* `torch`: nome del pacchetto\n",
    "* `2.3.0`: versione del pacchetto\n",
    "* `cp311`: compatibilità con Python 3.11 (CPython)\n",
    "* `manylinux1_x86_64`: compilato per Linux 64-bit, compatibile con lo standard manylinux\n",
    "\n",
    "---\n",
    "\n",
    "## Perché le wheels sono fondamentali nei Dockerfile\n",
    "\n",
    "Durante la costruzione di un’immagine Docker (`docker build`), è preferibile che:\n",
    "\n",
    "1. La build sia veloce.\n",
    "2. Non siano richiesti compilatori o header system-level.\n",
    "3. L’immagine finale sia il più leggera possibile.\n",
    "\n",
    "Compilare pacchetti da sorgente (ad esempio PyTorch, Transformers, NumPy) dentro un container è lento e richiede l’installazione di tool di build.\n",
    "Le *wheels* risolvono questo problema perché possono essere precompilate in uno *stage di build* e poi riutilizzate nello *stage di runtime*.\n",
    "\n",
    "---\n",
    "\n",
    "## Esempio pratico con multi-stage build\n",
    "\n",
    "### Stage 1 – Builder\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN apt-get update && apt-get install -y build-essential git \\\n",
    " && pip install --upgrade pip wheel \\\n",
    " && pip wheel --no-deps --no-cache-dir -r requirements.txt -w /wheels\n",
    "```\n",
    "\n",
    "Questo comando crea una directory `/wheels` contenente le versioni precompilate di tutte le librerie specificate in `requirements.txt`.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```\n",
    "/wheels/\n",
    "├─ fastapi-0.110.0-py3-none-any.whl\n",
    "├─ uvicorn-0.30.0-py3-none-any.whl\n",
    "├─ numpy-1.26.4-cp311-cp311-manylinux_x86_64.whl\n",
    "└─ torch-2.3.0-cp311-cp311-manylinux_x86_64.whl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Stage 2 – Runtime\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /wheels /wheels\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-index --find-links=/wheels -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\",\"app:app\",\"--host\",\"0.0.0.0\",\"--port\",\"8080\"]\n",
    "```\n",
    "\n",
    "Questo secondo stage:\n",
    "\n",
    "* copia le wheels già compilate dal builder;\n",
    "* installa i pacchetti da quelle wheel senza accedere a PyPI;\n",
    "* non necessita di compilatori o strumenti di sviluppo.\n",
    "\n",
    "Il risultato è un container finale più leggero, veloce da costruire e più sicuro.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantaggi pratici dell’uso delle wheels\n",
    "\n",
    "| Aspetto                  | Vantaggio                                               |\n",
    "| ------------------------ | ------------------------------------------------------- |\n",
    "| Velocità di build        | Installazione istantanea da pacchetti precompilati      |\n",
    "| Stabilità                | Nessuna dipendenza da compilatori o librerie di sistema |\n",
    "| Dimensione dell’immagine | Meno tool di build → runtime più leggero                |\n",
    "| Sicurezza                | Nessun accesso esterno a PyPI in fase di build          |\n",
    "| Portabilità              | Stesse wheels riutilizzabili in ambienti diversi        |\n",
    "\n",
    "---\n",
    "\n",
    "## Come creare manualmente le wheels\n",
    "\n",
    "Puoi generare le wheels per un progetto o per una lista di dipendenze.\n",
    "\n",
    "Per un singolo progetto:\n",
    "\n",
    "```bash\n",
    "python setup.py bdist_wheel\n",
    "```\n",
    "\n",
    "Per tutte le dipendenze di `requirements.txt`:\n",
    "\n",
    "```bash\n",
    "pip wheel -r requirements.txt -w ./wheels\n",
    "```\n",
    "\n",
    "Questo crea la cartella `./wheels` che può essere riutilizzata per installazioni offline o rapide.\n",
    "\n",
    "---\n",
    "\n",
    "## Riassunto finale\n",
    "\n",
    "* Una **wheel (.whl)** è un pacchetto binario precompilato Python.\n",
    "* È più efficiente e veloce da installare rispetto al pacchetto sorgente.\n",
    "* Nei Dockerfile “da produzione”, le wheels vengono create in uno *stage builder* e poi installate nello *stage runtime*.\n",
    "* Questo approccio riduce drasticamente i tempi di build e rende l’immagine più leggera e stabile.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a033dae-b933-40f0-9cf5-fce1d3e26460",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Cos’è una “build in più step”\n",
    "\n",
    "Normalmente, un Dockerfile descrive **come costruire un’immagine**:\n",
    "cioè un ambiente con tutto ciò che serve per eseguire il tuo programma.\n",
    "\n",
    "Esempio semplice:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Questo funziona, ma c’è un problema:\n",
    "tutto quello che serve *durante la build* (come `pip`, compilatori, librerie di sviluppo, git, ecc.) rimane dentro l’immagine finale.\n",
    "\n",
    "Quindi l’immagine:\n",
    "\n",
    "* è più **pesante**,\n",
    "* contiene **strumenti non necessari all’esecuzione**,\n",
    "* può avere più **vulnerabilità**,\n",
    "* e rallenta la distribuzione.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Cosa si intende per “build in più step”\n",
    "\n",
    "Una **multi-stage build** significa dividere la costruzione in **più fasi (step)**, ognuna con un compito specifico.\n",
    "Alla fine, Docker tiene **solo l’ultimo step**, cioè il risultato “pulito” e pronto a essere eseguito.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* il **primo step** costruisce o prepara qualcosa (es. installa dipendenze, compila codice, genera pacchetti);\n",
    "* il **secondo step** copia solo ciò che serve dal primo;\n",
    "* gli step intermedi vengono scartati (quindi l’immagine finale resta leggera).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Esempio concreto\n",
    "\n",
    "Immagina un’app Python che ha molte librerie da installare (Transformers, FastAPI, NumPy, ecc.).\n",
    "Alcune di queste hanno componenti C/C++ e richiedono `gcc` per essere compilate.\n",
    "\n",
    "### Soluzione sbagliata (un solo step)\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "```\n",
    "\n",
    "Problema: il compilatore (`build-essential`) e git rimangono nell’immagine finale.\n",
    "Risultato: immagine grande e meno sicura.\n",
    "\n",
    "---\n",
    "\n",
    "### Soluzione corretta: multi-stage build\n",
    "\n",
    "```dockerfile\n",
    "# Step 1 - builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install --upgrade pip wheel\n",
    "RUN pip wheel --no-deps -r requirements.txt -w /wheels\n",
    "\n",
    "# Step 2 - runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /wheels /wheels\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-index --find-links=/wheels -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "```\n",
    "\n",
    "Vediamolo in parole semplici:\n",
    "\n",
    "1. **Nel primo step (“builder”)**\n",
    "\n",
    "   * Si installano gli strumenti pesanti (compilatori).\n",
    "   * Si scaricano e si “precompilano” tutte le librerie in formato `.whl` (wheel).\n",
    "\n",
    "2. **Nel secondo step (“runtime”)**\n",
    "\n",
    "   * Si parte da una nuova immagine pulita.\n",
    "   * Si copiano *solo* le wheel precompilate dal primo step.\n",
    "   * Si installano velocemente senza compilare nulla.\n",
    "   * Nessun compilatore o tool extra rimane nell’immagine.\n",
    "\n",
    "Alla fine, il risultato è:\n",
    "\n",
    "* un’immagine più leggera,\n",
    "* più veloce da costruire,\n",
    "* più sicura e portabile.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Come funziona tecnicamente\n",
    "\n",
    "Ogni volta che scrivi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "```\n",
    "\n",
    "Docker crea **uno stage** con il nome “builder”.\n",
    "\n",
    "Poi, quando scrivi:\n",
    "\n",
    "```dockerfile\n",
    "COPY --from=builder /wheels /wheels\n",
    "```\n",
    "\n",
    "Docker **copia solo quella cartella** dal builder allo stage successivo.\n",
    "\n",
    "Gli altri file, programmi e tool del builder non vengono copiati:\n",
    "vengono **eliminati completamente** al termine della build.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Vantaggi principali\n",
    "\n",
    "| Aspetto             | Senza multi-stage                | Con multi-stage                          |\n",
    "| ------------------- | -------------------------------- | ---------------------------------------- |\n",
    "| Dimensione immagine | Molto grande                     | Più leggera                              |\n",
    "| Sicurezza           | Contiene tool inutili (gcc, git) | Contiene solo runtime                    |\n",
    "| Tempo di build      | Lento                            | Più veloce (cache pip + precompilazione) |\n",
    "| Pulizia             | Tutto resta nel container        | Solo l’essenziale viene copiato          |\n",
    "| Deploy              | Più pesante e fragile            | Più stabile e rapido                     |\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Quando usarla\n",
    "\n",
    "Usa una multi-stage build in questi casi:\n",
    "\n",
    "* se l’app richiede **librerie complesse o compilate** (es. PyTorch, NumPy);\n",
    "* se vuoi **immagini leggere e sicure**;\n",
    "* se devi **riutilizzare build** in pipeline CI/CD;\n",
    "* se usi **linguaggi con transpiler o build step** (Python, Node.js, Go, ecc.).\n",
    "\n",
    "Nei progetti AI (CrewAI, LangChain, FastAPI, Qdrant), è sempre consigliata, perché:\n",
    "\n",
    "* molte librerie sono pesanti da compilare;\n",
    "* la cache pip migliora molto i tempi di rebuild;\n",
    "* l’immagine runtime deve essere il più snella possibile.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Come riconoscere uno “step”\n",
    "\n",
    "Ogni istruzione `FROM ... AS nome` apre un nuovo step.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "...  # step 1\n",
    "\n",
    "FROM python:3.11-slim AS runtime\n",
    "...  # step 2\n",
    "\n",
    "FROM nginx:alpine AS proxy\n",
    "...  # step 3\n",
    "```\n",
    "\n",
    "Solo **l’ultimo step** diventa l’immagine finale.\n",
    "Gli altri vengono usati solo come “fasi intermedie”.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Controllare gli step\n",
    "\n",
    "Puoi anche fermarti a uno step intermedio per vedere cosa contiene:\n",
    "\n",
    "```bash\n",
    "docker build --target builder -t myapp:builder .\n",
    "docker run -it myapp:builder bash\n",
    "```\n",
    "\n",
    "Serve per il debug o per verificare i file generati (es. le wheel in `/wheels`).\n",
    "\n",
    "---\n",
    "\n",
    "# 9. In sintesi\n",
    "\n",
    "* **Cos’è:** un modo per dividere la build in più fasi, ognuna con un compito specifico.\n",
    "* **Perché:** per costruire immagini più leggere, sicure e veloci.\n",
    "* **Come:** usando più istruzioni `FROM` e copiando solo ciò che serve dallo stage precedente.\n",
    "* **Risultato:** immagine finale pulita, con solo il codice e le librerie necessarie a eseguire l’applicazione.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaba191-ebe3-4617-a850-fe1f3b85edba",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Cos’è la cache in Docker\n",
    "\n",
    "Ogni volta che esegui:\n",
    "\n",
    "```bash\n",
    "docker build .\n",
    "```\n",
    "\n",
    "Docker **non ricostruisce tutto da zero**:\n",
    "memorizza (“cachizza”) i risultati delle istruzioni del Dockerfile per riutilizzarli in futuro.\n",
    "\n",
    "Ogni **istruzione** nel Dockerfile (`FROM`, `RUN`, `COPY`, ecc.) crea un **layer** nell’immagine.\n",
    "Un layer è come una fotografia dello stato del file system in quel momento.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Qui Docker crea i layer in questo ordine:\n",
    "\n",
    "1. Base image (`FROM`)\n",
    "2. Creazione cartella di lavoro (`WORKDIR`)\n",
    "3. Copia di `requirements.txt`\n",
    "4. Installazione delle dipendenze\n",
    "5. Copia del codice\n",
    "6. Comando finale\n",
    "\n",
    "Se ricostruisci l’immagine e **Docker capisce che nulla è cambiato** fino a un certo punto,\n",
    "riutilizza la cache dei layer precedenti e **ricostruisce solo quello che serve**.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Come Docker decide se usare la cache\n",
    "\n",
    "Docker controlla:\n",
    "\n",
    "* il **contenuto dei file copiati** (`COPY`, `ADD`),\n",
    "* i **comandi eseguiti** (`RUN`),\n",
    "* l’immagine base (`FROM`).\n",
    "\n",
    "Se trova una corrispondenza, riutilizza la cache.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* Cambi un file `.py` nel progetto → la cache si invalida **solo dopo** il `COPY . .`\n",
    "* Cambi `requirements.txt` → la cache si invalida già a metà build (perché cambia la fase `RUN pip install ...`).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Perché la cache è importante\n",
    "\n",
    "Senza cache, ogni build:\n",
    "\n",
    "* reinstallerebbe tutte le librerie da zero,\n",
    "* scaricherebbe ogni pacchetto ogni volta,\n",
    "* sarebbe lentissima.\n",
    "\n",
    "Con una cache corretta:\n",
    "\n",
    "* Docker riusa layer già costruiti,\n",
    "* le dipendenze si installano solo la prima volta,\n",
    "* il tempo di build si riduce da minuti a pochi secondi.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Come sfruttarla in modo efficace\n",
    "\n",
    "L’ordine delle istruzioni nel Dockerfile è **fondamentale**.\n",
    "Docker costruisce in sequenza, quindi se una riga cambia, **tutti i layer dopo** vengono ricostruiti.\n",
    "\n",
    "### Esempio sbagliato:\n",
    "\n",
    "```dockerfile\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "→ ogni volta che modifichi un file Python, anche il `pip install` viene rieseguito.\n",
    "\n",
    "### Esempio corretto:\n",
    "\n",
    "```dockerfile\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "→ se cambi solo il codice, la parte `pip install` resta in cache.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Cache locale: dove si trova\n",
    "\n",
    "Docker salva la cache sul tuo computer.\n",
    "La puoi vedere con:\n",
    "\n",
    "```bash\n",
    "docker image ls\n",
    "docker system df\n",
    "```\n",
    "\n",
    "Ogni immagine e layer rimane finché non lo elimini manualmente con:\n",
    "\n",
    "```bash\n",
    "docker system prune\n",
    "```\n",
    "\n",
    "oppure in modo più mirato:\n",
    "\n",
    "```bash\n",
    "docker builder prune\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Cache dei pacchetti (pip, apt, npm…)\n",
    "\n",
    "C’è un secondo tipo di cache: quella interna ai tool di installazione.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* `pip` salva i pacchetti in `~/.cache/pip`\n",
    "* `apt-get` salva i pacchetti in `/var/cache/apt`\n",
    "* `npm` salva i pacchetti in `~/.npm`\n",
    "\n",
    "Normalmente Docker **non conserva** queste cache tra build.\n",
    "Ma possiamo farlo — e questo è ciò che si intende con *cache mount*.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Cache mount (con BuildKit)\n",
    "\n",
    "**BuildKit** è la versione moderna del sistema di build di Docker.\n",
    "Permette di usare una cache “temporanea” che non gonfia l’immagine ma resta tra build successive.\n",
    "\n",
    "Per abilitarlo:\n",
    "\n",
    "```bash\n",
    "export DOCKER_BUILDKIT=1\n",
    "```\n",
    "\n",
    "Poi nel Dockerfile puoi scrivere:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Così:\n",
    "\n",
    "* la directory `/root/.cache/pip` viene riutilizzata tra build successive,\n",
    "* i pacchetti già scaricati non vengono riscaricati,\n",
    "* ma la cache **non viene copiata dentro l’immagine finale**.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Cache nel mondo reale (esempio con Python)\n",
    "\n",
    "Supponiamo di avere questo Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Cosa succede:\n",
    "\n",
    "1. Al primo build, scarica tutto da zero.\n",
    "2. Al secondo build, se `requirements.txt` non è cambiato, la cache pip viene riutilizzata → molto più veloce.\n",
    "3. Se cambi solo `main.py`, la cache `pip install` rimane valida.\n",
    "\n",
    "---\n",
    "\n",
    "# 9. `.dockerignore`: il primo livello di cache “intelligente”\n",
    "\n",
    "Quando Docker costruisce un’immagine, **invia tutto il contenuto della cartella** al daemon Docker.\n",
    "Se dentro ci sono file pesanti (dataset, modelli, `venv`, ecc.),\n",
    "la build diventa più lenta e invalida la cache inutilmente.\n",
    "\n",
    "Crea un file `.dockerignore` per escluderli:\n",
    "\n",
    "```\n",
    ".git\n",
    "__pycache__/\n",
    "venv/\n",
    ".env\n",
    "data/\n",
    "models/\n",
    "```\n",
    "\n",
    "Questo non solo velocizza la build, ma impedisce a Docker di invalidare i layer quando cambiano file irrilevanti.\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Cache su più macchine (CI/CD)\n",
    "\n",
    "Se costruisci l’immagine su un server remoto (es. GitHub Actions),\n",
    "puoi “spingere” e “tirare” la cache da un registry.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker buildx build \\\n",
    "  --cache-to=type=inline \\\n",
    "  --cache-from=type=inline \\\n",
    "  -t myimage:latest .\n",
    "```\n",
    "\n",
    "In questo modo, anche la pipeline remota riusa la cache creata in locale.\n",
    "\n",
    "---\n",
    "\n",
    "# 11. Quando la cache non serve (e va disattivata)\n",
    "\n",
    "A volte è meglio forzare una build “pulita”:\n",
    "\n",
    "```bash\n",
    "docker build --no-cache -t myimage .\n",
    "```\n",
    "\n",
    "Serve quando:\n",
    "\n",
    "* una dipendenza esterna è cambiata,\n",
    "* un layer è corrotto,\n",
    "* o vuoi testare il tempo di una build da zero.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. Buone pratiche generali\n",
    "\n",
    "| Cosa fare                                                        | Perché                                        |\n",
    "| ---------------------------------------------------------------- | --------------------------------------------- |\n",
    "| Copiare `requirements.txt` prima del codice                      | Mantiene in cache `pip install`               |\n",
    "| Abilitare BuildKit                                               | Usa cache pip e apt tra build                 |\n",
    "| Usare `.dockerignore`                                            | Evita cache invalidata da file inutili        |\n",
    "| Non cancellare cache utile (`docker system prune`) troppo spesso | Rallenta build successive                     |\n",
    "| Usare versioni precise nei requirements                          | Evita invalidazioni casuali                   |\n",
    "| Montare directory cache (`--mount=type=cache`)                   | Evita download ripetuti                       |\n",
    "| Usare multi-stage build                                          | Separa build e runtime, cache più prevedibile |\n",
    "\n",
    "---\n",
    "\n",
    "# 13. Riepilogo visivo\n",
    "\n",
    "| Scenario                           | Cache usata                    | Tempo build  |\n",
    "| ---------------------------------- | ------------------------------ | ------------ |\n",
    "| Primo build                        | Nessuna cache                  | Lento        |\n",
    "| Secondo build, stessi file         | Cache layer Docker + cache pip | Molto veloce |\n",
    "| Modifico requirements.txt          | Cache invalidata da metà build | Medio        |\n",
    "| Modifico solo codice               | Solo ultimi layer ricostruiti  | Veloce       |\n",
    "| Cache disattivata con `--no-cache` | Nessuna                        | Lento        |\n",
    "\n",
    "---\n",
    "\n",
    "# 14. In breve\n",
    "\n",
    "* **Docker salva i risultati di ogni istruzione come “layer”**.\n",
    "* **Se i file o i comandi non cambiano**, quei layer vengono riutilizzati.\n",
    "* **L’ordine delle istruzioni** è la chiave per sfruttare la cache.\n",
    "* **BuildKit** aggiunge una cache “temporanea” per pip, apt e altri gestori di pacchetti.\n",
    "* **.dockerignore** evita di far ricostruire inutilmente i layer.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c1b86-c08e-4548-9447-f3997ebbff05",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Il concetto di “root” nei container\n",
    "\n",
    "Quando un container Docker viene avviato, **di default** usa l’utente `root`.\n",
    "\n",
    "Nel mondo Linux, `root` è l’amministratore del sistema, quindi può:\n",
    "\n",
    "* modificare o cancellare qualsiasi file;\n",
    "* installare pacchetti;\n",
    "* eseguire comandi critici;\n",
    "* accedere a tutto il file system.\n",
    "\n",
    "Questo significa che, se un’app dentro un container viene compromessa (ad esempio tramite una vulnerabilità o una libreria malevola), un utente malintenzionato potrebbe:\n",
    "\n",
    "* ottenere accesso **completo al container**;\n",
    "* e in certi casi anche al **sistema host** (soprattutto se ci sono volumi montati o permessi sbagliati).\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Perché evitare l’utente root\n",
    "\n",
    "In un ambiente di produzione, eseguire i container come root **è una cattiva pratica** per vari motivi:\n",
    "\n",
    "| Rischio           | Descrizione                                                                         |\n",
    "| ----------------- | ----------------------------------------------------------------------------------- |\n",
    "| **Sicurezza**     | un exploit nel codice può compromettere il sistema host                             |\n",
    "| **Isolamento**    | root nel container può scrivere in volumi o directory condivise                     |\n",
    "| **Tracciabilità** | difficile distinguere le operazioni del container da quelle di sistema              |\n",
    "| **Compliance**    | molti standard di sicurezza (es. OWASP, CIS Docker Benchmark) vietano l’uso di root |\n",
    "\n",
    "Per questo motivo, è buona norma **creare un utente dedicato e con permessi limitati** per eseguire l’applicazione.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Come si crea un utente non-root nel Dockerfile\n",
    "\n",
    "Il modo più semplice è usare il comando `useradd` o `adduser` durante la build.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# 1. Crea un utente e una home directory\n",
    "RUN useradd -m -u 10001 appuser\n",
    "\n",
    "# 2. Imposta la cartella di lavoro\n",
    "WORKDIR /app\n",
    "\n",
    "# 3. Copia i file e assegna la proprietà all’utente creato\n",
    "COPY . .\n",
    "RUN chown -R appuser:appuser /app\n",
    "\n",
    "# 4. Passa all’utente non-root\n",
    "USER appuser\n",
    "\n",
    "# 5. Esegui il comando finale\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Vediamo cosa fa, riga per riga:\n",
    "\n",
    "* `useradd -m -u 10001 appuser`\n",
    "  Crea un utente chiamato `appuser` con ID `10001` (gli ID < 1000 sono solitamente riservati al sistema).\n",
    "\n",
    "* `WORKDIR /app`\n",
    "  Imposta la directory di lavoro del container.\n",
    "\n",
    "* `COPY . .`\n",
    "  Copia i file dell’app.\n",
    "\n",
    "* `chown -R appuser:appuser /app`\n",
    "  Cambia il proprietario della cartella `/app`, in modo che l’utente `appuser` possa leggere/scrivere.\n",
    "\n",
    "* `USER appuser`\n",
    "  Indica a Docker che **tutti i comandi successivi** verranno eseguiti come `appuser`.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Come verificare che il container non sia root\n",
    "\n",
    "Dopo aver creato l’immagine, puoi verificarlo con:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm nome_immagine whoami\n",
    "```\n",
    "\n",
    "Output previsto:\n",
    "\n",
    "```\n",
    "appuser\n",
    "```\n",
    "\n",
    "Oppure controllando l’ID utente:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm nome_immagine id\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "uid=10001(appuser) gid=10001(appuser) groups=10001(appuser)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Esempio reale in un’app AI (FastAPI o CrewAI)\n",
    "\n",
    "Ecco un esempio più realistico, che unisce sicurezza e praticità:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Installazione dipendenze\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Creazione utente non-root\n",
    "RUN useradd -m -u 10001 appuser\n",
    "\n",
    "# Copia codice e assegna permessi\n",
    "COPY . .\n",
    "RUN chown -R appuser:appuser /app\n",
    "\n",
    "# Passa all’utente non-root\n",
    "USER appuser\n",
    "\n",
    "# Porta e avvio app\n",
    "EXPOSE 8080\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "```\n",
    "\n",
    "Risultato:\n",
    "\n",
    "* l’app gira come `appuser`;\n",
    "* non ha accesso a file di sistema;\n",
    "* anche se venisse compromessa, i danni resterebbero confinati al container.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Buone pratiche aggiuntive\n",
    "\n",
    "### 6.1 Imposta i permessi prima possibile\n",
    "\n",
    "Meglio eseguire `chown` nel builder, così la copia nel runtime è già corretta:\n",
    "\n",
    "```dockerfile\n",
    "COPY --chown=appuser:appuser . .\n",
    "```\n",
    "\n",
    "### 6.2 Non eseguire comandi privilegiati dopo `USER`\n",
    "\n",
    "Dopo `USER appuser`, non puoi più installare pacchetti o modificare file di sistema.\n",
    "Quindi crea l’utente **alla fine della build**, subito prima del `CMD`.\n",
    "\n",
    "### 6.3 Evita di lavorare nella home root\n",
    "\n",
    "Non salvare log o dati in `/root` o `/tmp` se non servono.\n",
    "Usa `/app`, `/data`, o una directory dedicata con permessi corretti.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Quando serve root (e come gestirlo)\n",
    "\n",
    "In alcuni casi, è necessario usare root temporaneamente, ad esempio:\n",
    "\n",
    "* per installare pacchetti con `apt-get`;\n",
    "* per compilare estensioni C;\n",
    "* per configurare permessi speciali.\n",
    "\n",
    "Puoi farlo solo negli stage iniziali, e poi tornare non-root nello stage finale.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "# Stage 1 (builder)\n",
    "FROM python:3.11-slim AS builder\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Stage 2 (runtime)\n",
    "FROM python:3.11-slim\n",
    "RUN useradd -m -u 10001 appuser\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build /app\n",
    "USER appuser\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "In questo modo, il codice viene costruito come root (dove serve),\n",
    "ma **eseguito come utente non-root** nell’immagine finale.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Controllare gli utenti attivi nel container\n",
    "\n",
    "Puoi ispezionare l’immagine:\n",
    "\n",
    "```bash\n",
    "docker run -it nome_immagine bash\n",
    "cat /etc/passwd\n",
    "```\n",
    "\n",
    "Vedrai un elenco di utenti, tra cui il tuo:\n",
    "\n",
    "```\n",
    "appuser:x:10001:10001::/home/appuser:/bin/bash\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Eseguire container temporaneamente come root\n",
    "\n",
    "Se devi solo “entrare” nel container per debug e non vuoi modificare il Dockerfile:\n",
    "\n",
    "```bash\n",
    "docker run -it --user root nome_immagine bash\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Riepilogo concettuale\n",
    "\n",
    "| Punto chiave           | Spiegazione                                                    |\n",
    "| ---------------------- | -------------------------------------------------------------- |\n",
    "| **Root**               | È l’amministratore del sistema, ha accesso a tutto             |\n",
    "| **Problema**           | Se un’app viene compromessa, anche l’host è a rischio          |\n",
    "| **Soluzione**          | Creare un utente limitato e passare a lui con `USER`           |\n",
    "| **Posizione corretta** | Dopo aver installato pacchetti e copiato il codice             |\n",
    "| **Beneficio**          | Maggiore sicurezza, isolamento e conformità alle best practice |\n",
    "\n",
    "---\n",
    "\n",
    "# 11. In sintesi\n",
    "\n",
    "* Docker, di default, esegue tutto come **root**.\n",
    "* Creare e usare un **utente non-root** è una pratica essenziale per la sicurezza.\n",
    "* Serve a **limitare i danni** in caso di exploit o errore nel codice.\n",
    "* Si implementa con poche righe (`useradd`, `chown`, `USER`).\n",
    "* Nei progetti AI, dove si usano spesso file, dataset o modelli, riduce il rischio di modifiche indesiderate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550916c-5689-47ce-8348-532e059a415e",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Cos’è un Healthcheck\n",
    "\n",
    "Un **healthcheck** è un meccanismo che permette a Docker di **verificare automaticamente se un container è “sano”** (cioè sta funzionando come previsto) oppure no.\n",
    "\n",
    "In pratica, Docker non si limita a vedere se il container “è in esecuzione”, ma controlla periodicamente se:\n",
    "\n",
    "* il servizio risponde su una porta (es. HTTP 8080);\n",
    "* un processo è ancora attivo;\n",
    "* o una certa condizione è vera (es. un file esiste o un comando restituisce `0`).\n",
    "\n",
    "Se il test fallisce, Docker **segnala che il container è “unhealthy”**.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Perché serve\n",
    "\n",
    "Senza un healthcheck, Docker considera il container “up” finché il processo principale non termina.\n",
    "Ma in molti casi un’app può essere “in esecuzione” ma non funzionare (esempio: un server FastAPI crasha internamente ma non chiude il processo).\n",
    "\n",
    "L’healthcheck serve per:\n",
    "\n",
    "* far capire a Docker (e a Docker Compose, Kubernetes, Swarm, ecc.) se il container è effettivamente funzionante;\n",
    "* permettere a sistemi esterni (come Compose o orchestratori) di **riavviare automaticamente** il servizio se non risponde;\n",
    "* sincronizzare la partenza di altri container che dipendono da lui (`depends_on` con `condition: service_healthy`).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Come si definisce nel Dockerfile\n",
    "\n",
    "La sintassi è:\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK [OPTIONS] CMD comando_da_eseguire || exit 1\n",
    "```\n",
    "\n",
    "Le opzioni principali sono:\n",
    "\n",
    "* `--interval=30s` → ogni quanto tempo eseguire il test (default 30s)\n",
    "* `--timeout=3s` → tempo massimo per considerare il test riuscito\n",
    "* `--start-period=10s` → tempo di “grace” dopo l’avvio, prima di iniziare a testare\n",
    "* `--retries=3` → quante volte deve fallire prima di marcare “unhealthy”\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Esempio base: server FastAPI o CrewAI\n",
    "\n",
    "Se il tuo container espone un’API HTTP (es. `http://localhost:8080/health`):\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\n",
    "  CMD curl -fsS http://localhost:8080/health || exit 1\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* `curl -fsS` tenta una richiesta HTTP silenziosa (fallisce se non riceve risposta);\n",
    "* `|| exit 1` fa fallire l’healthcheck se `curl` non riesce a connettersi;\n",
    "* dopo 3 tentativi falliti, Docker segna il container come **unhealthy**.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Esempio con Streamlit o server su porta 8501\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK --interval=20s --timeout=3s --retries=3 \\\n",
    "  CMD wget --spider -q http://localhost:8501/_stcore/health || exit 1\n",
    "```\n",
    "\n",
    "Qui usiamo `wget` invece di `curl`.\n",
    "L’opzione `--spider -q` fa solo un “ping” HTTP senza scaricare il contenuto.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Esempio per container Python senza HTTP (task AI, script, ecc.)\n",
    "\n",
    "Se il container non espone una porta HTTP ma deve eseguire periodicamente un file Python, puoi usare:\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK --interval=1m CMD pgrep -f main.py > /dev/null || exit 1\n",
    "```\n",
    "\n",
    "* `pgrep -f main.py` controlla che il processo Python sia attivo;\n",
    "* se non trova nulla, l’healthcheck fallisce.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Comportamento in runtime\n",
    "\n",
    "Puoi verificare lo stato di salute del container con:\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "E troverai una colonna “STATUS” come:\n",
    "\n",
    "```\n",
    "Up 2 minutes (healthy)\n",
    "Up 1 minute (starting)\n",
    "Up 3 minutes (unhealthy)\n",
    "```\n",
    "\n",
    "Oppure con:\n",
    "\n",
    "```bash\n",
    "docker inspect nome_container --format='{{json .State.Health}}' | jq\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Come Docker interpreta gli stati\n",
    "\n",
    "| Stato         | Significato                                                              |\n",
    "| ------------- | ------------------------------------------------------------------------ |\n",
    "| **starting**  | Docker ha appena avviato il container, healthcheck non ancora effettuato |\n",
    "| **healthy**   | Il test è passato                                                        |\n",
    "| **unhealthy** | Il test è fallito per più volte di seguito                               |\n",
    "| **none**      | Nessun healthcheck definito                                              |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94cd38-6873-4341-9899-598e9ff2b181",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Il problema: i segreti nella build\n",
    "\n",
    "Spesso, durante la costruzione di un’immagine Docker, dobbiamo accedere a risorse private, ad esempio:\n",
    "\n",
    "* repository Git privati,\n",
    "* pacchetti Python privati (su un index interno o su Azure),\n",
    "* API key o token temporanei.\n",
    "\n",
    "Molti principianti commettono un errore grave:\n",
    "**scrivono queste credenziali direttamente nel Dockerfile**, ad esempio:\n",
    "\n",
    "```dockerfile\n",
    "RUN pip install --extra-index-url \"https://myuser:mytoken@pypi.example.com/simple\" mypackage\n",
    "```\n",
    "\n",
    "Questo è pericoloso perché:\n",
    "\n",
    "* le credenziali vengono salvate **nei layer dell’immagine**;\n",
    "* chiunque scarichi l’immagine può leggerle con:\n",
    "\n",
    "  ```bash\n",
    "  docker history --no-trunc nome_immagine\n",
    "  ```\n",
    "* anche se cancelli il file o sovrascrivi la variabile, rimane nei layer precedenti (immutabili).\n",
    "\n",
    "---\n",
    "\n",
    "# 2. La soluzione moderna: BuildKit\n",
    "\n",
    "**BuildKit** è un sistema di build avanzato di Docker, sviluppato da Moby Project, che sostituisce il vecchio builder tradizionale.\n",
    "\n",
    "Offre molte funzionalità, tra cui:\n",
    "\n",
    "* parallelizzazione dei layer;\n",
    "* caching più efficiente;\n",
    "* supporto a **mount temporanei** (`--mount=type=cache` e `--mount=type=secret`);\n",
    "* esportazione e importazione di cache tra macchine;\n",
    "* build deterministiche e sicure.\n",
    "\n",
    "Per abilitarlo:\n",
    "\n",
    "```bash\n",
    "export DOCKER_BUILDKIT=1\n",
    "```\n",
    "\n",
    "oppure scrivendo in `/etc/docker/daemon.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"features\": {\n",
    "    \"buildkit\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Come funzionano i segreti in BuildKit\n",
    "\n",
    "L’idea è semplice:\n",
    "\n",
    "> invece di scrivere la chiave nel Dockerfile o copiare un file `.env`,\n",
    "> la fornisci **solo in fase di build**, come un file temporaneo accessibile al comando `RUN`.\n",
    "\n",
    "Docker la monta in `/run/secrets/<id>` e poi la rimuove automaticamente al termine di quello specifico step.\n",
    "Non rimane in nessun layer, quindi non è mai visibile nell’immagine finale.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Sintassi\n",
    "\n",
    "Nel Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "RUN --mount=type=secret,id=<nome_id> \\\n",
    "    <comando che usa il segreto>\n",
    "```\n",
    "\n",
    "Durante la build:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build \\\n",
    "  --secret id=<nome_id>,src=<path_al_file> .\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Esempio pratico: chiave Azure per CrewAI\n",
    "\n",
    "Supponiamo che il tuo progetto AI debba scaricare modelli o configurazioni da un’area privata di Azure, usando una chiave salvata in:\n",
    "\n",
    "```\n",
    ".secrets/azure_key.txt\n",
    "```\n",
    "\n",
    "Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "\n",
    "# Usa la chiave solo in fase di build\n",
    "RUN --mount=type=secret,id=azure_key \\\n",
    "    export AZURE_KEY=$(cat /run/secrets/azure_key) \\\n",
    " && python setup.py install\n",
    "```\n",
    "\n",
    "Comando di build:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build \\\n",
    "  --secret id=azure_key,src=.secrets/azure_key.txt \\\n",
    "  -t crewai-secure .\n",
    "```\n",
    "\n",
    "Durante questo comando:\n",
    "\n",
    "* la chiave viene letta solo da `/run/secrets/azure_key`;\n",
    "* è disponibile solo mentre viene eseguito lo `RUN`;\n",
    "* viene distrutta subito dopo;\n",
    "* non resta nei layer, né nei log, né nella cache.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Verifica: non appare nella cronologia\n",
    "\n",
    "Dopo la build, se provi:\n",
    "\n",
    "```bash\n",
    "docker history crewai-secure\n",
    "```\n",
    "\n",
    "non vedrai mai la chiave in nessun layer.\n",
    "Questo è il principale vantaggio rispetto all’uso di variabili d’ambiente.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Esempio con più segreti\n",
    "\n",
    "Puoi montare più segreti contemporaneamente:\n",
    "\n",
    "```dockerfile\n",
    "RUN --mount=type=secret,id=azure_key \\\n",
    "    --mount=type=secret,id=hf_token \\\n",
    "    export AZURE_KEY=$(cat /run/secrets/azure_key) \\\n",
    "    && export HF_TOKEN=$(cat /run/secrets/hf_token) \\\n",
    "    && python download_model.py\n",
    "```\n",
    "\n",
    "E costruisci così:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build \\\n",
    "  --secret id=azure_key,src=.secrets/azure_key.txt \\\n",
    "  --secret id=hf_token,src=.secrets/huggingface_token.txt \\\n",
    "  -t ai-secure .\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Esempio con repository Git privato\n",
    "\n",
    "Se il tuo progetto clona un repo privato:\n",
    "\n",
    "```dockerfile\n",
    "RUN --mount=type=ssh git clone git@github.com:myorg/private-repo.git\n",
    "```\n",
    "\n",
    "Build:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build --ssh default .\n",
    "```\n",
    "\n",
    "In questo caso, BuildKit usa la tua chiave SSH locale (es. `~/.ssh/id_rsa`) in modo temporaneo e sicuro.\n",
    "Niente finisce nell’immagine finale.\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Dove si trovano i file montati\n",
    "\n",
    "All’interno dello step di build, i file dei segreti si trovano in:\n",
    "\n",
    "```\n",
    "/run/secrets/<id>\n",
    "```\n",
    "\n",
    "e vengono eliminati automaticamente alla fine di quello specifico `RUN`.\n",
    "Non sono visibili da altri comandi, né da altri container.\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Confronto: `--build-arg` vs `--secret`\n",
    "\n",
    "| Metodo                | Sicuro | Persistente nei layer  | Facile da usare   |\n",
    "| --------------------- | ------ | ---------------------- | ----------------- |\n",
    "| `--build-arg`         | ❌ No   | ✅ Sì (resta nei layer) | ✅ Semplice        |\n",
    "| Variabile `ENV`       | ❌ No   | ✅ Sì                   | ✅ Semplice        |\n",
    "| `--mount=type=secret` | ✅ Sì   | ❌ No                   | 🔸 Serve BuildKit |\n",
    "\n",
    "Conclusione: usa `--secret` per chiavi, token o credenziali sensibili;\n",
    "usa `--build-arg` solo per valori pubblici o non critici.\n",
    "\n",
    "---\n",
    "\n",
    "# 11. Applicazioni pratiche in progetti AI\n",
    "\n",
    "Ecco alcuni casi reali in cui questo approccio è utile:\n",
    "\n",
    "* **CrewAI o LangChain**: per fornire `AZURE_OPENAI_API_KEY` senza scriverla nel Dockerfile.\n",
    "* **Qdrant o Pinecone privati**: per passare token API in fase di setup o popolamento iniziale.\n",
    "* **HuggingFace**: per scaricare modelli privati (`HF_TOKEN`).\n",
    "* **Repo Git privati**: clonati tramite `--mount=type=ssh`.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. Buone pratiche\n",
    "\n",
    "1. **Mantieni tutti i segreti** in una cartella separata (es. `.secrets/`) esclusa dal `.dockerignore`.\n",
    "2. **Non usare `ARG` o `ENV` per chiavi sensibili.**\n",
    "3. **Usa sempre BuildKit** per i secret mounts.\n",
    "4. **Non scrivere mai i segreti nei log** o nei comandi con `echo`.\n",
    "5. **Dai nomi chiari ai secret id** (`azure_key`, `hf_token`, `pypi_auth`, ecc.).\n",
    "6. **Non copiare i file dei segreti nel container.**\n",
    "7. **Gestisci permessi stretti sui file dei segreti** (es. `chmod 600 .secrets/*`).\n",
    "\n",
    "---\n",
    "\n",
    "# 13. In sintesi\n",
    "\n",
    "| Concetto                | Descrizione                                                                |\n",
    "| ----------------------- | -------------------------------------------------------------------------- |\n",
    "| **Problema**            | Le chiavi scritte nel Dockerfile finiscono nei layer e restano accessibili |\n",
    "| **Soluzione**           | Usare BuildKit con `--mount=type=secret`                                   |\n",
    "| **Percorso temporaneo** | `/run/secrets/<id>`                                                        |\n",
    "| **Sicurezza**           | Il file è visibile solo durante il comando `RUN`, poi viene rimosso        |\n",
    "| **Uso tipico**          | Token Azure, chiavi API, repo privati, credenziali PyPI                    |\n",
    "| **Vantaggio**           | Nessuna informazione sensibile resta nell’immagine finale                  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c66fd-55c0-49ab-9efc-6a91518c3bc9",
   "metadata": {},
   "source": [
    "# **3.1 – Introduzione a Docker Compose per AI stacks**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Perché esiste Docker Compose**\n",
    "\n",
    "Quando lavori con Docker, ogni container è **isolato e indipendente**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* Un container ospita il **backend FastAPI** (CrewAI).\n",
    "* Un altro container ospita **Qdrant**, il database vettoriale.\n",
    "* Un altro ancora la **UI Streamlit**.\n",
    "\n",
    "Con `docker run`, dovresti avviarli tutti **a mano**, collegarli a una **rete**, assegnare **porte**, gestire **volumi**, variabili, dipendenze, e ricordarti tutti i parametri ogni volta.\n",
    "\n",
    "Esempio di quanto diventa scomodo:\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "\n",
    "docker run -d --name qdrant \\\n",
    "  --network ai_net \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "\n",
    "docker run -d --name backend \\\n",
    "  --network ai_net \\\n",
    "  -p 8080:8080 \\\n",
    "  -e QDRANT_HOST=qdrant \\\n",
    "  -e QDRANT_PORT=6333 \\\n",
    "  myorg/crewai-backend:latest\n",
    "\n",
    "docker run -d --name ui \\\n",
    "  --network ai_net \\\n",
    "  -p 8501:8501 \\\n",
    "  -e API_BASE_URL=http://backend:8080 \\\n",
    "  myorg/streamlit-ui:latest\n",
    "```\n",
    "\n",
    "Funziona, ma è **lungo, fragile e ripetitivo**.\n",
    "Serve un modo per **descrivere tutto questo in un solo file**, leggibile e versionabile.\n",
    "Quel file è **`docker-compose.yml`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cos’è Docker Compose**\n",
    "\n",
    "Docker Compose è uno **strumento di orchestrazione locale**.\n",
    "Serve per **definire e gestire più container come un’unica applicazione**.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* Scrivi **tutta la configurazione** (immagini, porte, variabili, volumi, reti, dipendenze)\n",
    "* in un file YAML chiamato `docker-compose.yml`\n",
    "* e poi avvii tutto con **un solo comando**:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Docker Compose:\n",
    "\n",
    "1. Crea automaticamente la rete interna tra i servizi.\n",
    "2. Crea i volumi definiti nel file.\n",
    "3. Costruisce le immagini se hai indicato `build:`.\n",
    "4. Lancia i container nell’ordine giusto (`depends_on`).\n",
    "5. Permette di spegnere tutto con un solo `docker compose down`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Struttura logica di un file `docker-compose.yml`**\n",
    "\n",
    "Un file Compose segue questa **struttura ad albero**:\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"       # (opzionale)\n",
    "services:            # i container dell'applicazione\n",
    "  <nome_servizio>:\n",
    "    image: ...       # oppure build: ...\n",
    "    ports:\n",
    "    environment:\n",
    "    volumes:\n",
    "    depends_on:\n",
    "volumes:              # volumi persistenti\n",
    "networks:             # (opzionale) reti personalizzate\n",
    "```\n",
    "\n",
    "Ogni **servizio** rappresenta un container.\n",
    "Ogni container può avere:\n",
    "\n",
    "* variabili d’ambiente,\n",
    "* porte esposte,\n",
    "* volumi da montare,\n",
    "* dipendenze da altri servizi.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Esempio reale per uno stack AI**\n",
    "\n",
    "Immagina di avere un progetto con:\n",
    "\n",
    "* **CrewAI backend** (FastAPI),\n",
    "* **Qdrant** (vector DB),\n",
    "* **Streamlit UI**.\n",
    "\n",
    "Ecco come lo descriveresti:\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    ports:\n",
    "      - \"6333:6333\"\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "      interval: 10s\n",
    "      timeout: 3s\n",
    "      retries: 5\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    environment:\n",
    "      - QDRANT_HOST=qdrant\n",
    "      - QDRANT_PORT=6333\n",
    "    volumes:\n",
    "      - ./config:/app/config:ro\n",
    "      - ./models:/root/.cache/huggingface\n",
    "    depends_on:\n",
    "      qdrant:\n",
    "        condition: service_healthy\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    environment:\n",
    "      - API_BASE_URL=http://backend:8080\n",
    "    depends_on:\n",
    "      - backend\n",
    "\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Spiegazione riga per riga**\n",
    "\n",
    "### 🔹 `version: \"3.9\"`\n",
    "\n",
    "Serve per indicare la versione dello schema Compose.\n",
    "Nelle versioni recenti è **opzionale**: Compose la riconosce automaticamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `services:`\n",
    "\n",
    "È la sezione principale.\n",
    "Ogni chiave al suo interno rappresenta un container (un servizio indipendente).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `qdrant:`\n",
    "\n",
    "Il nome del servizio.\n",
    "Diventa anche **hostname interno**: il backend potrà connettersi a `http://qdrant:6333`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `image: qdrant/qdrant:v1.10.0`\n",
    "\n",
    "Specifica quale immagine Docker usare.\n",
    "Può essere una:\n",
    "\n",
    "* immagine pubblica (`python:3.11`, `qdrant/qdrant`)\n",
    "* immagine privata (`myorg/backend:latest`)\n",
    "* o una da costruire localmente con `build:`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `build: ./backend`\n",
    "\n",
    "Indica che Compose deve costruire l’immagine a partire dal Dockerfile nella cartella `backend/`.\n",
    "\n",
    "Se hai già pubblicato la tua immagine (es. su Docker Hub o un registry interno), puoi usare:\n",
    "\n",
    "```yaml\n",
    "image: myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `ports:`\n",
    "\n",
    "Serve per **mappare** le porte del container verso l’host.\n",
    "\n",
    "```yaml\n",
    "ports:\n",
    "  - \"8080:8080\"  # (host:container)\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "`localhost:8080` → porta 8080 dentro il container backend.\n",
    "Puoi aprire la tua UI su `localhost:8501` o le API su `localhost:8080`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `environment:`\n",
    "\n",
    "Definisce variabili d’ambiente dentro il container.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "environment:\n",
    "  - QDRANT_HOST=qdrant\n",
    "  - QDRANT_PORT=6333\n",
    "```\n",
    "\n",
    "Nel codice Python:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.getenv(\"QDRANT_HOST\")  # => \"qdrant\"\n",
    "```\n",
    "\n",
    "Puoi anche leggerle da un file `.env` esterno (Compose lo supporta nativamente).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `volumes:`\n",
    "\n",
    "Serve per **montare directory persistenti** o **cartelle locali** nel container.\n",
    "\n",
    "Tipi di volume:\n",
    "\n",
    "* **Bind mount**: collega una cartella locale.\n",
    "\n",
    "  ```yaml\n",
    "  - ./config:/app/config:ro\n",
    "  ```\n",
    "\n",
    "  → leggi i file YAML di CrewAI dal tuo computer (solo lettura).\n",
    "\n",
    "* **Volume gestito da Docker**:\n",
    "\n",
    "  ```yaml\n",
    "  - qdrant_data:/qdrant/storage\n",
    "  ```\n",
    "\n",
    "  → storage persistente mantenuto da Docker (non sparisce a ogni `down`).\n",
    "\n",
    "La sezione finale:\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "crea il volume se non esiste.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `depends_on:`\n",
    "\n",
    "Definisce le **dipendenze di avvio**.\n",
    "Docker avvia prima i servizi da cui dipendi.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "depends_on:\n",
    "  qdrant:\n",
    "    condition: service_healthy\n",
    "```\n",
    "\n",
    "→ il backend parte **solo quando Qdrant risponde al suo healthcheck**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `healthcheck:`\n",
    "\n",
    "Serve per dire a Docker come verificare che un servizio sia “vivo”.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "healthcheck:\n",
    "  test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "  interval: 10s\n",
    "  timeout: 3s\n",
    "  retries: 5\n",
    "```\n",
    "\n",
    "Docker controlla Qdrant ogni 10 secondi e aggiorna il suo stato interno (healthy/unhealthy).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `volumes:` (sezione finale)\n",
    "\n",
    "Qui definisci **tutti i volumi gestiti da Docker**.\n",
    "Ogni voce è un volume persistente.\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "Serve per mantenere i dati anche dopo un `docker compose down`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Come funziona la rete in Compose**\n",
    "\n",
    "Compose crea automaticamente **una rete privata** per tutti i servizi del file.\n",
    "I container si vedono per **nome del servizio**, come se fosse un DNS.\n",
    "\n",
    "| Servizio | Nome DNS interno | Porta interna |\n",
    "| -------- | ---------------- | ------------- |\n",
    "| qdrant   | `qdrant`         | 6333          |\n",
    "| backend  | `backend`        | 8080          |\n",
    "| ui       | `ui`             | 8501          |\n",
    "\n",
    "Quindi nel backend puoi scrivere:\n",
    "\n",
    "```python\n",
    "client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "```\n",
    "\n",
    "e non serve l’IP.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Comandi principali**\n",
    "\n",
    "| Comando                            | Descrizione                         |\n",
    "| ---------------------------------- | ----------------------------------- |\n",
    "| `docker compose up -d`             | avvia tutti i servizi in background |\n",
    "| `docker compose ps`                | mostra i container attivi           |\n",
    "| `docker compose logs -f backend`   | visualizza i log del backend        |\n",
    "| `docker compose exec backend bash` | entra nel container backend         |\n",
    "| `docker compose down`              | ferma e rimuove tutto               |\n",
    "| `docker compose build backend`     | ricostruisce solo il backend        |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Benefici concreti per progetti AI**\n",
    "\n",
    "| Problema                      | Soluzione con Compose                           |\n",
    "| ----------------------------- | ----------------------------------------------- |\n",
    "| Setup manuale lungo           | Un solo comando `docker compose up`             |\n",
    "| Gestione reti e nomi          | DNS interno automatico (`backend`, `qdrant`)    |\n",
    "| Dati persi a ogni restart     | Volumi persistenti gestiti                      |\n",
    "| Avvio non sincronizzato       | `depends_on` + `healthcheck`                    |\n",
    "| Ambiente locale riproducibile | Tutto descritto in YAML, condivisibile nel repo |\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizio pratico**\n",
    "\n",
    "1. Crea la struttura:\n",
    "\n",
    "   ```\n",
    "   project/\n",
    "   ├─ backend/ (con Dockerfile e app.py)\n",
    "   ├─ ui/ (Streamlit)\n",
    "   ├─ docker-compose.yml\n",
    "   └─ config/\n",
    "   ```\n",
    "2. Copia il file Compose di esempio.\n",
    "3. Avvia:\n",
    "\n",
    "   ```bash\n",
    "   docker compose up -d\n",
    "   ```\n",
    "4. Apri la UI su `localhost:8501` e verifica che si connetta al backend (che parla con Qdrant).\n",
    "\n",
    "---\n",
    "\n",
    "## **10. In sintesi**\n",
    "\n",
    "* Docker Compose è il **collante** dei container.\n",
    "* Descrive tutto in un unico file: servizi, reti, volumi, porte, variabili.\n",
    "* Ti permette di **avviare uno stack AI completo con un solo comando**.\n",
    "* È lo standard per orchestrare ambienti **CrewAI + Qdrant + UI** in locale o in CI/CD.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc9eed-7d77-4ecf-b5ec-93e7b05a9bc1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **1. File di override (`docker-compose.override.yml`)**\n",
    "\n",
    "### **A cosa serve**\n",
    "\n",
    "Quando usi Docker Compose, il file principale è:\n",
    "\n",
    "```\n",
    "docker-compose.yml\n",
    "```\n",
    "\n",
    "Ma puoi aggiungere un secondo file:\n",
    "\n",
    "```\n",
    "docker-compose.override.yml\n",
    "```\n",
    "\n",
    "che **modifica o aggiunge** impostazioni solo per l’ambiente di sviluppo.\n",
    "\n",
    "Docker Compose lo riconosce **automaticamente**: non serve specificarlo.\n",
    "Quando lanci:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Compose unisce i due file:\n",
    "\n",
    "```\n",
    "docker-compose.yml  +  docker-compose.override.yml\n",
    "```\n",
    "\n",
    "e crea una configurazione unica.\n",
    "\n",
    "---\n",
    "\n",
    "### **Perché si usa**\n",
    "\n",
    "Perché ti permette di:\n",
    "\n",
    "* **mantenere il file principale pulito e stabile** (per la produzione),\n",
    "* e mettere le **modifiche temporanee o locali** (come hot-reload, porte extra, mount del codice) solo nel file di override.\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio**\n",
    "\n",
    "**docker-compose.yml (base)**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "```\n",
    "\n",
    "**docker-compose.override.yml (solo in dev)**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    volumes:\n",
    "      - ./backend:/app\n",
    "    environment:\n",
    "      - DEBUG=True\n",
    "    command: uvicorn main:app --reload --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "Cosa succede:\n",
    "\n",
    "* In produzione (`docker compose -f docker-compose.yml up`) → parte senza reload, come un’immagine stabile.\n",
    "* In sviluppo (`docker compose up`) → viene aggiunto il mount locale e il reload automatico.\n",
    "\n",
    "---\n",
    "\n",
    "### **Regola base**\n",
    "\n",
    "* Se un campo è un **valore singolo** (es. una stringa), l’override lo **sostituisce**.\n",
    "* Se è una **mappa** (es. `environment`), viene **fuso**.\n",
    "* Se è una **lista** (es. `ports`), l’override **la rimpiazza completamente**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "# base\n",
    "ports:\n",
    "  - \"8080:8080\"\n",
    "\n",
    "# override\n",
    "ports:\n",
    "  - \"8090:8080\"   # la lista cambia interamente\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Profili (`profiles:`)**\n",
    "\n",
    "### **A cosa servono**\n",
    "\n",
    "I profili permettono di **attivare o disattivare certi servizi** nel file Compose.\n",
    "Questo è molto utile quando vuoi che **alcuni container partano solo in certi casi**, per esempio:\n",
    "\n",
    "* la UI Streamlit solo in dev;\n",
    "* il monitoring solo in test;\n",
    "* o un job una tantum solo su richiesta.\n",
    "\n",
    "---\n",
    "\n",
    "### **Come funziona**\n",
    "\n",
    "Ogni servizio può dichiarare uno o più profili:\n",
    "\n",
    "```yaml\n",
    "profiles: [\"nome_del_profilo\"]\n",
    "```\n",
    "\n",
    "Se non attivi quel profilo, **il servizio non parte**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    profiles: [\"ui\"]\n",
    "```\n",
    "\n",
    "Se avvii:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "→ partono **solo `qdrant` e `backend`** (perché non hanno profili).\n",
    "\n",
    "Se avvii:\n",
    "\n",
    "```bash\n",
    "docker compose --profile ui up -d\n",
    "```\n",
    "\n",
    "→ parte anche la **UI** (perché hai attivato il profilo `ui`).\n",
    "\n",
    "Puoi anche attivare più profili insieme:\n",
    "\n",
    "```bash\n",
    "docker compose --profile ui --profile gpu up -d\n",
    "```\n",
    "\n",
    "oppure:\n",
    "\n",
    "```bash\n",
    "COMPOSE_PROFILES=ui,gpu docker compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio pratico completo**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    profiles: [\"ui\"]      # parte solo se attivo il profilo ui\n",
    "\n",
    "  monitoring:\n",
    "    image: grafana/grafana:latest\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    profiles: [\"ops\"]     # parte solo se attivo il profilo ops\n",
    "```\n",
    "\n",
    "Comandi:\n",
    "\n",
    "```bash\n",
    "# solo backend e qdrant\n",
    "docker compose up -d\n",
    "\n",
    "# aggiungi la UI\n",
    "docker compose --profile ui up -d\n",
    "\n",
    "# avvia tutto (anche grafana)\n",
    "docker compose --profile ui --profile ops up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Come usarli insieme (override + profili)**\n",
    "\n",
    "Puoi usare **entrambi**:\n",
    "\n",
    "* `override.yml` → per cambiare configurazioni in locale;\n",
    "* `profiles` → per decidere *quali* servizi avviare.\n",
    "\n",
    "Esempio pratico in un progetto AI:\n",
    "\n",
    "**docker-compose.yml**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports: [\"8080:8080\"]\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports: [\"8501:8501\"]\n",
    "    profiles: [\"ui\"]\n",
    "```\n",
    "\n",
    "**docker-compose.override.yml**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    volumes:\n",
    "      - ./backend:/app\n",
    "    command: uvicorn main:app --reload --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "Ora:\n",
    "\n",
    "* In produzione → usi solo il file principale (senza override, senza profilo UI).\n",
    "* In sviluppo → `docker compose --profile ui up -d` (e hai sia l’UI sia il reload del backend).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In sintesi**\n",
    "\n",
    "| Funzione          | Serve a                             | Attivazione                      | Esempio                            |\n",
    "| ----------------- | ----------------------------------- | -------------------------------- | ---------------------------------- |\n",
    "| **Override file** | Modificare configurazioni in locale | Automatico (`docker compose up`) | Aggiungere volumi, reload, log     |\n",
    "| **Profili**       | Accendere/spegnere servizi interi   | Manuale (`--profile`)            | Attivare la UI, GPU o monitoraggio |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c60289-9ed6-4f59-ba96-e323aab3db89",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1. Cos’è Kubernetes**\n",
    "\n",
    "Kubernetes — abbreviato **K8s** — è una **piattaforma di orchestrazione di container**.\n",
    "In parole semplici, serve a **gestire e coordinare molti container Docker** (o di altri runtime) in modo automatico, sicuro e scalabile.\n",
    "\n",
    "> Docker ti fa “correre” i container.\n",
    "> Kubernetes ti permette di “organizzare” centinaia di container insieme.\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Il problema che risolve**\n",
    "\n",
    "Con Docker singolo o Docker Compose puoi:\n",
    "\n",
    "* avviare più container (API, DB, UI, ecc.),\n",
    "* connetterli in rete,\n",
    "* usare volumi.\n",
    "\n",
    "Ma se vuoi andare in **produzione su un cluster di server**, e avere:\n",
    "\n",
    "* **scalabilità** (più copie dello stesso servizio),\n",
    "* **auto-ripartenza automatica** se un container si blocca,\n",
    "* **load balancing** tra istanze multiple,\n",
    "* **aggiornamenti senza downtime (rolling updates)**,\n",
    "* **gestione risorse e limiti CPU/RAM**,\n",
    "  Docker da solo non basta.\n",
    "\n",
    "Qui entra in gioco Kubernetes.\n",
    "\n",
    "---\n",
    "\n",
    "# **3. Cosa fa Kubernetes in pratica**\n",
    "\n",
    "Kubernetes gestisce:\n",
    "\n",
    "1. **Il deployment** → fa partire i container (pod) e li mantiene attivi.\n",
    "2. **Lo scaling** → aumenta o riduce automaticamente il numero di copie.\n",
    "3. **Il networking** → fa comunicare i container tra loro in modo sicuro.\n",
    "4. **Il bilanciamento del carico** → distribuisce le richieste fra i pod.\n",
    "5. **Lo storage** → collega volumi persistenti ai container.\n",
    "6. **La configurazione** → passa variabili e segreti ai container.\n",
    "7. **L’autoguarigione** → se un container crasha, Kubernetes lo ricrea.\n",
    "\n",
    "---\n",
    "\n",
    "# **4. Architettura base di Kubernetes**\n",
    "\n",
    "Immagina un **cluster Kubernetes** come un piccolo “sistema operativo distribuito”:\n",
    "\n",
    "* un **Master Node** (controlla tutto),\n",
    "* uno o più **Worker Node** (eseguono i container).\n",
    "\n",
    "Ogni worker node esegue:\n",
    "\n",
    "* **Pod** → l’unità base, contiene uno o più container;\n",
    "* **Kubelet** → un agente che riceve ordini dal master;\n",
    "* **Kube Proxy** → gestisce la rete dei container.\n",
    "\n",
    "---\n",
    "\n",
    "## **Componenti principali**\n",
    "\n",
    "| Concetto                      | Cosa fa                                               | Analogia                                |\n",
    "| ----------------------------- | ----------------------------------------------------- | --------------------------------------- |\n",
    "| **Pod**                       | Il contenitore logico che ospita uno o più container  | Un singolo “servizio in esecuzione”     |\n",
    "| **Deployment**                | Definisce *quanti* pod vogliamo e come gestirli       | Un “supervisore” che li mantiene attivi |\n",
    "| **Service**                   | Espone un gruppo di pod su una rete interna o esterna | Come il `ports:` di Docker              |\n",
    "| **Ingress**                   | Gestisce accessi HTTP esterni al cluster              | Come un reverse proxy Nginx             |\n",
    "| **ConfigMap / Secret**        | Memorizza configurazioni e chiavi                     | Come `.env` o variabili Compose         |\n",
    "| **Volume / PersistentVolume** | Gestisce file o storage persistenti                   | Come i volumi Docker                    |\n",
    "\n",
    "---\n",
    "\n",
    "# **5. Esempio semplice (AI-ready)**\n",
    "\n",
    "Immagina uno stack come:\n",
    "\n",
    "* un backend **FastAPI (CrewAI)**;\n",
    "* un database **Qdrant**;\n",
    "* una UI **Streamlit**.\n",
    "\n",
    "In Docker Compose sarebbe un unico file con 3 servizi.\n",
    "In Kubernetes, ciascun servizio diventa una **coppia di risorse**:\n",
    "\n",
    "| Servizio       | Deployment                | Service                |\n",
    "| -------------- | ------------------------- | ---------------------- |\n",
    "| CrewAI Backend | `backend-deployment.yaml` | `backend-service.yaml` |\n",
    "| Qdrant         | `qdrant-deployment.yaml`  | `qdrant-service.yaml`  |\n",
    "| Streamlit UI   | `ui-deployment.yaml`      | `ui-service.yaml`      |\n",
    "\n",
    "Ogni Deployment crea i **pod** (cioè i container attivi).\n",
    "Ogni Service permette agli altri di raggiungerli in rete.\n",
    "\n",
    "---\n",
    "\n",
    "# **6. Un esempio concreto**\n",
    "\n",
    "### `backend-deployment.yaml`\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/crewai-backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "```\n",
    "\n",
    "### `backend-service.yaml`\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  type: ClusterIP\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 8080\n",
    "```\n",
    "\n",
    "Qui:\n",
    "\n",
    "* Kubernetes avvia **2 pod** del backend.\n",
    "* Il **Service** `backend` permette ad altri container (es. Qdrant, UI) di comunicare con lui su `backend:8080`.\n",
    "\n",
    "---\n",
    "\n",
    "# **7. Come si interagisce con Kubernetes**\n",
    "\n",
    "Una volta installato (in cloud o in locale con Minikube o Kind), si usa il comando:\n",
    "\n",
    "```bash\n",
    "kubectl\n",
    "```\n",
    "\n",
    "Esempi pratici:\n",
    "\n",
    "| Comando                                    | Cosa fa                       |\n",
    "| ------------------------------------------ | ----------------------------- |\n",
    "| `kubectl apply -f backend-deployment.yaml` | crea o aggiorna un deployment |\n",
    "| `kubectl get pods`                         | mostra i container attivi     |\n",
    "| `kubectl logs nome-pod`                    | visualizza i log              |\n",
    "| `kubectl delete -f file.yaml`              | rimuove una risorsa           |\n",
    "| `kubectl describe pod nome-pod`            | mostra dettagli di un pod     |\n",
    "\n",
    "---\n",
    "\n",
    "# **8. Come provare Kubernetes in locale**\n",
    "\n",
    "Per imparare e testare:\n",
    "\n",
    "### Opzione 1: **Minikube**\n",
    "\n",
    "Kubernetes locale su un solo computer:\n",
    "\n",
    "```bash\n",
    "minikube start\n",
    "kubectl get nodes\n",
    "```\n",
    "\n",
    "### Opzione 2: **Kind**\n",
    "\n",
    "Cluster Kubernetes dentro Docker:\n",
    "\n",
    "```bash\n",
    "kind create cluster\n",
    "```\n",
    "\n",
    "Entrambi creano un “mini cluster” dove puoi provare i tuoi deployment.\n",
    "\n",
    "---\n",
    "\n",
    "# **9. Kubernetes e Docker Compose: differenze in sintesi**\n",
    "\n",
    "| Funzione              | Docker Compose          | Kubernetes                                         |\n",
    "| --------------------- | ----------------------- | -------------------------------------------------- |\n",
    "| **Scopo**             | Orchestrazione locale   | Orchestrazione distribuita                         |\n",
    "| **File**              | `docker-compose.yml`    | File YAML separati (`Deployment`, `Service`, ecc.) |\n",
    "| **Avvio**             | `docker compose up`     | `kubectl apply -f .`                               |\n",
    "| **Networking**        | rete privata automatica | rete interna + Service DNS                         |\n",
    "| **Scalabilità**       | manuale                 | automatica (`replicas:` o autoscaler)              |\n",
    "| **Tolleranza errore** | limitata                | auto-ripartenza e healthcheck                      |\n",
    "| **Uso tipico**        | sviluppo                | produzione e cloud                                 |\n",
    "\n",
    "---\n",
    "\n",
    "# **10. Kubernetes nel mondo AI**\n",
    "\n",
    "Kubernetes è molto usato per orchestrare pipeline AI perché:\n",
    "\n",
    "* può **gestire modelli in container separati** (es. inference server, retriever, database);\n",
    "* permette **autoscaling in base al carico** (es. più istanze del modello se arrivano più richieste);\n",
    "* può integrare **GPU e volumi persistenti** per dataset e modelli;\n",
    "* consente di aggiornare un modello o un microservizio **senza downtime**.\n",
    "\n",
    "Esempio tipico:\n",
    "\n",
    "* 1 Pod: Qdrant (vector DB)\n",
    "* 1 Pod: CrewAI backend (FastAPI)\n",
    "* 1 Pod: Streamlit UI\n",
    "* 1 Pod: Worker (inference GPU)\n",
    "* 1 Pod: CronJob per update dataset\n",
    "\n",
    "Tutto orchestrato, scalabile e con auto-restart.\n",
    "\n",
    "---\n",
    "\n",
    "# **11. Dove gira Kubernetes**\n",
    "\n",
    "Puoi usarlo:\n",
    "\n",
    "* **in locale** (Minikube, Kind, Rancher Desktop)\n",
    "* **su cloud**:\n",
    "\n",
    "  * Google Kubernetes Engine (GKE)\n",
    "  * Azure Kubernetes Service (AKS)\n",
    "  * Amazon EKS\n",
    "* oppure **in ibrido** (cluster aziendali o su server dedicati).\n",
    "\n",
    "---\n",
    "\n",
    "# **12. In sintesi**\n",
    "\n",
    "| Concetto            | Significato                                               |\n",
    "| ------------------- | --------------------------------------------------------- |\n",
    "| **Kubernetes**      | sistema che gestisce e coordina container su più macchine |\n",
    "| **Pod**             | unità minima: 1 o più container                           |\n",
    "| **Deployment**      | controlla quanti pod devono essere in esecuzione          |\n",
    "| **Service**         | permette ai pod di comunicare                             |\n",
    "| **Ingress**         | apre l’accesso esterno                                    |\n",
    "| **kubectl**         | il comando per interagire con il cluster                  |\n",
    "| **Minikube / Kind** | strumenti per provarlo in locale                          |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab052d1-edcc-41cd-9a47-d195f10b8a15",
   "metadata": {},
   "source": [
    "## 1. Cosa fa Kubernetes in pratica\n",
    "\n",
    "Kubernetes è un sistema che gestisce più container in modo coordinato.\n",
    "Non esegue direttamente i container (quello lo fa Docker o un container runtime), ma li controlla: decide **quanti** devono esserci, **dove** devono girare e **come** devono comunicare.\n",
    "\n",
    "Quando vuoi creare un'applicazione, in Kubernetes non scrivi comandi da terminale come in Docker (`docker run ...`), ma scrivi **file YAML** che descrivono cosa vuoi ottenere.\n",
    "Ogni file YAML rappresenta una risorsa, e Kubernetes si occupa di \"raggiungere\" quello stato.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Il ruolo dei file YAML\n",
    "\n",
    "Ogni file YAML ha sempre la stessa struttura di base:\n",
    "\n",
    "```yaml\n",
    "apiVersion: <versione API>\n",
    "kind: <tipo di risorsa>\n",
    "metadata:\n",
    "  name: <nome risorsa>\n",
    "spec:\n",
    "  ...specifiche della risorsa...\n",
    "```\n",
    "\n",
    "Esempi di risorse:\n",
    "\n",
    "* `Pod` → un container o gruppo di container\n",
    "* `Deployment` → un gruppo di pod gestiti automaticamente\n",
    "* `Service` → il collegamento di rete tra i pod o verso l’esterno\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Il Pod: la base di tutto\n",
    "\n",
    "Un **Pod** è l’unità minima di esecuzione in Kubernetes.\n",
    "Dentro un pod può esserci uno o più container, ma nella maggior parte dei casi ne ha uno solo.\n",
    "\n",
    "Esempio pratico di pod:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: simple-pod\n",
    "spec:\n",
    "  containers:\n",
    "    - name: web\n",
    "      image: nginx:latest\n",
    "      ports:\n",
    "        - containerPort: 80\n",
    "```\n",
    "\n",
    "Questo YAML dice:\n",
    "\n",
    "* crea un pod chiamato `simple-pod`;\n",
    "* dentro il pod esegui un container basato sull’immagine `nginx:latest`;\n",
    "* esponi la porta 80 all’interno del cluster.\n",
    "\n",
    "Applica il file:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f pod.yaml\n",
    "```\n",
    "\n",
    "Verifica lo stato:\n",
    "\n",
    "```bash\n",
    "kubectl get pods\n",
    "kubectl describe pod simple-pod\n",
    "```\n",
    "\n",
    "Visualizza i log:\n",
    "\n",
    "```bash\n",
    "kubectl logs simple-pod\n",
    "```\n",
    "\n",
    "Elimina il pod:\n",
    "\n",
    "```bash\n",
    "kubectl delete pod simple-pod\n",
    "```\n",
    "\n",
    "Problema: se questo pod si blocca o viene eliminato, scompare.\n",
    "Non c’è alcun meccanismo che lo ricrei.\n",
    "Per questo serve il **Deployment**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Il Deployment: gestione automatica dei pod\n",
    "\n",
    "Un **Deployment** è un oggetto che gestisce uno o più pod identici.\n",
    "Serve per mantenere attivo un certo numero di copie e aggiornare l’applicazione senza interruzioni.\n",
    "\n",
    "Esempio di Deployment per un backend FastAPI:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend-deployment\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "```\n",
    "\n",
    "Spiegazione pratica:\n",
    "\n",
    "* `replicas: 3` indica che vogliamo tre pod attivi contemporaneamente;\n",
    "* `selector.matchLabels` e `template.metadata.labels` collegano il Deployment ai pod che crea;\n",
    "* nella sezione `containers` si definiscono i container come in un pod normale.\n",
    "\n",
    "Crea il Deployment:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f backend-deployment.yaml\n",
    "```\n",
    "\n",
    "Controlla cosa ha creato:\n",
    "\n",
    "```bash\n",
    "kubectl get deployments\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "Se uno dei pod si blocca, Kubernetes lo ricrea automaticamente.\n",
    "Se aggiorni l’immagine nel file YAML e riesegui `kubectl apply`, Kubernetes effettua un **rolling update**: aggiorna i pod uno alla volta, senza downtime.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Il Service: collegare i pod in rete\n",
    "\n",
    "Ogni pod in Kubernetes ha un indirizzo IP, ma questo IP cambia ogni volta che il pod viene ricreato.\n",
    "Quindi non puoi fare affidamento sugli IP.\n",
    "Serve un **Service**, che è un punto di accesso stabile.\n",
    "\n",
    "Esempio di Service per il backend:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 8080\n",
    "      targetPort: 8080\n",
    "  type: ClusterIP\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* `selector.app: backend` collega il Service ai pod che hanno l’etichetta `app=backend` (cioè quelli del Deployment);\n",
    "* `port` è la porta del Service (come viene visto dagli altri servizi);\n",
    "* `targetPort` è la porta interna dei pod;\n",
    "* `type: ClusterIP` significa che il servizio è accessibile solo all’interno del cluster.\n",
    "\n",
    "Applica il file:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f backend-service.yaml\n",
    "```\n",
    "\n",
    "Verifica:\n",
    "\n",
    "```bash\n",
    "kubectl get services\n",
    "```\n",
    "\n",
    "Ora altri pod (ad esempio un frontend) possono comunicare con questo backend usando:\n",
    "\n",
    "```\n",
    "http://backend-service:8080\n",
    "```\n",
    "\n",
    "Non serve conoscere gli IP.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Esporre un servizio all’esterno\n",
    "\n",
    "Per poter accedere da fuori (dal tuo computer, browser o client API) devi usare `type: NodePort` o `LoadBalancer`.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-service\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 8080\n",
    "      nodePort: 30080\n",
    "```\n",
    "\n",
    "`nodePort: 30080` espone la porta 8080 dei pod sulla porta 30080 della macchina fisica del cluster.\n",
    "\n",
    "Avvia il servizio:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f backend-service.yaml\n",
    "```\n",
    "\n",
    "Controlla:\n",
    "\n",
    "```bash\n",
    "kubectl get services\n",
    "```\n",
    "\n",
    "Apri nel browser:\n",
    "\n",
    "```\n",
    "http://<ip-del-nodo>:30080\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Come collegare più componenti (esempio AI semplice)\n",
    "\n",
    "Supponiamo di avere un backend FastAPI e un database Qdrant.\n",
    "\n",
    "### qdrant-deployment.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: qdrant\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: qdrant\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: qdrant\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: qdrant\n",
    "          image: qdrant/qdrant:v1.10.0\n",
    "          ports:\n",
    "            - containerPort: 6333\n",
    "```\n",
    "\n",
    "### qdrant-service.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: qdrant-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: qdrant\n",
    "  ports:\n",
    "    - port: 6333\n",
    "      targetPort: 6333\n",
    "  type: ClusterIP\n",
    "```\n",
    "\n",
    "### backend-deployment.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/crewai-backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "          env:\n",
    "            - name: QDRANT_HOST\n",
    "              value: qdrant-service\n",
    "            - name: QDRANT_PORT\n",
    "              value: \"6333\"\n",
    "```\n",
    "\n",
    "### backend-service.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 8080\n",
    "  type: NodePort\n",
    "```\n",
    "\n",
    "Applica tutto:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f qdrant-deployment.yaml\n",
    "kubectl apply -f qdrant-service.yaml\n",
    "kubectl apply -f backend-deployment.yaml\n",
    "kubectl apply -f backend-service.yaml\n",
    "```\n",
    "\n",
    "Verifica:\n",
    "\n",
    "```bash\n",
    "kubectl get all\n",
    "```\n",
    "\n",
    "Il backend parlerà con Qdrant tramite il nome DNS interno `qdrant-service:6333`.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Comandi fondamentali per lavorare con YAML\n",
    "\n",
    "| Azione                           | Comando                                       |\n",
    "| -------------------------------- | --------------------------------------------- |\n",
    "| Creare o aggiornare risorse      | `kubectl apply -f file.yaml`                  |\n",
    "| Mostrare risorse attive          | `kubectl get all`                             |\n",
    "| Mostrare dettagli di una risorsa | `kubectl describe <tipo> <nome>`              |\n",
    "| Entrare in un container          | `kubectl exec -it <pod> -- bash`              |\n",
    "| Mostrare i log                   | `kubectl logs <pod>`                          |\n",
    "| Eliminare una risorsa            | `kubectl delete -f file.yaml`                 |\n",
    "| Testare senza applicare          | `kubectl apply --dry-run=client -f file.yaml` |\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Schema logico completo\n",
    "\n",
    "1. Scrivi un **Deployment** per ogni applicazione.\n",
    "2. Assegna **etichette (labels)** ai pod nel template.\n",
    "3. Crea un **Service** con un **selector** che punta alle stesse etichette.\n",
    "4. Usa `kubectl apply` per creare tutto.\n",
    "5. Controlla che i pod siano attivi con `kubectl get pods`.\n",
    "6. Se serve accesso esterno, usa `type: NodePort` o `LoadBalancer`.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. In sintesi\n",
    "\n",
    "* **Pod** → è un contenitore (uno o più container) in esecuzione.\n",
    "* **Deployment** → crea e mantiene un gruppo di pod uguali, li aggiorna e li ricrea se cadono.\n",
    "* **Service** → fornisce un nome fisso per raggiungere i pod, anche se gli IP cambiano.\n",
    "* Tutto viene descritto in **file YAML** che dichiari lo stato desiderato.\n",
    "* Kubernetes si occupa di mantenerlo reale.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90eb61-a807-4a76-b7de-71d9eee6bd69",
   "metadata": {},
   "source": [
    "# Installazione\n",
    "\n",
    "## 1. Requisiti preliminari\n",
    "\n",
    "Prima di iniziare, assicurati che:\n",
    "\n",
    "* **Docker Desktop** sia già installato e avviato (serve come driver per Minikube).\n",
    "  Verifica aprendo Docker Desktop: deve risultare “Running”.\n",
    "* Stai usando **Windows 10 o 11 (64 bit)**.\n",
    "* Hai i **permessi da amministratore**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Scaricare Minikube dal sito ufficiale\n",
    "\n",
    "1. Vai sul sito ufficiale di Minikube:\n",
    "   **[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)**\n",
    "2. Scorri alla sezione **Windows**.\n",
    "3. Clicca sul link di download per l’eseguibile:\n",
    "   **[https://github.com/kubernetes/minikube/releases/latest](https://github.com/kubernetes/minikube/releases/latest)**\n",
    "4. Nella pagina GitHub, trova la sezione **Assets** e scarica il file:\n",
    "\n",
    "   ```\n",
    "   minikube-installer.exe\n",
    "   ```\n",
    "\n",
    "   (Non scaricare i file `.sha256` o `.asc` – serve solo il `.exe`)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Installazione con `minikube-installer.exe`\n",
    "\n",
    "1. Dopo aver scaricato il file, **clicca due volte** su:\n",
    "\n",
    "   ```\n",
    "   minikube-installer.exe\n",
    "   ```\n",
    "\n",
    "2. Segui il processo guidato:\n",
    "\n",
    "   * accetta i termini di licenza;\n",
    "   * lascia il percorso predefinito (es. `C:\\Program Files (x86)\\Kubernetes\\Minikube`);\n",
    "   * assicurati che l’opzione per aggiungere Minikube al **PATH di sistema** sia selezionata;\n",
    "   * clicca su **Install**.\n",
    "\n",
    "3. Attendi il completamento (pochi secondi/minuti).\n",
    "\n",
    "4. Quando finisce, puoi già aprire un **Prompt dei comandi** o **PowerShell** e digitare:\n",
    "\n",
    "   ```powershell\n",
    "   minikube version\n",
    "   ```\n",
    "\n",
    "   Se risponde con la versione (es. `minikube version: v1.33.0`), l’installazione è andata a buon fine.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Verifica che `kubectl` sia incluso\n",
    "\n",
    "Il pacchetto installer `.exe` di Minikube include **kubectl**, quindi non serve installarlo a parte.\n",
    "\n",
    "Verifica con:\n",
    "\n",
    "```powershell\n",
    "kubectl version --client\n",
    "```\n",
    "\n",
    "Dovresti vedere qualcosa come:\n",
    "\n",
    "```\n",
    "Client Version: v1.30.0\n",
    "Kustomize Version: v5.0.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Avviare Minikube con Docker Desktop\n",
    "\n",
    "1. Assicurati che Docker Desktop sia **in esecuzione**.\n",
    "\n",
    "2. Apri **PowerShell** come amministratore.\n",
    "\n",
    "3. Avvia Minikube con Docker come driver:\n",
    "\n",
    "   ```powershell\n",
    "   minikube start --driver=docker\n",
    "   ```\n",
    "\n",
    "   Questo comando:\n",
    "\n",
    "   * crea un cluster Kubernetes locale;\n",
    "   * configura kubectl automaticamente;\n",
    "   * utilizza Docker Desktop come motore.\n",
    "\n",
    "4. Controlla lo stato:\n",
    "\n",
    "   ```powershell\n",
    "   minikube status\n",
    "   ```\n",
    "\n",
    "   Output atteso:\n",
    "\n",
    "   ```\n",
    "   host: Running\n",
    "   kubelet: Running\n",
    "   apiserver: Running\n",
    "   kubeconfig: Configured\n",
    "   ```\n",
    "\n",
    "5. Controlla i nodi del cluster:\n",
    "\n",
    "   ```powershell\n",
    "   kubectl get nodes\n",
    "   ```\n",
    "\n",
    "   Dovresti vedere:\n",
    "\n",
    "   ```\n",
    "   NAME       STATUS   ROLES           AGE   VERSION\n",
    "   minikube   Ready    control-plane   1m    v1.30.0\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. (Facoltativo) Aggiungere il supporto Ingress\n",
    "\n",
    "Se vuoi pubblicare servizi web tramite domini locali (`myapp.local`, ecc.):\n",
    "\n",
    "```powershell\n",
    "minikube addons enable ingress\n",
    "```\n",
    "\n",
    "Verifica:\n",
    "\n",
    "```powershell\n",
    "kubectl get pods -n ingress-nginx\n",
    "```\n",
    "\n",
    "Deve risultare in esecuzione un pod simile a `ingress-nginx-controller`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Avvio, stop e reset del cluster\n",
    "\n",
    "* **Avviare Minikube**:\n",
    "\n",
    "  ```powershell\n",
    "  minikube start --driver=docker\n",
    "  ```\n",
    "\n",
    "* **Fermarlo temporaneamente**:\n",
    "\n",
    "  ```powershell\n",
    "  minikube stop\n",
    "  ```\n",
    "\n",
    "* **Eliminare tutto (reset completo)**:\n",
    "\n",
    "  ```powershell\n",
    "  minikube delete\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Test rapido\n",
    "\n",
    "Proviamo un semplice pod:\n",
    "\n",
    "```powershell\n",
    "kubectl run test-nginx --image=nginx --port=80\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "Esporre il pod:\n",
    "\n",
    "```powershell\n",
    "kubectl expose pod test-nginx --type=NodePort --port=80\n",
    "kubectl get svc\n",
    "```\n",
    "\n",
    "Apri il servizio nel browser:\n",
    "\n",
    "```powershell\n",
    "minikube service test-nginx\n",
    "```\n",
    "\n",
    "Se si apre una pagina “Welcome to nginx”, il cluster è funzionante.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Installare Kompose (conversione Docker Compose → Kubernetes)\n",
    "\n",
    "Ora puoi installare Kompose, per convertire progetti Compose in Kubernetes.\n",
    "\n",
    "1. Vai su:\n",
    "   **[https://github.com/kubernetes/kompose/releases/latest](https://github.com/kubernetes/kompose/releases/latest)**\n",
    "\n",
    "2. Scarica:\n",
    "\n",
    "   ```\n",
    "   kompose-windows-amd64.exe\n",
    "   ```\n",
    "\n",
    "3. Rinominalo in:\n",
    "\n",
    "   ```\n",
    "   kompose.exe\n",
    "   ```\n",
    "\n",
    "4. Spostalo in una cartella presente nel tuo PATH, ad esempio:\n",
    "\n",
    "   ```\n",
    "   C:\\Program Files\\Kubernetes\\Minikube\\\n",
    "   ```\n",
    "\n",
    "   oppure aggiungi la cartella dove l’hai salvato al PATH di Windows (Pannello di controllo → Sistema → Variabili d’ambiente).\n",
    "\n",
    "5. Verifica l’installazione:\n",
    "\n",
    "   ```powershell\n",
    "   kompose version\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Riassunto comandi chiave\n",
    "\n",
    "| Scopo                   | Comando                            |\n",
    "| ----------------------- | ---------------------------------- |\n",
    "| Avviare il cluster      | `minikube start --driver=docker`   |\n",
    "| Fermarlo                | `minikube stop`                    |\n",
    "| Eliminare tutto         | `minikube delete`                  |\n",
    "| Vedere lo stato         | `minikube status`                  |\n",
    "| Aprire la dashboard web | `minikube dashboard`               |\n",
    "| Mostrare i nodi         | `kubectl get nodes`                |\n",
    "| Mostrare i pod          | `kubectl get pods`                 |\n",
    "| Aprire un servizio web  | `minikube service <nome-servizio>` |\n",
    "\n",
    "---\n",
    "\n",
    "## 11. In sintesi\n",
    "\n",
    "Dopo l’installazione con `minikube-installer.exe`:\n",
    "\n",
    "* Kubernetes è già pronto e configurato (non serve installare `kubectl` separatamente).\n",
    "* Puoi usare Docker Desktop come driver.\n",
    "* Con Kompose puoi convertire i tuoi file `docker-compose.yml` in manifest Kubernetes con:\n",
    "\n",
    "  ```powershell\n",
    "  kompose convert -f .\\docker-compose.yml --service-nodeport\n",
    "  kubectl apply -f .\n",
    "  minikube service nome-servizio\n",
    "  ```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe982d-a485-4fc9-babe-94dc7cf3135f",
   "metadata": {},
   "source": [
    "# Da Kompose a K8s\n",
    "---\n",
    "\n",
    "## 1) Punto di partenza: `docker-compose.yml`\n",
    "\n",
    "Esempio minimale (backend FastAPI + Qdrant):\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    ports: [\"6333:6333\"]\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "\n",
    "  backend:\n",
    "    image: myorg/crewai-backend:latest\n",
    "    environment:\n",
    "      QDRANT_HOST: qdrant\n",
    "      QDRANT_PORT: \"6333\"\n",
    "    ports: [\"8080:8080\"]\n",
    "\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Conversione con Kompose\n",
    "\n",
    "Se hai Windows + Minikube:\n",
    "\n",
    "```powershell\n",
    "# (facoltativo) fonde compose + override + .env in un solo file\n",
    "docker compose config > compose.merged.yml\n",
    "\n",
    "# conversione; --service-nodeport per esporre facilmente i servizi in Minikube\n",
    "kompose convert -f .\\compose.merged.yml --service-nodeport\n",
    "# oppure: kompose convert -f .\\docker-compose.yml --service-nodeport\n",
    "```\n",
    "\n",
    "**Cosa ottieni** nella cartella:\n",
    "\n",
    "```\n",
    "backend-deployment.yaml\n",
    "backend-service.yaml\n",
    "qdrant-deployment.yaml\n",
    "qdrant-service.yaml\n",
    "qdrant-data-persistentvolumeclaim.yaml   # se rileva il volume nominato\n",
    "```\n",
    "\n",
    "Kompose ha già mappato:\n",
    "\n",
    "* `image`, `environment`, `ports` → nei `Deployment`/`Service`\n",
    "* `volumes` → in `PersistentVolumeClaim + volumeMounts`\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Scegli il numero di copie (repliche)\n",
    "\n",
    "Kompose crea di default **1 replica**.\n",
    "Per scalare, **modifica il Deployment** (o usa `kubectl scale`).\n",
    "\n",
    "Apri `backend-deployment.yaml` e imposta:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  replicas: 3                # <-- scegli tu quante copie\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      io.kompose.service: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        io.kompose.service: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/crewai-backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "          env:\n",
    "            - name: QDRANT_HOST\n",
    "              value: qdrant\n",
    "            - name: QDRANT_PORT\n",
    "              value: \"6333\"\n",
    "```\n",
    "\n",
    "Se vuoi, puoi anche cambiare il **tipo di Service** (es. `NodePort` o `LoadBalancer`) nel file `backend-service.yaml`.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Applica al cluster\n",
    "\n",
    "```powershell\n",
    "kubectl apply -f .\n",
    "kubectl get deploy,svc,pods,pvc\n",
    "```\n",
    "\n",
    "Apri il backend o la UI da Minikube:\n",
    "\n",
    "```powershell\n",
    "minikube service backend\n",
    "# (se hai generato anche la ui: minikube service ui)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Operazioni tipiche dopo la conversione\n",
    "\n",
    "### A) Scalare senza editare file\n",
    "\n",
    "```powershell\n",
    "kubectl scale deployment backend --replicas=5\n",
    "kubectl get deploy backend\n",
    "```\n",
    "\n",
    "### B) Aggiornare l’immagine (rolling update)\n",
    "\n",
    "Modifica `image:` nel file `backend-deployment.yaml` **oppure**:\n",
    "\n",
    "```powershell\n",
    "kubectl set image deployment/backend backend=myorg/crewai-backend:1.1.0\n",
    "kubectl rollout status deployment/backend\n",
    "```\n",
    "\n",
    "### C) Aggiungere readiness/liveness probe (consigliato)\n",
    "\n",
    "Kompose non traduce `healthcheck` di Compose in probe K8s. Aggiungile tu:\n",
    "\n",
    "```yaml\n",
    "# dentro spec.template.spec.containers[0]\n",
    "readinessProbe:\n",
    "  httpGet:\n",
    "    path: /health\n",
    "    port: 8080\n",
    "  initialDelaySeconds: 5\n",
    "  periodSeconds: 10\n",
    "livenessProbe:\n",
    "  httpGet:\n",
    "    path: /health\n",
    "    port: 8080\n",
    "  initialDelaySeconds: 15\n",
    "  periodSeconds: 20\n",
    "```\n",
    "\n",
    "### D) Risorse minime (soprattutto su laptop)\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  requests:\n",
    "    cpu: \"250m\"\n",
    "    memory: \"256Mi\"\n",
    "  limits:\n",
    "    cpu: \"1\"\n",
    "    memory: \"1Gi\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Cosa “automatizza” davvero Kompose e cosa no\n",
    "\n",
    "* **Sì**: genera automaticamente i manifest **Deployment**, **Service** e **PVC** a partire da `docker-compose.yml`.\n",
    "* **No**: non gestisce l’ordine di avvio tipo `depends_on` (in Kubernetes si usano **readinessProbe**), non crea automaticamente **Ingress**, non aggiunge limiti risorse o probe avanzate. Queste parti le imposti tu dopo la conversione.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Sequenza riassuntiva\n",
    "\n",
    "```powershell\n",
    "# 1) (opzionale) fondi i compose con .env\n",
    "docker compose config > compose.merged.yml\n",
    "\n",
    "# 2) converti\n",
    "kompose convert -f .\\compose.merged.yml --service-nodeport\n",
    "\n",
    "# 3) opzionale: modifica replicas/resources/probe nei Deployment\n",
    "# 4) applica\n",
    "kubectl apply -f .\n",
    "\n",
    "# 5) verifica e apri\n",
    "kubectl get all\n",
    "minikube service backend\n",
    "\n",
    "# 6) scala o aggiorna\n",
    "kubectl scale deployment backend --replicas=5\n",
    "kubectl set image deployment/backend backend=myorg/crewai-backend:1.1.0\n",
    "```\n",
    "\n",
    "Questo è il flusso tipico: **Kompose ti genera la base Kubernetes**, tu scegli **repliche** e aggiungi i dettagli operativi (probe, risorse, tipi di Service).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
