{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5052f859-6d31-4e2e-8f97-99d3cd301236",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **1.1 – Perché Docker è cruciale nel mondo AI: ambienti riproducibili e isolati**\n",
    "\n",
    "---\n",
    "\n",
    "## **Contesto**\n",
    "\n",
    "Nel mondo dell’AI engineering, il codice raramente vive da solo.\n",
    "Un singolo progetto può includere:\n",
    "\n",
    "* una **CrewAI Flow pipeline** composta da più agenti;\n",
    "* una **base di conoscenza indicizzata** su Qdrant o FAISS;\n",
    "* una **UI Streamlit** o FastAPI per interazione utente;\n",
    "* un **database PostgreSQL** per log, tracciamento e valutazione;\n",
    "* librerie Python ad alta complessità (Torch, Transformers, OpenAI, LangChain, ecc.);\n",
    "* e talvolta anche **accelerazione GPU**.\n",
    "\n",
    "In questo ecosistema complesso, anche un piccolo cambiamento nella versione di Python, Torch o CUDA può **rompere la compatibilità** dell’intero progetto.\n",
    "È qui che entra in gioco Docker.\n",
    "\n",
    "---\n",
    "\n",
    "## **Concetto chiave: riproducibilità e isolamento**\n",
    "\n",
    "### 1. **Riproducibilità**\n",
    "\n",
    "Docker permette di impacchettare tutto ciò che serve per far girare un’applicazione — **codice, dipendenze, librerie, variabili d’ambiente, sistema operativo** — in un’immagine immutabile.\n",
    "Chiunque esegua quell’immagine, su qualunque macchina, ottiene **esattamente lo stesso comportamento**.\n",
    "\n",
    "> **Esempio pratico**\n",
    "> Un flow CrewAI funziona sulla tua macchina, ma non sul server remoto perché il server usa Python 3.10 mentre tu hai 3.11.\n",
    "> Con Docker, entrambi eseguite **la stessa immagine**, basata sullo stesso ambiente (`FROM python:3.11-slim`), e il comportamento sarà identico.\n",
    "\n",
    "### 2. **Isolamento**\n",
    "\n",
    "Ogni container Docker è **un ambiente isolato** dal sistema operativo host e dagli altri container:\n",
    "\n",
    "* Non condivide processi, pacchetti o variabili d’ambiente.\n",
    "* Può avere una rete privata e filesystem dedicato.\n",
    "* Se un container va in crash o consuma troppa RAM, **non impatta gli altri**.\n",
    "\n",
    "Questo isolamento è cruciale in sistemi AI con **più microservizi**:\n",
    "\n",
    "* il backend CrewAI non interferisce con Qdrant,\n",
    "* Qdrant non influisce sul database PostgreSQL,\n",
    "* e ogni parte può essere aggiornata o riavviata indipendentemente.\n",
    "\n",
    "---\n",
    "\n",
    "## **Perché è cruciale per l’AI moderna**\n",
    "\n",
    "### 1. **Gestione delle dipendenze**\n",
    "\n",
    "Progetti AI usano spesso librerie non allineate tra loro:\n",
    "\n",
    "* `torch==2.3.0` richiede una versione specifica di CUDA,\n",
    "* `transformers==4.44` può rompere LangChain se non aggiornato,\n",
    "* `qdrant-client` ha binding Rust/Python sensibili alla versione.\n",
    "\n",
    "Con Docker puoi bloccare **esattamente le versioni** nel Dockerfile, garantendo che il progetto sia stabile nel tempo.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Reproducible Research e MLOps**\n",
    "\n",
    "In MLOps e AI engineering, la **riproducibilità degli esperimenti** è un requisito critico.\n",
    "Con Docker puoi:\n",
    "\n",
    "* rieseguire esattamente una pipeline anche mesi dopo;\n",
    "* distribuire lo stesso ambiente a un collega o server;\n",
    "* garantire che l’esperimento su cui è stato addestrato un modello sia documentato e verificabile.\n",
    "\n",
    "Molte aziende e laboratori (OpenAI, Hugging Face, Meta AI) **versionano i propri ambienti Docker** insieme al codice.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Distribuzione e scalabilità**\n",
    "\n",
    "Un container è un’unità standard, facilmente distribuibile:\n",
    "\n",
    "* Puoi spostarlo da un laptop a un server cloud o a un cluster Kubernetes;\n",
    "* Puoi scalare lo stesso container su più nodi senza riconfigurare nulla;\n",
    "* Ogni microservizio CrewAI (rag, retriever, evaluator, frontend) può essere un container separato.\n",
    "\n",
    "Esempio tipico di stack AI containerizzato:\n",
    "\n",
    "```\n",
    "crew-backend     -> container FastAPI con CrewAI\n",
    "qdrant-db        -> container Qdrant ufficiale\n",
    "postgres-logs    -> container PostgreSQL\n",
    "streamlit-ui     -> container Streamlit con API utente\n",
    "```\n",
    "\n",
    "Con un solo comando:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "tutto l’ambiente prende vita, identico su ogni macchina.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Isolamento GPU e AI workloads**\n",
    "\n",
    "Docker supporta nativamente l’accesso alle GPU tramite:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all\n",
    "```\n",
    "\n",
    "o, in Compose:\n",
    "\n",
    "```yaml\n",
    "deploy:\n",
    "  resources:\n",
    "    reservations:\n",
    "      devices:\n",
    "        - capabilities: [gpu]\n",
    "```\n",
    "\n",
    "Questo permette di:\n",
    "\n",
    "* eseguire modelli AI pesanti in container,\n",
    "* isolare il carico GPU da altri processi,\n",
    "* e distribuire workload AI in cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## **Analogia concettuale**\n",
    "\n",
    "> Pensa a Docker come a un “**laboratorio virtuale sigillato**”.\n",
    "> Dentro ci sono le tue provette (codice, librerie, modelli), il tuo microscopio (framework AI), e perfino il manuale d’uso (Dockerfile).\n",
    "> Nessuno può sporcare il tuo ambiente e tu puoi ricrearlo all’infinito.\n",
    "\n",
    "---\n",
    "\n",
    "## **Esercizio pratico (10 minuti)**\n",
    "\n",
    "1. Lancia un container Python:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it python:3.11 bash\n",
    "   ```\n",
    "2. Installa alcune librerie:\n",
    "\n",
    "   ```bash\n",
    "   pip install crewai qdrant-client\n",
    "   ```\n",
    "3. Esci e rilancia il container: scopri che le librerie **non persistono**.\n",
    "   → Capirai che ogni container è **ephemeral** e **isolato**.\n",
    "4. Rilancia con volume montato:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it -v $(pwd)/app:/app python:3.11 bash\n",
    "   ```\n",
    "\n",
    "   Ora tutto ciò che salvi in `/app` persiste localmente.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d1b00-113e-4c93-a97c-8d26d5aaf7f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.2 – Differenze tra venv, Conda, VM e container**\n",
    "\n",
    "Nel mondo dell’AI engineering esistono diversi modi per isolare un ambiente di sviluppo o di esecuzione. Prima di capire a fondo Docker, è fondamentale distinguere tra **ambienti virtuali (venv, Conda)** e **macchine virtuali (VM)**, così da comprendere dove si colloca la containerizzazione.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Virtualenv e venv**\n",
    "\n",
    "Gli ambienti virtuali in Python (creati con `venv` o `virtualenv`) sono **isolatori di pacchetti**: permettono di avere versioni di librerie diverse da quelle del sistema operativo, ma non isolano il sistema vero e proprio.\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install crewai qdrant-client\n",
    "```\n",
    "\n",
    "In questo caso:\n",
    "\n",
    "* L’ambiente virtuale **usa sempre lo stesso Python** dell’host;\n",
    "* Tutto gira **sullo stesso sistema operativo**;\n",
    "* Non puoi controllare la versione di OS, CUDA o driver GPU;\n",
    "* Se aggiorni globalmente una libreria come `torch`, potresti rompere un altro progetto.\n",
    "\n",
    "È utile per **sviluppo locale**, ma non garantisce **riproducibilità perfetta**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Conda environment**\n",
    "\n",
    "Conda è uno strumento più avanzato, molto diffuso in ambito data science.\n",
    "Può gestire non solo librerie Python, ma anche **pacchetti di sistema** (come `ffmpeg`, `libtorch`, `cuda`).\n",
    "\n",
    "```bash\n",
    "conda create -n crewai python=3.11\n",
    "conda activate crewai\n",
    "conda install pytorch cudatoolkit=12.1 -c pytorch\n",
    "```\n",
    "\n",
    "Conda risolve molti problemi di compatibilità, ma:\n",
    "\n",
    "* Gli ambienti restano **legati al sistema operativo**;\n",
    "* Non è portabile tra sistemi (un env Linux non gira su Windows);\n",
    "* Le versioni dei driver e delle librerie native (CUDA, cuDNN, Rust) restano dipendenti dall’host.\n",
    "\n",
    "In altre parole, **Conda isola le librerie, non il sistema**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Virtual Machines (VM)**\n",
    "\n",
    "Le macchine virtuali (VM) isolano tutto: sistema operativo, kernel, driver, file system.\n",
    "Ogni VM è un computer completo, con un suo OS e risorse dedicate (CPU, RAM, disco).\n",
    "\n",
    "Vantaggi:\n",
    "\n",
    "* Isolamento totale.\n",
    "* Puoi avere sistemi operativi diversi sull’host (es. Linux su Windows).\n",
    "\n",
    "Svantaggi:\n",
    "\n",
    "* Ogni VM pesa **diversi GB**;\n",
    "* L’avvio è lento;\n",
    "* Consuma molta memoria e CPU;\n",
    "* Duplicare o aggiornare ambienti è costoso.\n",
    "\n",
    "Per esempio, se un progetto CrewAI richiede 4 microservizi in VM, ognuno con un OS Linux, avresti 4 sistemi completi da mantenere, aggiornare e gestire: un incubo in produzione.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Docker container**\n",
    "\n",
    "Docker rappresenta un **punto di equilibrio perfetto** tra i due mondi:\n",
    "\n",
    "* Leggero come un ambiente virtuale;\n",
    "* Isolato come una macchina virtuale.\n",
    "\n",
    "I container non contengono un sistema operativo completo: condividono il **kernel dell’host**, ma mantengono filesystem, processi e librerie isolati.\n",
    "Questo riduce drasticamente i tempi di avvio e il consumo di risorse.\n",
    "\n",
    "### Esempio:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11-slim bash\n",
    "```\n",
    "\n",
    "Questo comando:\n",
    "\n",
    "* Scarica un’immagine contenente Linux minimale + Python 3.11;\n",
    "* Avvia un container isolato;\n",
    "* In meno di 1 secondo sei dentro un sistema pulito.\n",
    "\n",
    "Puoi poi installare CrewAI, Qdrant, LangChain o Streamlit senza toccare il tuo sistema locale.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Differenze riassuntive**\n",
    "\n",
    "| Caratteristica         | venv / virtualenv | Conda         | Virtual Machine           | Docker Container             |\n",
    "| ---------------------- | ----------------- | ------------- | ------------------------- | ---------------------------- |\n",
    "| Isolamento OS          | ❌                 | ❌             | ✅                         | ✅ (parziale, condiviso)      |\n",
    "| Peso                   | 🔹 Leggero        | 🔹 Medio      | ⚫ Pesante                 | 🔹 Leggero                   |\n",
    "| Avvio                  | Immediato         | Immediato     | Lento (minuti)            | Istantaneo                   |\n",
    "| Portabilità            | ❌                 | ❌             | ✅ (con immagine)          | ✅                            |\n",
    "| GPU accesso diretto    | ✅ (locale)        | ✅             | ⚠️ complesso              | ✅ (via driver NVIDIA/ROCm)   |\n",
    "| Riproducibilità totale | ❌                 | ⚠️ Parziale   | ✅                         | ✅                            |\n",
    "| Uso ideale             | Dev locale        | ML lab locale | Sistemi legacy o completi | Produzione AI e microservizi |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Esempio pratico**\n",
    "\n",
    "Immagina di dover distribuire un sistema AI composto da:\n",
    "\n",
    "* `CrewAI` backend per l’orchestrazione,\n",
    "* `Qdrant` per la ricerca vettoriale,\n",
    "* `Streamlit` come interfaccia utente.\n",
    "\n",
    "### Con venv:\n",
    "\n",
    "Ogni sviluppatore deve installare manualmente Python, CrewAI, Qdrant, Streamlit, configurare le porte e i database — altissimo rischio di errore.\n",
    "\n",
    "### Con Docker:\n",
    "\n",
    "Basta clonare il progetto e lanciare:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "Tutto si avvia in container separati, già configurati.\n",
    "L’ambiente sarà identico per ogni persona e ogni server.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Analogia semplice**\n",
    "\n",
    "* **venv**: come usare scatole per tenere separati gli oggetti sulla stessa scrivania.\n",
    "* **VM**: come avere scrivanie diverse in stanze diverse.\n",
    "* **Docker**: come avere scatole sigillate identiche, che puoi spostare ovunque e aprire ovunque, già pronte all’uso.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550baa4-7aa9-435e-8620-6d0c6f59332a",
   "metadata": {},
   "source": [
    "\n",
    "# **1.3 – Architettura Docker: client, daemon, immagini, container e registry**\n",
    "\n",
    "Per comprendere davvero Docker — e non solo “usarlo” — bisogna capirne la **struttura interna**: come comunica, chi fa cosa e dove avviene l’esecuzione reale dei container.\n",
    "Molti sviluppatori usano Docker per anni senza conoscere la differenza tra *client* e *daemon*: questo punto serve a eliminare quella confusione, così da lavorare in modo consapevole e sicuro.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. L’architettura generale**\n",
    "\n",
    "Docker è composto da **quattro elementi principali**:\n",
    "\n",
    "1. **Docker Client** → l’interfaccia con cui tu interagisci.\n",
    "2. **Docker Daemon (dockerd)** → il motore che esegue davvero i container.\n",
    "3. **Docker Images** → i “modelli” o blueprint dei container.\n",
    "4. **Docker Containers** → le istanze in esecuzione delle immagini.\n",
    "5. **Docker Registry** → il magazzino remoto dove le immagini vengono salvate e condivise.\n",
    "\n",
    "Tutti questi componenti lavorano insieme come un sistema client-server.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Il Client**\n",
    "\n",
    "Il **client** è tutto ciò che usi per comunicare con Docker:\n",
    "\n",
    "* il comando `docker` nel terminale,\n",
    "* o l’interfaccia grafica Docker Desktop.\n",
    "\n",
    "Quando scrivi:\n",
    "\n",
    "```bash\n",
    "docker run python:3.11\n",
    "```\n",
    "\n",
    "il client **non esegue direttamente** il container.\n",
    "In realtà, invia una richiesta API al Daemon Docker in background (dockerd), che è il vero motore.\n",
    "\n",
    "Docker Client può anche collegarsi a un daemon remoto, ad esempio su un server cloud:\n",
    "\n",
    "```bash\n",
    "export DOCKER_HOST=ssh://user@server\n",
    "```\n",
    "\n",
    "In questo modo, puoi controllare container su un’altra macchina come se fossero locali.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Il Daemon (dockerd)**\n",
    "\n",
    "Il **Docker Daemon** è il processo che:\n",
    "\n",
    "* riceve comandi dal client,\n",
    "* scarica immagini,\n",
    "* crea, avvia e ferma container,\n",
    "* gestisce volumi, reti e log.\n",
    "\n",
    "È lui a parlare con il kernel del sistema operativo per impostare **namespaces**, **cgroups**, e filesystem copy-on-write.\n",
    "\n",
    "In pratica, è il “cuore” del sistema Docker.\n",
    "\n",
    "Su Linux gira come processo di sistema, su macOS e Windows è incapsulato all’interno di una VM leggera (perché Docker richiede kernel Linux).\n",
    "\n",
    "---\n",
    "\n",
    "### Esempio di flusso reale:\n",
    "\n",
    "Quando esegui:\n",
    "\n",
    "```bash\n",
    "docker run -d -p 8000:8000 --name crew_backend crewai:latest\n",
    "```\n",
    "\n",
    "accade in realtà questo:\n",
    "\n",
    "1. Il client Docker invia la richiesta al daemon (`dockerd`).\n",
    "2. Il daemon controlla se l’immagine `crewai:latest` esiste localmente.\n",
    "\n",
    "   * Se no, la scarica dal registry.\n",
    "3. Crea un container a partire dall’immagine.\n",
    "4. Isola il processo, assegna rete, volumi e risorse.\n",
    "5. Avvia il container e monitora il suo stato.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Le Immagini**\n",
    "\n",
    "Un’immagine è un **pacchetto immutabile** che contiene:\n",
    "\n",
    "* un sistema operativo minimale (es. Debian Slim),\n",
    "* tutte le dipendenze necessarie,\n",
    "* e il tuo codice (CrewAI, Qdrant, Streamlit, ecc.).\n",
    "\n",
    "Ogni immagine è composta da **layer**, ognuno dei quali rappresenta una modifica:\n",
    "\n",
    "* layer di base (es. Python),\n",
    "* layer con le librerie installate,\n",
    "* layer con il codice dell’applicazione.\n",
    "\n",
    "Esempio di Dockerfile semplificato:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Quando la build parte, ogni comando crea un layer.\n",
    "Docker li **mette in cache**, quindi se non modifichi `requirements.txt`, non ricostruisce tutto da zero.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. I Container**\n",
    "\n",
    "Il **container** è l’istanza in esecuzione di un’immagine.\n",
    "È un processo isolato, con il suo filesystem, rete e risorse dedicate.\n",
    "\n",
    "Concettualmente:\n",
    "\n",
    "* un’immagine è come una **classe** in programmazione;\n",
    "* un container è **un oggetto** istanziato da quella classe.\n",
    "\n",
    "Puoi avere più container dalla stessa immagine:\n",
    "\n",
    "```bash\n",
    "docker run -d --name crewai1 crewai:latest\n",
    "docker run -d --name crewai2 crewai:latest\n",
    "```\n",
    "\n",
    "Entrambi eseguono lo stesso codice, ma in ambienti separati.\n",
    "\n",
    "I container sono **ephemeral**: se li elimini (`docker rm`), spariscono, ma puoi sempre ricrearli dalla stessa immagine.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Il Registry**\n",
    "\n",
    "Il **registry** è un archivio remoto per immagini Docker.\n",
    "I più noti sono:\n",
    "\n",
    "* **Docker Hub** (pubblico),\n",
    "* **GitHub Container Registry (GHCR)**,\n",
    "* **GitLab Container Registry**,\n",
    "* o registry privati aziendali (es. AWS ECR, Azure Container Registry).\n",
    "\n",
    "Il registry è per le immagini ciò che GitHub è per il codice:\n",
    "ti permette di **versionare**, **condividere** e **distribuire** in modo centralizzato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker build -t myorg/crewai-backend:1.0 .\n",
    "docker push myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "Ora chiunque, da un’altra macchina, può eseguire:\n",
    "\n",
    "```bash\n",
    "docker run myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "e avrà esattamente il tuo ambiente.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Schema riassuntivo**\n",
    "\n",
    "```\n",
    "┌────────────────────────────┐\n",
    "│        Docker Client       │\n",
    "│ (CLI / Docker Desktop UI)  │\n",
    "└────────────┬───────────────┘\n",
    "             │ API REST\n",
    "┌────────────▼───────────────┐\n",
    "│       Docker Daemon        │\n",
    "│     (dockerd in Linux)     │\n",
    "│  ┌───────────────┬────────┐│\n",
    "│  │   Images      │   Vol. ││\n",
    "│  │   Containers  │   Net. ││\n",
    "│  └───────────────┴────────┘│\n",
    "└────────────┬────────────────\n",
    "             │ Pull / Push\n",
    "┌────────────▼───────────────┐\n",
    "│       Docker Registry      │\n",
    "│ (Docker Hub / GHCR / ECR)  │\n",
    "└────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Come si lega all’AI engineering**\n",
    "\n",
    "Capire l’architettura Docker serve anche a **diagnosticare errori frequenti** in ambienti AI:\n",
    "\n",
    "* Se un container non parte, non è “Docker rotto”: è il daemon che non riceve o non riesegue il processo.\n",
    "* Se un’immagine non viene trovata, il problema è nel registry o nei permessi di push/pull.\n",
    "* Se un volume non si monta, è la gestione del layer filesystem del daemon.\n",
    "\n",
    "In pipeline AI con CrewAI, Qdrant e Streamlit, tutto ruota intorno a questo flusso:\n",
    "\n",
    "* il **client** (Compose o CLI) invia la configurazione;\n",
    "* il **daemon** crea i servizi come container isolati;\n",
    "* le **immagini** rappresentano ogni microservizio AI;\n",
    "* i **registry** custodiscono le versioni deployabili.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizio pratico (15 minuti)**\n",
    "\n",
    "1. Esegui:\n",
    "\n",
    "   ```bash\n",
    "   docker run hello-world\n",
    "   ```\n",
    "\n",
    "   Poi verifica cosa accade nel daemon con:\n",
    "\n",
    "   ```bash\n",
    "   docker ps -a\n",
    "   docker images\n",
    "   docker info\n",
    "   ```\n",
    "2. Scarica manualmente un’immagine:\n",
    "\n",
    "   ```bash\n",
    "   docker pull python:3.11-slim\n",
    "   ```\n",
    "\n",
    "   e osserva i layer scaricati.\n",
    "3. Ispeziona l’immagine:\n",
    "\n",
    "   ```bash\n",
    "   docker inspect python:3.11-slim\n",
    "   ```\n",
    "\n",
    "Capirai come **client**, **daemon** e **registry** interagiscono nel mondo reale.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd26bc2-61db-4ad0-921f-c4dc480924b1",
   "metadata": {},
   "source": [
    "\n",
    "# **1.4 – Come Docker gestisce librerie pesanti (Torch, CUDA, ROCm, Transformers)**\n",
    "\n",
    "Quando si containerizza un’applicazione AI, non si parla più solo di Python e dipendenze leggere.\n",
    "L’ambiente deve spesso includere:\n",
    "\n",
    "* **PyTorch** o **TensorFlow**, librerie enormi con binding nativi in C++ o CUDA;\n",
    "* **CUDA Toolkit** o **ROCm**, per l’accelerazione su GPU NVIDIA o AMD;\n",
    "* **Transformers** e modelli LLM, spesso di diversi GB di peso.\n",
    "\n",
    "Docker può gestire tutto questo in modo efficiente, ma serve capire come funziona “sotto il cofano”.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Docker e le librerie native**\n",
    "\n",
    "Una libreria come `torch` non è solo Python puro: include componenti compilati in C/C++ e spesso richiede l’accesso diretto a driver e device hardware.\n",
    "\n",
    "Nel sistema host, queste librerie vengono installate con il supporto nativo del sistema operativo (es. `/usr/lib/cuda`).\n",
    "Nel container, invece, **non esiste nulla di preinstallato**: devi fornire tu l’ambiente completo.\n",
    "\n",
    "Docker lo risolve in due modi:\n",
    "\n",
    "1. usando **immagini base specifiche per GPU**, già predisposte da NVIDIA o AMD;\n",
    "2. esponendo i **driver GPU dell’host** al container tramite un layer d’integrazione (NVIDIA Container Toolkit o ROCm runtime).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Immagini base NVIDIA e CUDA**\n",
    "\n",
    "NVIDIA mantiene immagini ufficiali con CUDA e PyTorch preconfigurati, ad esempio:\n",
    "\n",
    "* `nvidia/cuda`\n",
    "* `pytorch/pytorch`\n",
    "* `tensorflow/tensorflow`\n",
    "\n",
    "Queste immagini contengono:\n",
    "\n",
    "* il sistema operativo base (Ubuntu o Debian),\n",
    "* CUDA Toolkit (compilatori, librerie, runtime),\n",
    "* i driver utente per l’accelerazione GPU,\n",
    "* e a volte anche PyTorch preinstallato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Quando esegui il container, puoi dare accesso alla GPU dell’host:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all my-ai-container\n",
    "```\n",
    "\n",
    "Il container non ha bisogno di driver NVIDIA interni: utilizza quelli **già presenti sull’host**, esposti attraverso il toolkit.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. NVIDIA Container Toolkit**\n",
    "\n",
    "Il **NVIDIA Container Toolkit** è ciò che permette a Docker di parlare con la GPU.\n",
    "Funziona come un ponte tra il sistema host e il container.\n",
    "\n",
    "Installazione (Linux):\n",
    "\n",
    "```bash\n",
    "sudo apt install -y nvidia-container-toolkit\n",
    "sudo systemctl restart docker\n",
    "```\n",
    "\n",
    "Dopo questa configurazione, puoi:\n",
    "\n",
    "* lanciare container con GPU accessibile (`--gpus all`);\n",
    "* monitorare la GPU dal container (`nvidia-smi`);\n",
    "* eseguire modelli Torch e TensorFlow accelerati.\n",
    "\n",
    "Senza questo toolkit, Docker non può accedere alle GPU dell’host, perché il kernel non “vede” i device.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. ROCm e GPU AMD**\n",
    "\n",
    "Per GPU AMD, il meccanismo è simile ma basato su **ROCm** (Radeon Open Compute).\n",
    "AMD fornisce immagini ufficiali con supporto ROCm preinstallato, ad esempio:\n",
    "\n",
    "* `rocm/pytorch`\n",
    "* `rocm/tensorflow`\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM rocm/pytorch:latest\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "CMD [\"python\", \"train.py\"]\n",
    "```\n",
    "\n",
    "L’host deve avere i driver ROCm installati e accessibili.\n",
    "Docker non gestisce direttamente la GPU AMD: la espone come device `/dev/kfd` o `/dev/dri`, e il container la utilizza tramite i runtime ROCm interni.\n",
    "\n",
    "Avvio:\n",
    "\n",
    "```bash\n",
    "docker run --device=/dev/kfd --device=/dev/dri my-rocm-container\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Transformers e modelli di grandi dimensioni**\n",
    "\n",
    "Le librerie **Transformers** e **Diffusers** di Hugging Face portano un’altra sfida: i modelli sono enormi (GB di pesi binari), spesso scaricati da remoto.\n",
    "\n",
    "Best practice:\n",
    "\n",
    "* monta una **cache condivisa** per i modelli, per non riscaricarli a ogni build;\n",
    "* non includere i pesi dentro l’immagine Docker;\n",
    "* usa un volume dedicato o un percorso esterno.\n",
    "\n",
    "Esempio in Compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  crewai:\n",
    "    build: .\n",
    "    volumes:\n",
    "      - ./models:/root/.cache/huggingface\n",
    "```\n",
    "\n",
    "In questo modo:\n",
    "\n",
    "* i modelli restano persistenti anche se ricrei il container;\n",
    "* più container possono condividere la stessa cache.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Dimensioni delle immagini e ottimizzazione**\n",
    "\n",
    "Quando si aggiungono PyTorch, CUDA e Transformers, le immagini possono facilmente superare i **5–10 GB**.\n",
    "Per ottimizzarle:\n",
    "\n",
    "1. **Usa multi-stage build**\n",
    "\n",
    "   * Compila o installa solo ciò che serve in un primo stage.\n",
    "   * Copia solo i binari finali nello stage runtime.\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel as build\n",
    "   RUN pip install crewai qdrant-client\n",
    "\n",
    "   FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "   COPY --from=build /opt/conda /opt/conda\n",
    "   CMD [\"python\", \"main.py\"]\n",
    "   ```\n",
    "\n",
    "2. **Evita apt inutili**\n",
    "\n",
    "   * Ogni `RUN apt-get install` crea un layer.\n",
    "   * Pulisci la cache (`rm -rf /var/lib/apt/lists/*`).\n",
    "\n",
    "3. **Usa immagini “slim” o “runtime”**\n",
    "\n",
    "   * Le immagini `-devel` contengono compilatori e header (necessari solo in build).\n",
    "   * In produzione basta `-runtime`.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Testare GPU e librerie in container**\n",
    "\n",
    "Per verificare che Docker stia usando correttamente la GPU:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all --rm pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime nvidia-smi\n",
    "```\n",
    "\n",
    "Output atteso:\n",
    "\n",
    "```\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.40       Driver Version: 550.40       CUDA Version: 12.1     |\n",
    "| GPU Name: RTX 4090      Memory Usage: 2345MiB / 24576MiB                    |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "Poi, per testare Torch:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "→ `True`\n",
    "\n",
    "Questo conferma che il container accede ai driver GPU host e può eseguire modelli accelerati.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Integrazione con CrewAI e Qdrant**\n",
    "\n",
    "Quando costruisci pipeline reali con **CrewAI**, **Qdrant** e **LLM**, separa sempre i componenti:\n",
    "\n",
    "* il container “AI compute” (PyTorch, Transformers, CUDA/ROCm);\n",
    "* il container “vector DB” (Qdrant o Milvus);\n",
    "* e il container “interface” (Streamlit o FastAPI).\n",
    "\n",
    "Questo approccio:\n",
    "\n",
    "* evita conflitti tra librerie native (Torch, Rust, SQLite, ecc.),\n",
    "* riduce le dimensioni di ciascun container,\n",
    "* permette di scalare indipendentemente il componente AI compute.\n",
    "\n",
    "Esempio di Compose parziale:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  ai-compute:\n",
    "    build: ./ai\n",
    "    deploy:\n",
    "      resources:\n",
    "        reservations:\n",
    "          devices:\n",
    "            - capabilities: [gpu]\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "  streamlit:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Riepilogo concettuale**\n",
    "\n",
    "| Elemento                                    | Ruolo in Docker                                          | Note                                                     |\n",
    "| ------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n",
    "| **PyTorch / TensorFlow**                    | Librerie Python con binding C/CUDA                       | Devono essere installate su immagini compatibili con GPU |\n",
    "| **CUDA / ROCm**                             | Layer di accesso GPU                                     | Esposto dal sistema host, non incluso nei container      |\n",
    "| **Transformers / Diffusers**                | Framework LLM e modelli                                  | Gestire cache e volumi condivisi                         |\n",
    "| **NVIDIA Container Toolkit / ROCm runtime** | Ponte hardware → container                               | Necessario per esporre device GPU                        |\n",
    "| **Best practice**                           | Usa immagini preconfigurate, multi-stage e cache modelli | Evita build pesanti e duplicazione di dati               |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dab0bb-b62c-40bb-b5af-7a9c6fd12f54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.5 – Setup ambiente (Windows): installazione Docker Desktop e configurazione GPU (NVIDIA o ROCm)**\n",
    "\n",
    "Su Windows, Docker non viene eseguito nativamente: lavora all’interno di una macchina virtuale Linux gestita dal **motore WSL 2 (Windows Subsystem for Linux)**.\n",
    "Questo è il componente che permette a Docker di avere un vero kernel Linux e quindi di eseguire correttamente container basati su immagini come `python:3.11-slim`, `pytorch/pytorch`, o `qdrant/qdrant`.\n",
    "\n",
    "L’obiettivo di questo setup è garantire:\n",
    "\n",
    "* un’installazione pulita e stabile di Docker Desktop;\n",
    "* l’attivazione di **WSL 2** e del **kernel Linux**;\n",
    "* il corretto **accesso alla GPU** (NVIDIA o AMD) da parte dei container;\n",
    "* la possibilità di eseguire stack AI completi (CrewAI + Qdrant + Streamlit) con accelerazione hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Prerequisiti di sistema**\n",
    "\n",
    "### Requisiti minimi\n",
    "\n",
    "* **Windows 10** (versione 2004 o superiore) oppure **Windows 11**\n",
    "* **64 bit**\n",
    "* **CPU con virtualizzazione hardware abilitata** (Intel VT-x o AMD-V)\n",
    "* Almeno **8 GB di RAM** (consigliati 16 GB per AI)\n",
    "* Connessione Internet per scaricare immagini e tool\n",
    "\n",
    "### Requisiti GPU\n",
    "\n",
    "* **Per NVIDIA:** driver 470+ e toolkit CUDA 11 o superiore\n",
    "* **Per AMD:** driver ROCm 6.0+ con supporto a HIP (solo Windows 11 attualmente sperimentale)\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Installazione di WSL 2**\n",
    "\n",
    "WSL 2 è il motore Linux su cui Docker Desktop si appoggia.\n",
    "Per installarlo:\n",
    "\n",
    "Apri **PowerShell come Amministratore** e digita:\n",
    "\n",
    "```bash\n",
    "wsl --install\n",
    "```\n",
    "\n",
    "Questo comando:\n",
    "\n",
    "* attiva i componenti “Piattaforma macchina virtuale” e “Sottosistema Windows per Linux”;\n",
    "* installa automaticamente Ubuntu come distribuzione predefinita;\n",
    "* abilita il kernel Linux.\n",
    "\n",
    "Dopo il riavvio, verifica che tutto sia attivo:\n",
    "\n",
    "```bash\n",
    "wsl -l -v\n",
    "```\n",
    "\n",
    "Dovresti vedere un output simile a:\n",
    "\n",
    "```\n",
    "  NAME      STATE           VERSION\n",
    "* Ubuntu    Running         2\n",
    "```\n",
    "\n",
    "Se `VERSION` è 1, aggiorna con:\n",
    "\n",
    "```bash\n",
    "wsl --set-version Ubuntu 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Installazione di Docker Desktop**\n",
    "\n",
    "1. Vai al sito ufficiale:\n",
    "   🔗 [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)\n",
    "2. Scarica **Docker Desktop for Windows**.\n",
    "3. Durante l’installazione, **assicurati di selezionare “Use WSL 2 based engine”**.\n",
    "4. Dopo l’installazione, riavvia il sistema.\n",
    "5. Avvia Docker Desktop e apri il terminale PowerShell o Ubuntu WSL per testare:\n",
    "\n",
    "   ```bash\n",
    "   docker run hello-world\n",
    "   ```\n",
    "\n",
    "   Se il messaggio dice “Hello from Docker!”, l’installazione è riuscita.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Configurazione GPU – NVIDIA**\n",
    "\n",
    "Per usare PyTorch o TensorFlow con accelerazione GPU all’interno di container, serve il **NVIDIA Container Toolkit**.\n",
    "\n",
    "### Passaggi\n",
    "\n",
    "1. Assicurati che i driver NVIDIA siano aggiornati:\n",
    "\n",
    "   * Apri `nvidia-smi` nel prompt.\n",
    "     Se restituisce un output valido, i driver sono attivi.\n",
    "\n",
    "2. Installa **NVIDIA Container Toolkit** (dalla WSL Ubuntu):\n",
    "\n",
    "   ```bash\n",
    "   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n",
    "   curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n",
    "   curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n",
    "     sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
    "   sudo apt-get update\n",
    "   sudo apt-get install -y nvidia-container-toolkit\n",
    "   sudo systemctl restart docker\n",
    "   ```\n",
    "\n",
    "3. Verifica:\n",
    "\n",
    "   ```bash\n",
    "   docker run --rm --gpus all nvidia/cuda:12.1-base nvidia-smi\n",
    "   ```\n",
    "\n",
    "   Se compare la tua GPU, Docker è configurato per CUDA.\n",
    "\n",
    "4. Ora puoi eseguire modelli CrewAI o Torch nel container:\n",
    "\n",
    "   ```bash\n",
    "   docker run --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "   ```\n",
    "\n",
    "   Output atteso: `True`\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Configurazione GPU – AMD (ROCm)**\n",
    "\n",
    "> ⚠️ Su Windows il supporto ROCm via Docker è ancora **sperimentale**.\n",
    "> Si consiglia di usare **Ubuntu WSL** con ROCm installato o, meglio, una macchina Linux nativa.\n",
    "\n",
    "Per sistemi che supportano ROCm (es. RX 7900 XTX, MI 210, ecc.):\n",
    "\n",
    "1. Installa driver ROCm per Windows 11:\n",
    "   🔗 [https://www.amd.com/en/developer/resources/rocm.html](https://www.amd.com/en/developer/resources/rocm.html)\n",
    "2. Installa Docker Desktop come sopra.\n",
    "3. Apri WSL Ubuntu e verifica la presenza dei device:\n",
    "\n",
    "   ```bash\n",
    "   ls /dev | grep kfd\n",
    "   ```\n",
    "4. Avvia container ROCm:\n",
    "\n",
    "   ```bash\n",
    "   docker run --device=/dev/kfd --device=/dev/dri rocm/pytorch:latest\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Test finale**\n",
    "\n",
    "Una volta completata l’installazione:\n",
    "\n",
    "```bash\n",
    "docker run hello-world\n",
    "docker run -it python:3.11-slim bash\n",
    "```\n",
    "\n",
    "Se entrambi i comandi funzionano, Docker e WSL 2 sono configurati correttamente.\n",
    "\n",
    "Per GPU:\n",
    "\n",
    "* Verifica CUDA: `docker run --gpus all nvidia/cuda:12.1-base nvidia-smi`\n",
    "* Oppure PyTorch: `docker run --gpus all pytorch/pytorch python -c \"import torch; print(torch.cuda.is_available())\"`\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Consigli pratici per progetti AI**\n",
    "\n",
    "* **Disattiva “Use Windows containers”**: assicurati che Docker Desktop usi container **Linux-based**.\n",
    "* **Assegna risorse adeguate** (Settings → Resources):\n",
    "  CPU ≥ 4 core, RAM ≥ 8 GB, GPU enabled.\n",
    "* **Condividi le directory di lavoro** (Settings → Resources → File Sharing): aggiungi la cartella del progetto.\n",
    "* **Evita di costruire immagini dentro WSL** se usi IDE Windows: costruiscile da terminale Docker Desktop o da VS Code + Docker Extension per mantenere il contesto coerente.\n",
    "* **Aggiorna WSL regolarmente**:\n",
    "\n",
    "  ```bash\n",
    "  wsl --update\n",
    "  ```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab8e22-fa05-40ee-8b5f-398616d2fd39",
   "metadata": {},
   "source": [
    "# **1.6 – Comandi base e ciclo di vita di un container**\n",
    "\n",
    "Quando esegui un container, Docker lo tratta come un **processo isolato**: può essere avviato, messo in pausa, riavviato o rimosso.\n",
    "Per gestirlo, Docker fornisce una serie di comandi CLI che ti permettono di **controllare ogni fase del suo ciclo di vita**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Concetto di ciclo di vita**\n",
    "\n",
    "Un container nasce da un’immagine ed esegue un processo principale (il *command* o *entrypoint* definito nel Dockerfile).\n",
    "Dalla creazione alla rimozione, può passare attraverso vari stati:\n",
    "\n",
    "```\n",
    "created → running → stopped → removed\n",
    "```\n",
    "\n",
    "Ogni fase è gestita da comandi specifici, che vediamo subito.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `docker ps` – Visualizzare i container attivi**\n",
    "\n",
    "Mostra la lista dei container attualmente in esecuzione.\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "```\n",
    "CONTAINER ID   IMAGE                  COMMAND                  STATUS         PORTS                  NAMES\n",
    "f2a45b8c11df   qdrant/qdrant:latest   \"/usr/bin/qdrant\"        Up 5 minutes   6333/tcp, 6334/tcp    qdrant_db\n",
    "d3a21ce6c442   crewai:latest          \"python main.py\"         Up 2 minutes   8080/tcp              crew_backend\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker ps -a` → mostra **tutti i container**, anche quelli stoppati.\n",
    "* `docker ps -q` → mostra solo gli ID (utile negli script).\n",
    "* `docker ps --filter \"status=exited\"` → filtra per stato.\n",
    "\n",
    " *Uso tipico in AI pipelines:*\n",
    "Verificare che `qdrant`, `crewai` e `streamlit` siano effettivamente attivi in uno stack multi-container.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `docker exec` – Entrare o eseguire comandi dentro un container**\n",
    "\n",
    "Permette di eseguire un comando in un container già in esecuzione, o di aprire una shell interattiva.\n",
    "\n",
    "```bash\n",
    "docker exec -it <container_name> bash\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker exec -it crew_backend bash\n",
    "```\n",
    "\n",
    "Ora sei “dentro” il container come se fosse un piccolo Linux isolato.\n",
    "Puoi navigare, leggere log, o testare Python:\n",
    "\n",
    "```bash\n",
    "python\n",
    "import crewai\n",
    "```\n",
    "\n",
    "### Varianti:\n",
    "\n",
    "* `docker exec crew_backend ls /app` → esegue un singolo comando e restituisce l’output.\n",
    "* `-i` = interattivo (input), `-t` = terminale (TTY).\n",
    "\n",
    " *Esempio pratico:*\n",
    "Se il container `crewai` non risponde, puoi entrare e controllare il file `/app/main.py` o la presenza delle chiavi `.env`.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `docker logs` – Leggere i log del container**\n",
    "\n",
    "Mostra l’output standard (`stdout` e `stderr`) del processo principale del container.\n",
    "È uno dei comandi più usati per il debugging.\n",
    "\n",
    "```bash\n",
    "docker logs crew_backend\n",
    "```\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "```\n",
    "[INFO] CrewAI server started on port 8080\n",
    "[INFO] Connected to Qdrant at qdrant_db:6333\n",
    "[WARNING] Missing OpenAI API key - using fallback model\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker logs -f crew_backend` → *follow mode*, segue in tempo reale i log (come `tail -f`).\n",
    "* `docker logs --since 10m crew_backend` → mostra solo gli ultimi 10 minuti.\n",
    "* `docker logs -n 50 crew_backend` → ultimi 50 log lines.\n",
    "\n",
    " *Uso tipico:*\n",
    "Quando un microservizio AI fallisce all’avvio, questo comando mostra errori di import, di connessione o di chiavi API mancanti.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `docker inspect` – Analizzare in profondità container o immagini**\n",
    "\n",
    "Fornisce tutte le informazioni tecniche di un container o di un’immagine in formato JSON.\n",
    "È fondamentale per capire configurazioni, reti, volumi e variabili d’ambiente.\n",
    "\n",
    "```bash\n",
    "docker inspect crew_backend\n",
    "```\n",
    "\n",
    "Output (estratto semplificato):\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"Id\": \"d3a21ce6c442...\",\n",
    "    \"State\": { \"Status\": \"running\", \"Pid\": 1342 },\n",
    "    \"Mounts\": [\n",
    "      { \"Source\": \"/home/michael/app\", \"Destination\": \"/app\" }\n",
    "    ],\n",
    "    \"NetworkSettings\": {\n",
    "      \"IPAddress\": \"172.18.0.3\",\n",
    "      \"Ports\": { \"8080/tcp\": [{ \"HostPort\": \"8080\" }] }\n",
    "    },\n",
    "    \"Config\": {\n",
    "      \"Env\": [\"OPENAI_API_KEY=sk-...\", \"MODE=production\"],\n",
    "      \"Cmd\": [\"python\", \"main.py\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker inspect --format='{{.NetworkSettings.IPAddress}}' crew_backend`\n",
    "  → mostra solo l’IP interno.\n",
    "* `docker inspect -f '{{.Config.Env}}' crew_backend`\n",
    "  → mostra le variabili d’ambiente.\n",
    "\n",
    " *Uso tipico:*\n",
    "Scoprire su quale rete interna è connesso un container CrewAI per permettere a Streamlit o Qdrant di comunicare correttamente.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Comandi complementari del ciclo di vita**\n",
    "\n",
    "### Avvio e stop container\n",
    "\n",
    "```bash\n",
    "docker start crew_backend\n",
    "docker stop crew_backend\n",
    "```\n",
    "\n",
    "### Riavvio rapido\n",
    "\n",
    "```bash\n",
    "docker restart crew_backend\n",
    "```\n",
    "\n",
    "### Creazione e rimozione\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_backend crewai:latest\n",
    "docker rm crew_backend\n",
    "```\n",
    "\n",
    " *Nota:* un container rimosso non cancella l’immagine da cui è stato creato.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Visualizzare immagini e volumi**\n",
    "\n",
    "Per vedere le immagini salvate localmente:\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "```\n",
    "\n",
    "Per vedere i volumi (dove risiedono i dati persistenti):\n",
    "\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "Esempio tipico in uno stack CrewAI:\n",
    "\n",
    "```\n",
    "REPOSITORY          TAG       SIZE\n",
    "crewai              latest    2.3GB\n",
    "qdrant/qdrant       v1.10.0   650MB\n",
    "python              3.11-slim 140MB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico (20 minuti)**\n",
    "\n",
    "1. Avvia un container Python:\n",
    "\n",
    "   ```bash\n",
    "   docker run -d --name pytest python:3.11-slim sleep 300\n",
    "   ```\n",
    "2. Verifica che sia attivo:\n",
    "\n",
    "   ```bash\n",
    "   docker ps\n",
    "   ```\n",
    "3. Entra nel container:\n",
    "\n",
    "   ```bash\n",
    "   docker exec -it pytest bash\n",
    "   ```\n",
    "4. Installa qualcosa al suo interno (es. `pip install numpy`), poi esci.\n",
    "5. Leggi i log:\n",
    "\n",
    "   ```bash\n",
    "   docker logs pytest\n",
    "   ```\n",
    "6. Ispeziona:\n",
    "\n",
    "   ```bash\n",
    "   docker inspect pytest\n",
    "   ```\n",
    "7. Ferma e rimuovi:\n",
    "\n",
    "   ```bash\n",
    "   docker stop pytest\n",
    "   docker rm pytest\n",
    "   ```\n",
    "\n",
    "Questo ciclo ti mostra come **nascita, esecuzione e distruzione** di un container avvengono in modo trasparente e controllato.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Riepilogo pratico**\n",
    "\n",
    "| Comando                | Funzione principale                  | Uso tipico               |\n",
    "| ---------------------- | ------------------------------------ | ------------------------ |\n",
    "| `docker ps`            | Elenca container attivi              | Controllo dello stato    |\n",
    "| `docker exec`          | Entra o esegue comandi nel container | Debug o test rapido      |\n",
    "| `docker logs`          | Legge i log del container            | Diagnosi di errori       |\n",
    "| `docker inspect`       | Mostra configurazione completa       | Analisi rete, env, mount |\n",
    "| `docker start/stop/rm` | Gestione ciclo di vita               | Riavvio, cleanup         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d290372-c08f-4f52-95f3-a9ec7627f53a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.7 – Gestione ambienti AI interattivi (`docker run -it python:3.11 bash`)**\n",
    "\n",
    "Molti sviluppatori AI lavorano con ambienti virtuali o notebook locali, ma questo spesso porta a conflitti tra versioni di librerie, Python o CUDA.\n",
    "Con Docker puoi creare **ambienti di sviluppo temporanei e isolati**, pronti all’uso, perfetti per testare rapidamente nuove librerie, modelli o configurazioni di CrewAI.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Concetto di ambiente interattivo**\n",
    "\n",
    "Un container Docker può essere usato in due modi:\n",
    "\n",
    "* come **servizio**, in esecuzione continua (es. un backend CrewAI, un database Qdrant);\n",
    "* oppure come **ambiente interattivo**, dove lavori dentro una shell Linux pulita, come se fosse una macchina virtuale leggera.\n",
    "\n",
    "Il comando chiave è:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11 bash\n",
    "```\n",
    "\n",
    "Vediamo cosa succede in dettaglio.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Analisi del comando**\n",
    "\n",
    "| Parte         | Significato                                                        |\n",
    "| ------------- | ------------------------------------------------------------------ |\n",
    "| `docker run`  | crea e avvia un container basato su un’immagine                    |\n",
    "| `-i`          | abilita l’input interattivo (stdin aperto)                         |\n",
    "| `-t`          | assegna un terminale TTY per interazione umana                     |\n",
    "| `python:3.11` | immagine base ufficiale di Python (Debian + Python 3.11)           |\n",
    "| `bash`        | comando da eseguire all’avvio del container (avvia una shell Bash) |\n",
    "\n",
    "Il risultato è un prompt interattivo dentro un sistema Linux minimale, con Python già installato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```\n",
    "root@0a3b82f3d87c:/# python\n",
    "Python 3.11.9 (main, May 10 2024, 10:11:00)\n",
    ">>> import sys\n",
    ">>> sys.version\n",
    "'3.11.9'\n",
    "```\n",
    "\n",
    "Ora sei **dentro un container** isolato dal tuo sistema Windows o macOS, e tutto ciò che fai (installazioni, file, modifiche) resta confinato lì dentro.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Caratteristiche di un ambiente interattivo Docker**\n",
    "\n",
    "1. **Pulito:** ogni container parte sempre dallo stesso stato iniziale.\n",
    "2. **Isolato:** non interferisce con librerie o file dell’host.\n",
    "3. **Temporaneo:** se lo chiudi senza salvare, sparisce (utile per test rapidi).\n",
    "4. **Reproducibile:** puoi ricrearlo identico in ogni momento.\n",
    "5. **Leggero:** avvio in meno di un secondo.\n",
    "\n",
    " È perfetto per testare rapidamente:\n",
    "\n",
    "* librerie nuove (`pip install crewai qdrant-client`);\n",
    "* modelli (`from transformers import pipeline`);\n",
    "* bug di compatibilità (`import torch; torch.cuda.is_available()`).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Lavorare dentro il container**\n",
    "\n",
    "Una volta dentro la shell:\n",
    "\n",
    "```bash\n",
    "root@0a3b82f3d87c:/#\n",
    "```\n",
    "\n",
    "Puoi usare comandi Linux e Python normalmente:\n",
    "\n",
    "```bash\n",
    "apt update && apt install nano -y\n",
    "pip install crewai qdrant-client langchain\n",
    "python\n",
    "```\n",
    "\n",
    "Tutto funzionerà come in un vero sistema Linux, ma:\n",
    "\n",
    "* i file restano **solo nel container**;\n",
    "* quando esci (`exit` o `Ctrl+D`), il container si ferma;\n",
    "* al riavvio sarà “vuoto” se non hai salvato nulla su un volume (vedremo tra poco come farlo).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Uscire e rientrare**\n",
    "\n",
    "Esci con:\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "Il container resta fermo ma non scompare.\n",
    "Puoi vederlo con:\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "E rientrare con:\n",
    "\n",
    "```bash\n",
    "docker start -ai <container_id>\n",
    "```\n",
    "\n",
    "oppure eliminarlo:\n",
    "\n",
    "```bash\n",
    "docker rm <container_id>\n",
    "```\n",
    "\n",
    " *Consiglio*: dai un nome ai tuoi container per non confonderli:\n",
    "\n",
    "```bash\n",
    "docker run -it --name crew_env python:3.11 bash\n",
    "```\n",
    "\n",
    "Poi puoi riprenderlo facilmente:\n",
    "\n",
    "```bash\n",
    "docker start -ai crew_env\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Montare una cartella locale (persistenza)**\n",
    "\n",
    "Per evitare che tutto vada perso alla chiusura, puoi **montare una directory dell’host** nel container:\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash   # su Windows PowerShell\n",
    "```\n",
    "\n",
    "oppure\n",
    "\n",
    "```bash\n",
    "docker run -it -v $(pwd):/app python:3.11 bash # su Linux/macOS\n",
    "```\n",
    "\n",
    "Ora la cartella corrente del tuo computer è visibile in `/app` dentro il container.\n",
    "Puoi crearci file, script o notebook:\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "nano test.py\n",
    "python test.py\n",
    "```\n",
    "\n",
    "Tutto resta salvato anche dopo l’uscita, perché i file vivono nel filesystem dell’host.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Eseguire Python direttamente**\n",
    "\n",
    "Puoi saltare la shell e avviare Python in un solo step:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11\n",
    "```\n",
    "\n",
    "oppure eseguire un comando singolo:\n",
    "\n",
    "```bash\n",
    "docker run --rm python:3.11 python -c \"print('Hello AI World')\"\n",
    "```\n",
    "\n",
    "L’opzione `--rm` elimina automaticamente il container una volta terminato.\n",
    "\n",
    " *Utile per test rapidi di librerie CrewAI, LangChain, HuggingFace o Qdrant-client senza installarle localmente.*\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Testare la GPU in un ambiente interattivo**\n",
    "\n",
    "Se hai configurato NVIDIA Container Toolkit:\n",
    "\n",
    "```bash\n",
    "docker run -it --gpus all pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime bash\n",
    "```\n",
    "\n",
    "Poi dentro:\n",
    "\n",
    "```bash\n",
    "python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "→ `True` significa che Docker sta usando la tua GPU correttamente.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Pulizia e gestione**\n",
    "\n",
    "Dopo aver terminato gli esperimenti, puoi pulire facilmente:\n",
    "\n",
    "```bash\n",
    "docker ps -a            # mostra tutti i container\n",
    "docker rm <id>          # rimuove un container\n",
    "docker images           # mostra immagini\n",
    "docker rmi python:3.11  # rimuove un’immagine se vuoi liberare spazio\n",
    "```\n",
    "\n",
    " *Docker Desktop mostra tutto anche graficamente, utile per i primi tempi.*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **11. In sintesi**\n",
    "\n",
    "| Azione                       | Comando                           |\n",
    "| ---------------------------- | --------------------------------- |\n",
    "| Avvia ambiente interattivo   | `docker run -it python:3.11 bash` |\n",
    "| Assegna un nome al container | `--name crew_env`                 |\n",
    "| Monta una directory locale   | `-v %cd%:/app`                    |\n",
    "| Riaccedi al container        | `docker start -ai crew_env`       |\n",
    "| Elimina container e immagine | `docker rm` / `docker rmi`        |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8d414-7e4a-4edb-9f43-0b208bdd5414",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **Docker – Recap dei Comandi Fondamentali**\n",
    "\n",
    "| **Comando**                                                      | **Funzione**                                              | **Esempio pratico / Descrizione**                                       |\n",
    "| ---------------------------------------------------------------- | --------------------------------------------------------- | ----------------------------------------------------------------------- |\n",
    "| `docker run <img>`                                               | Crea e avvia un container da un’immagine                  | `docker run hello-world` → esegue un test di installazione              |\n",
    "| `docker run -it <img> bash`                                      | Avvia un container **interattivo** con terminale          | `docker run -it python:3.11 bash` → entra in un ambiente Python isolato |\n",
    "| `docker run -it --name <nome>`                                   | Crea container con nome personalizzato                    | `docker run -it --name crew_env python:3.11 bash`                       |\n",
    "| `docker run --rm <img>`                                          | Esegue container temporaneo e lo elimina alla chiusura    | `docker run --rm python:3.11 python -c \"print('Hello')\"`                |\n",
    "| `docker run -v <path_host>:<path_container>`                     | Monta una cartella locale dentro il container             | `docker run -it -v %cd%:/app python:3.11 bash`                          |\n",
    "| `docker run --gpus all <img>`                                    | Espone GPU NVIDIA/AMD al container                        | `docker run --gpus all pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime`   |\n",
    "| `docker ps`                                                      | Mostra i container attivi                                 | `docker ps` → elenca solo quelli in esecuzione                          |\n",
    "| `docker ps -a`                                                   | Mostra tutti i container, inclusi quelli fermati          | Utile per controllare container creati o terminati                      |\n",
    "| `docker exec -it <container> bash`                               | Apre shell Bash dentro un container attivo                | `docker exec -it crew_backend bash`                                     |\n",
    "| `docker exec <container> <cmd>`                                  | Esegue un singolo comando dentro un container             | `docker exec crew_backend ls /app`                                      |\n",
    "| `docker logs <container>`                                        | Mostra i log standard del container                       | `docker logs -f crew_backend` → segue in tempo reale i log              |\n",
    "| `docker inspect <container>`                                     | Mostra info dettagliate (rete, mount, env, porte)         | `docker inspect qdrant_db`                                              |\n",
    "| `docker inspect -f '{{.NetworkSettings.IPAddress}}' <container>` | Estrae solo l’IP interno del container                    | utile per connessioni manuali tra servizi                               |\n",
    "| `docker images`                                                  | Elenca tutte le immagini salvate localmente               | Mostra repository, tag, dimensione e ID                                 |\n",
    "| `docker pull <img>`                                              | Scarica un’immagine dal registry (Docker Hub, GHCR, ecc.) | `docker pull python:3.11-slim`                                          |\n",
    "| `docker build -t <nome>:<tag> .`                                 | Crea un’immagine a partire da un Dockerfile               | `docker build -t crewai-backend:1.0 .`                                  |\n",
    "| `docker tag <img> <registry>/<repo>:<tag>`                       | Aggiunge un tag per pushare un’immagine                   | `docker tag crewai:1.0 myorg/crewai:1.0`                                |\n",
    "| `docker push <repo>`                                             | Carica un’immagine sul registry remoto                    | `docker push myorg/crewai:1.0`                                          |\n",
    "| `docker start <container>`                                       | Riavvia un container fermato                              | `docker start crew_backend`                                             |\n",
    "| `docker stop <container>`                                        | Ferma un container attivo                                 | `docker stop crew_backend`                                              |\n",
    "| `docker restart <container>`                                     | Riavvia il container (stop + start)                       | utile per applicare aggiornamenti                                       |\n",
    "| `docker rm <container>`                                          | Rimuove un container fermo                                | `docker rm crew_backend`                                                |\n",
    "| `docker rmi <image>`                                             | Rimuove un’immagine locale                                | `docker rmi python:3.11-slim`                                           |\n",
    "| `docker volume ls`                                               | Elenca i volumi persistenti                               | utile per dataset, modelli o DB                                         |\n",
    "| `docker network ls`                                              | Elenca le reti Docker                                     | utile per capire come comunicano i microservizi                         |\n",
    "| `docker compose up -d`                                           | Avvia più container definiti in `docker-compose.yml`      | `docker compose up -d` → lancia CrewAI + Qdrant + Streamlit             |\n",
    "| `docker compose down`                                            | Ferma e rimuove tutti i container dello stack             | Cleanup completo di uno stack AI                                        |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120d9fe-a5db-4aa3-a201-a66268bfeb28",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **Esercizi sui comandi base Docker**\n",
    "\n",
    "---\n",
    "\n",
    "##  **SEZIONE 1 – TRACCE (per esercitarsi in autonomia)**\n",
    "\n",
    "### 🔹 **Esercizio 1 – Primo container interattivo**\n",
    "\n",
    "Crea un container interattivo basato su `python:3.11`, entra al suo interno, installa qualche libreria AI (es. `crewai` e `qdrant-client`), e verifica che funzioni.\n",
    "Chiudi il container e scopri se al riavvio le librerie sono ancora presenti.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 2 – Persistenza tramite volume**\n",
    "\n",
    "Ripeti l’esercizio 1, ma questa volta monta una cartella locale in `/app` dentro il container, salva un file Python e verifica che resti sul disco anche dopo aver chiuso il container.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 3 – Creare e rinominare container**\n",
    "\n",
    "Crea due container basati su `python:3.11`:\n",
    "\n",
    "* uno con il nome `crew_test`\n",
    "* uno con il nome `qdrant_test`\n",
    "\n",
    "Elenca i container, fermali e rimuovili entrambi.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 4 – Esaminare container attivi**\n",
    "\n",
    "Esegui un container in background (`-d`) basato su `python:3.11-slim` che esegua il comando:\n",
    "\n",
    "```bash\n",
    "python -c \"import time; [print('running...') or time.sleep(2) for _ in range(5)]\"\n",
    "```\n",
    "\n",
    "Poi:\n",
    "\n",
    "1. Controlla che sia attivo.\n",
    "2. Leggi i log del container.\n",
    "3. Ispeziona la sua configurazione (IP, comando, stato).\n",
    "4. Attendi che termini e verifica lo stato con `docker ps -a`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 5 – Interagire con un container esistente**\n",
    "\n",
    "Crea un container in background con:\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_env python:3.11 sleep 300\n",
    "```\n",
    "\n",
    "Poi:\n",
    "\n",
    "* entra dentro il container con `docker exec -it`;\n",
    "* crea un file `test.txt`;\n",
    "* leggi il contenuto dall’host senza entrare nel container;\n",
    "* infine fermalo e rimuovilo.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 6 – Analisi dettagliata**\n",
    "\n",
    "Crea un container basato su `python:3.11`, assegnagli un nome (`analyze_me`) e avvialo.\n",
    "Usa `docker inspect` per:\n",
    "\n",
    "1. Estrarre il suo indirizzo IP interno;\n",
    "2. Verificare il comando di avvio;\n",
    "3. Controllare se ha variabili d’ambiente predefinite.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 7 – Pulizia e gestione immagini**\n",
    "\n",
    "1. Elenca le immagini presenti sul tuo sistema.\n",
    "2. Cancella le immagini che non ti servono.\n",
    "3. Rimuovi tutti i container non più in uso.\n",
    "4. Pulisci il sistema con `docker system prune`.\n",
    "5. Controlla quanto spazio hai liberato.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#  **SEZIONE 2 – SOLUZIONI GUIDATE PASSO PASSO**\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 1 – Primo container interattivo**\n",
    "\n",
    "**1. Avvia il container:**\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11 bash\n",
    "```\n",
    "\n",
    "**2. All’interno:**\n",
    "\n",
    "```bash\n",
    "pip install crewai qdrant-client\n",
    "python -c \"import crewai, qdrant_client; print('ok')\"\n",
    "```\n",
    "\n",
    "**3. Esci:**\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "**4. Controlla lo stato:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "Il container è fermo ma ancora presente.\n",
    "Riavvialo:\n",
    "\n",
    "```bash\n",
    "docker start -ai <container_id>\n",
    "```\n",
    "\n",
    "Verifica: le librerie **non sono più installate** — il container è effimero.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 2 – Persistenza tramite volume**\n",
    "\n",
    "**1. Avvia il container con volume montato:**\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash\n",
    "```\n",
    "\n",
    "(su Linux/macOS: `-v $(pwd):/app`)\n",
    "\n",
    "**2. All’interno del container:**\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "echo \"print('Hello from Docker')\" > hello.py\n",
    "python hello.py\n",
    "```\n",
    "\n",
    "**3. Esci e controlla nella cartella locale:**\n",
    "Il file `hello.py` è rimasto → la persistenza funziona.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 3 – Creare e rinominare container**\n",
    "\n",
    "**1. Crea i container:**\n",
    "\n",
    "```bash\n",
    "docker run -it --name crew_test python:3.11 bash\n",
    "docker run -it --name qdrant_test python:3.11 bash\n",
    "```\n",
    "\n",
    "(esci subito da entrambi con `exit`)\n",
    "\n",
    "**2. Elenca i container:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "**3. Ferma e rimuovi:**\n",
    "\n",
    "```bash\n",
    "docker stop crew_test qdrant_test\n",
    "docker rm crew_test qdrant_test\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 4 – Esaminare container attivi**\n",
    "\n",
    "**1. Esegui in background:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name test_logger python:3.11-slim python -c \"import time; [print('running...') or time.sleep(2) for _ in range(5)]\"\n",
    "```\n",
    "\n",
    "**2. Controlla stato:**\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "**3. Leggi log:**\n",
    "\n",
    "```bash\n",
    "docker logs test_logger\n",
    "```\n",
    "\n",
    "**4. Ispeziona:**\n",
    "\n",
    "```bash\n",
    "docker inspect test_logger\n",
    "```\n",
    "\n",
    "**5. Dopo 10 secondi:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "Il container avrà `STATUS: Exited`.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 5 – Interagire con un container esistente**\n",
    "\n",
    "**1. Avvia container in background:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_env python:3.11 sleep 300\n",
    "```\n",
    "\n",
    "**2. Entra dentro:**\n",
    "\n",
    "```bash\n",
    "docker exec -it crew_env bash\n",
    "```\n",
    "\n",
    "**3. Crea file:**\n",
    "\n",
    "```bash\n",
    "echo \"Docker test OK\" > /tmp/test.txt\n",
    "exit\n",
    "```\n",
    "\n",
    "**4. Leggi contenuto da host:**\n",
    "\n",
    "```bash\n",
    "docker exec crew_env cat /tmp/test.txt\n",
    "```\n",
    "\n",
    "**5. Ferma e rimuovi:**\n",
    "\n",
    "```bash\n",
    "docker stop crew_env\n",
    "docker rm crew_env\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 6 – Analisi dettagliata**\n",
    "\n",
    "**1. Crea container:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name analyze_me python:3.11 sleep 60\n",
    "```\n",
    "\n",
    "**2. Estrarre IP:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.NetworkSettings.IPAddress}}' analyze_me\n",
    "```\n",
    "\n",
    "**3. Comando di avvio:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.Config.Cmd}}' analyze_me\n",
    "```\n",
    "\n",
    "**4. Variabili d’ambiente:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.Config.Env}}' analyze_me\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 7 – Pulizia e gestione immagini**\n",
    "\n",
    "**1. Elenca immagini e container:**\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "**2. Cancella tutto ciò che non serve:**\n",
    "\n",
    "```bash\n",
    "docker rm $(docker ps -aq)\n",
    "docker rmi $(docker images -q)\n",
    "```\n",
    "\n",
    "**3. Pulizia generale:**\n",
    "\n",
    "```bash\n",
    "docker system prune -af\n",
    "```\n",
    "\n",
    "**4. Controlla spazio:**\n",
    "\n",
    "```bash\n",
    "docker system df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff3bc-c9c1-4bbf-9122-da8517d59d2c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.8 – Persistenza notebook/data (`-v`, `--mount`, `--network`)**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema della volatilità nei container**\n",
    "\n",
    "Per impostazione predefinita, i container Docker sono **temporanei**.\n",
    "Se li elimini, tutto ciò che era stato scritto dentro (file, notebook, database, modelli scaricati) sparisce.\n",
    "Questo comportamento è ottimo per test e build pulite, ma in progetti AI è **inaccettabile**:\n",
    "\n",
    "* vogliamo mantenere **dataset e notebook** tra sessioni,\n",
    "* salvare **cache di modelli Hugging Face**,\n",
    "* preservare **indici vettoriali di Qdrant** o **file SQLite di CrewAI**.\n",
    "\n",
    "Docker offre due modi principali per salvare i dati:\n",
    "\n",
    "* **Volumi** (gestiti da Docker, con `-v` o `--mount`)\n",
    "* **Bind mount** (collega una cartella dell’host)\n",
    "\n",
    "Vediamoli nel dettaglio.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Persistenza con `-v` (bind mount)**\n",
    "\n",
    "Il metodo più semplice e immediato per rendere persistenti i dati è collegare una **cartella locale dell’host** a una directory del container.\n",
    "\n",
    "### Esempio:\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash   # Windows PowerShell\n",
    "```\n",
    "\n",
    "oppure su Linux/macOS:\n",
    "\n",
    "```bash\n",
    "docker run -it -v $(pwd):/app python:3.11 bash\n",
    "```\n",
    "\n",
    "All’interno del container, tutto ciò che scrivi in `/app` viene salvato nella tua directory locale.\n",
    "\n",
    "### Test rapido:\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "echo \"print('Persistente!')\" > test.py\n",
    "exit\n",
    "```\n",
    "\n",
    "Il file `test.py` esiste ancora nel tuo computer locale.\n",
    "\n",
    " **Uso tipico in AI:**\n",
    "\n",
    "* salvare notebook Jupyter (`.ipynb`);\n",
    "* scrivere output JSON o CSV di CrewAI;\n",
    "* mantenere la cache Hugging Face (`/root/.cache/huggingface`).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Persistenza con `--mount` (volumi gestiti da Docker)**\n",
    "\n",
    "`--mount` è un metodo più moderno e leggibile rispetto a `-v`.\n",
    "Offre maggiore controllo e chiarezza, soprattutto negli script o nei file Compose.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```bash\n",
    "docker run -it --mount type=bind,source=%cd%,target=/app python:3.11 bash\n",
    "```\n",
    "\n",
    "Equivalente a `-v %cd%:/app`, ma più esplicito e robusto.\n",
    "Puoi anche montare **volumi gestiti da Docker**, non solo cartelle locali.\n",
    "\n",
    "### Esempio con volume Docker:\n",
    "\n",
    "```bash\n",
    "docker volume create crew_data\n",
    "docker run -it --mount source=crew_data,target=/app python:3.11 bash\n",
    "```\n",
    "\n",
    "Tutto ciò che salvi in `/app` è conservato nel volume, anche se elimini il container.\n",
    "Puoi elencare i volumi:\n",
    "\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "e ispezionarli:\n",
    "\n",
    "```bash\n",
    "docker volume inspect crew_data\n",
    "```\n",
    "\n",
    " **Uso tipico in AI:**\n",
    "\n",
    "* salvare database Qdrant (`/qdrant/storage`),\n",
    "* dati CrewAI (`/data`),\n",
    "* cache modelli condivisa tra più container.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Differenza tra `-v` e `--mount`**\n",
    "\n",
    "| Caratteristica  | `-v`                   | `--mount`                               |\n",
    "| --------------- | ---------------------- | --------------------------------------- |\n",
    "| Sintassi        | più corta              | più leggibile e sicura                  |\n",
    "| Tipo            | supporta bind e volume | supporta bind, volume e tmpfs           |\n",
    "| Specificità     | stringa unica          | parametri chiari (type, source, target) |\n",
    "| Consigliato per | uso rapido             | ambienti complessi o Compose file       |\n",
    "\n",
    " In produzione e in file `docker-compose.yml`, **usa sempre `--mount`** o la forma YAML di `volumes:`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Persistenza di notebook e dati**\n",
    "\n",
    "Se vuoi eseguire **Jupyter Notebook in container**, devi montare la directory del progetto:\n",
    "\n",
    "```bash\n",
    "docker run -it -p 8888:8888 -v %cd%:/notebooks jupyter/base-notebook\n",
    "```\n",
    "\n",
    "Apri il browser su `localhost:8888` e troverai tutti i tuoi file locali visibili in `/notebooks`.\n",
    "\n",
    "Ogni notebook salvato lì resta anche dopo il riavvio del container.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Persistenza dei modelli AI**\n",
    "\n",
    "Le librerie Hugging Face salvano modelli scaricati in:\n",
    "\n",
    "```\n",
    "~/.cache/huggingface\n",
    "```\n",
    "\n",
    "Se vuoi evitare di riscaricarli ogni volta, monta la cache come volume persistente:\n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "  -v %USERPROFILE%\\.cache\\huggingface:/root/.cache/huggingface \\\n",
    "  pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime bash\n",
    "```\n",
    "\n",
    "Ora ogni container condividerà la stessa cache dei modelli.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Persistenza di database e vector store**\n",
    "\n",
    "### Qdrant:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "```\n",
    "\n",
    "Il volume `qdrant_data` mantiene l’indice vettoriale anche dopo il riavvio.\n",
    "\n",
    "### PostgreSQL (es. per CrewAI logs):\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 5432:5432 \\\n",
    "  -v pg_data:/var/lib/postgresql/data \\\n",
    "  -e POSTGRES_PASSWORD=crewpass \\\n",
    "  postgres:15\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Reti personalizzate (`--network`)**\n",
    "\n",
    "In un progetto AI multi-container, serve spesso far comunicare i servizi tra loro (es. CrewAI → Qdrant → Streamlit).\n",
    "Per farlo Docker offre le **reti bridge personalizzate**.\n",
    "\n",
    "### Creare una rete:\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "```\n",
    "\n",
    "### Eseguire container collegati alla stessa rete:\n",
    "\n",
    "```bash\n",
    "docker run -d --name qdrant --network ai_net qdrant/qdrant:v1.10.0\n",
    "docker run -it --name crew_backend --network ai_net python:3.11 bash\n",
    "```\n",
    "\n",
    "Ora, da dentro `crew_backend`, puoi connetterti a `qdrant` usando:\n",
    "\n",
    "```python\n",
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "```\n",
    "\n",
    " *Non serve conoscere l’IP*, Docker risolve automaticamente i nomi dei container come host DNS.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizi pratici**\n",
    "\n",
    "### 🔹 **Esercizio 1 – Volume locale**\n",
    "\n",
    "1. Crea una cartella `C:\\docker_test`.\n",
    "2. Avvia un container con:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it -v C:\\docker_test:/app python:3.11 bash\n",
    "   ```\n",
    "3. Dentro `/app`, crea `test.py` e scrivi qualcosa.\n",
    "4. Chiudi, verifica che il file sia rimasto nella cartella locale.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 2 – Volume Docker**\n",
    "\n",
    "1. Crea volume:\n",
    "\n",
    "   ```bash\n",
    "   docker volume create crew_data\n",
    "   ```\n",
    "2. Avvia container:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it --mount source=crew_data,target=/data python:3.11 bash\n",
    "   ```\n",
    "3. Crea file `/data/persist.txt`.\n",
    "4. Esci e rimuovi il container.\n",
    "5. Avvia un nuovo container con lo stesso volume e verifica che il file esista ancora.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Esercizio 3 – Rete condivisa**\n",
    "\n",
    "1. Crea rete:\n",
    "\n",
    "   ```bash\n",
    "   docker network create ai_net\n",
    "   ```\n",
    "2. Avvia Qdrant:\n",
    "\n",
    "   ```bash\n",
    "   docker run -d --name qdrant --network ai_net qdrant/qdrant:v1.10.0\n",
    "   ```\n",
    "3. Avvia Python backend:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it --network ai_net python:3.11 bash\n",
    "   ```\n",
    "4. Dentro Python:\n",
    "\n",
    "   ```python\n",
    "   from qdrant_client import QdrantClient\n",
    "   client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "   print(client.get_collections())\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Riepilogo**\n",
    "\n",
    "| Comando / Opzione               | Funzione                             | Esempio tipico AI                      |\n",
    "| ------------------------------- | ------------------------------------ | -------------------------------------- |\n",
    "| `-v host:container`             | Collega cartella locale (bind mount) | Notebook, codice sorgente              |\n",
    "| `--mount source=...,target=...` | Volume gestito da Docker             | Cache modelli, database, indici Qdrant |\n",
    "| `docker volume create <name>`   | Crea volume persistente              | `docker volume create crew_data`       |\n",
    "| `docker network create <name>`  | Crea rete personalizzata             | `docker network create ai_net`         |\n",
    "| `--network <name>`              | Collega container alla stessa rete   | `--network ai_net`                     |\n",
    "| `docker volume ls`              | Mostra volumi                        | Verifica storage CrewAI                |\n",
    "| `docker network ls`             | Mostra reti                          | Debug connessioni tra container        |\n",
    "\n",
    "---\n",
    "\n",
    "Docker non è solo “un contenitore”: è un **ecosistema di filesystem, reti e processi**.\n",
    "Per un AI Engineer, capire come usare `-v`, `--mount` e `--network` significa saper costruire **pipeline CrewAI e RAG persistenti**, scalabili e interconnesse in modo professionale.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8a185-6049-44ea-b5c7-a8ca3223d88e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.1 – Cos’è un Dockerfile**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Definizione**\n",
    "\n",
    "Un **Dockerfile** è un semplice **file di testo** che contiene **le istruzioni** per costruire un’immagine Docker.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* descrive **passo dopo passo** come creare un ambiente completo (sistema operativo, librerie, codice, comandi d’avvio);\n",
    "* Docker lo “legge” e, seguendo quelle istruzioni, costruisce un’immagine pronta all’uso;\n",
    "* quell’immagine può poi essere eseguita su qualsiasi computer o server con Docker installato, **sempre nello stesso modo**.\n",
    "\n",
    "È, a tutti gli effetti, **la ricetta dell’ambiente di esecuzione**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Analogia**\n",
    "\n",
    "Pensa al Dockerfile come a una **ricetta di cucina**:\n",
    "\n",
    "* Ogni riga è un ingrediente o un’azione (es. “installa Python”, “copia il codice”).\n",
    "* Docker è il cuoco che la legge e prepara il piatto (l’immagine).\n",
    "* L’immagine finale è il **piatto pronto** (un ambiente completo e isolato).\n",
    "* Quando “servi il piatto” (cioè lanci un container), Docker prende quell’immagine e la esegue come un piccolo sistema operativo in miniatura.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Perché serve**\n",
    "\n",
    "Nel mondo AI o software moderno, lavorare su progetti complessi come:\n",
    "\n",
    "* **CrewAI** (più agenti, librerie AI, dipendenze pesanti),\n",
    "* **LangChain** (diverse versioni di pacchetti),\n",
    "* **Qdrant** o **PostgreSQL** (database separati),\n",
    "* **Streamlit** o **FastAPI** (frontend e API),\n",
    "\n",
    "significa dover gestire decine di librerie e ambienti.\n",
    "Un Dockerfile risolve questo problema: crea un ambiente **standardizzato e replicabile**, che chiunque può ricostruire con un solo comando.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Come funziona**\n",
    "\n",
    "Docker legge il Dockerfile **dall’alto verso il basso**.\n",
    "Ogni istruzione crea un “**layer**” dell’immagine: un piccolo pezzo di filesystem.\n",
    "L’insieme di questi layer forma l’immagine finale.\n",
    "\n",
    "Esempio semplificato:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Vediamolo in parole:\n",
    "\n",
    "1. **FROM python:3.11-slim** → usa come base un sistema Linux con Python 3.11 già installato.\n",
    "2. **WORKDIR /app** → imposta la directory di lavoro.\n",
    "3. **COPY . .** → copia i file del progetto nel container.\n",
    "4. **RUN pip install -r requirements.txt** → installa le librerie.\n",
    "5. **CMD [\"python\", \"main.py\"]** → definisce il comando da eseguire quando il container parte.\n",
    "\n",
    "Il risultato sarà un’immagine Docker con:\n",
    "\n",
    "* Python 3.11\n",
    "* tutte le librerie del progetto\n",
    "* il codice copiato\n",
    "* pronta per avviarsi con `python main.py`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Creare e usare un Dockerfile**\n",
    "\n",
    "1. Crea un file chiamato `Dockerfile` (senza estensione).\n",
    "2. Scrivi le istruzioni dentro.\n",
    "3. Costruisci l’immagine con:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t nome-immagine .\n",
    "   ```\n",
    "\n",
    "   (`-t` = tag, `.` = directory corrente dove si trova il Dockerfile)\n",
    "4. Avvia un container da quell’immagine:\n",
    "\n",
    "   ```bash\n",
    "   docker run nome-immagine\n",
    "   ```\n",
    "\n",
    "Esempio completo:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai-backend .\n",
    "docker run -it crewai-backend\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Struttura tipica**\n",
    "\n",
    "Ogni Dockerfile segue un ordine logico:\n",
    "\n",
    "| Sezione        | Istruzione                 | Funzione                                                  |\n",
    "| -------------- | -------------------------- | --------------------------------------------------------- |\n",
    "| Base           | `FROM`                     | Sceglie l’immagine di partenza (es. Python, Node, Ubuntu) |\n",
    "| Setup          | `RUN`                      | Esegue comandi (es. installazioni, aggiornamenti)         |\n",
    "| Copia codice   | `COPY` / `ADD`             | Copia file dal computer nel container                     |\n",
    "| Configurazione | `ENV`, `WORKDIR`, `EXPOSE` | Imposta variabili e directory                             |\n",
    "| Avvio          | `CMD` / `ENTRYPOINT`       | Definisce il comando di esecuzione                        |\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Differenza tra immagine e container**\n",
    "\n",
    "* Il **Dockerfile** costruisce l’**immagine** (il modello).\n",
    "* Da quell’immagine si possono creare più **container** (le istanze in esecuzione).\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai:latest .\n",
    "docker run -d --name crew1 crewai:latest\n",
    "docker run -d --name crew2 crewai:latest\n",
    "```\n",
    "\n",
    "→ stesso ambiente, due container indipendenti.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico**\n",
    "\n",
    "1. Crea una nuova cartella:\n",
    "\n",
    "   ```\n",
    "   docker_test/\n",
    "   ├── Dockerfile\n",
    "   └── main.py\n",
    "   ```\n",
    "2. In `main.py` scrivi:\n",
    "\n",
    "   ```python\n",
    "   print(\"Hello from Docker!\")\n",
    "   ```\n",
    "3. In `Dockerfile`:\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM python:3.11-slim\n",
    "   WORKDIR /app\n",
    "   COPY . .\n",
    "   CMD [\"python\", \"main.py\"]\n",
    "   ```\n",
    "4. Costruisci e avvia:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t hello-docker .\n",
    "   docker run hello-docker\n",
    "   ```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Hello from Docker!\n",
    "```\n",
    "\n",
    "Ora hai creato la tua prima immagine personalizzata.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. In sintesi**\n",
    "\n",
    "| Concetto             | Descrizione                                                   |\n",
    "| -------------------- | ------------------------------------------------------------- |\n",
    "| Dockerfile           | File di testo con istruzioni per costruire un ambiente Docker |\n",
    "| Immagine             | L’ambiente creato a partire dal Dockerfile                    |\n",
    "| Container            | L’istanza in esecuzione dell’immagine                         |\n",
    "| `docker build`       | Crea l’immagine                                               |\n",
    "| `docker run`         | Esegue il container                                           |\n",
    "| `FROM`               | Base del sistema                                              |\n",
    "| `RUN`, `COPY`, `CMD` | Istruzioni principali                                         |\n",
    "\n",
    "---\n",
    "\n",
    "Un Dockerfile è quindi **il cuore di ogni progetto containerizzato**.\n",
    "Nei prossimi punti impareremo:\n",
    "\n",
    "* come ottimizzarlo per AI (ridurre peso e tempi di build),\n",
    "* come gestire dipendenze, cache e volumi,\n",
    "* e come scrivere Dockerfile modulari per pipeline CrewAI reali.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ddb26-0897-4a66-9c9f-b3f8982b52de",
   "metadata": {},
   "source": [
    "\n",
    "# **2.2 – Istruzioni fondamentali del Dockerfile**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. `FROM` – l’immagine di base**\n",
    "\n",
    "È **sempre la prima riga** di un Dockerfile.\n",
    "Serve per specificare **da quale sistema operativo o ambiente di partenza** costruire la tua immagine.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "```\n",
    "\n",
    "→ parte da Debian “slim” con Python 3.11 già installato.\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "```\n",
    "\n",
    "→ parte da un ambiente già pronto per PyTorch con CUDA e cuDNN.\n",
    "\n",
    "### Regole:\n",
    "\n",
    "* puoi usare **immagini ufficiali** (es. python, node, ubuntu) o personalizzate;\n",
    "* è possibile **cambiare base** in base al progetto (CPU-only o GPU);\n",
    "* ogni immagine base contiene già un piccolo sistema Linux.\n",
    "\n",
    " *Best practice per AI:*\n",
    "\n",
    "* per ambienti CPU: `python:3.11-slim`;\n",
    "* per GPU NVIDIA: `pytorch/pytorch:<ver>-cuda<xx>-runtime`;\n",
    "* per GPU AMD: `rocm/pytorch:latest`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `WORKDIR` – directory di lavoro**\n",
    "\n",
    "Definisce **la cartella in cui verranno eseguiti tutti i comandi successivi** (come `RUN`, `COPY`, `CMD`, ecc.).\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "→ Tutti i comandi successivi verranno eseguiti come se fossi dentro `/app`.\n",
    "\n",
    "Puoi definirne più d’uno:\n",
    "\n",
    "```dockerfile\n",
    "WORKDIR /usr/src\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "→ il secondo sovrascrive il primo (come un `cd`).\n",
    "\n",
    " *Best practice:*\n",
    "Usa sempre `WORKDIR` e **non** `/` o directory di sistema per scrivere i tuoi file.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `COPY` – copia file dall’host al container**\n",
    "\n",
    "Serve per trasferire file e cartelle dal tuo computer (host) all’interno dell’immagine.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "→ copia tutti i file della directory corrente nel container (nella `WORKDIR`).\n",
    "\n",
    "Puoi anche essere più specifico:\n",
    "\n",
    "```dockerfile\n",
    "COPY requirements.txt .\n",
    "COPY src/ ./src\n",
    "```\n",
    "\n",
    " *Suggerimenti:*\n",
    "\n",
    "* escludi file inutili con `.dockerignore` (es. `.git`, `__pycache__`, `venv`, `data/`);\n",
    "* mantieni ordine: prima copia i file di dipendenze (`requirements.txt`), poi il codice.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `RUN` – esegue comandi durante la build**\n",
    "\n",
    "`RUN` viene eseguito **mentre si costruisce l’immagine**, non quando il container parte.\n",
    "Serve per installare librerie, creare directory, aggiornare pacchetti, ecc.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "RUN apt-get update && apt-get install -y git\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "```\n",
    "\n",
    "Ogni `RUN` crea un **nuovo layer** dell’immagine.\n",
    "\n",
    " *Ottimizzazione:*\n",
    "\n",
    "* combina più comandi con `&&` per ridurre i layer;\n",
    "* pulisci la cache di apt per alleggerire l’immagine:\n",
    "\n",
    "  ```dockerfile\n",
    "  RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*\n",
    "  ```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `ENV` – definisce variabili d’ambiente**\n",
    "\n",
    "Le variabili definite con `ENV` sono visibili **dentro il container** a runtime.\n",
    "Molto utile per chiavi API, configurazioni o impostazioni di Python.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV OPENAI_API_KEY=\"sk-xxxxx\"\n",
    "```\n",
    "\n",
    "Puoi anche dichiararle tutte insieme:\n",
    "\n",
    "```dockerfile\n",
    "ENV PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PYTHONUNBUFFERED=1 \\\n",
    "    PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "```\n",
    "\n",
    " *Best practice per AI:*\n",
    "\n",
    "* imposta sempre `PYTHONUNBUFFERED=1` → output immediato nei log;\n",
    "* evita di scrivere chiavi sensibili nel Dockerfile → passa le variabili con `-e` nel `docker run`.\n",
    "\n",
    "Esempio runtime:\n",
    "\n",
    "```bash\n",
    "docker run -e OPENAI_API_KEY=$OPENAI_API_KEY crewai-backend\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. `EXPOSE` – documenta le porte usate**\n",
    "\n",
    "Serve per **indicare quale porta interna del container** viene usata dal servizio.\n",
    "Non apre realmente la porta, ma aiuta Docker a sapere come mappare correttamente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "EXPOSE 8080\n",
    "```\n",
    "\n",
    "→ Il container comunica sulla porta 8080.\n",
    "Poi, quando lo lanci:\n",
    "\n",
    "```bash\n",
    "docker run -p 8080:8080 crewai-backend\n",
    "```\n",
    "\n",
    "la porta 8080 del container è raggiungibile come `localhost:8080`.\n",
    "\n",
    " *Best practice:*\n",
    "\n",
    "* API backend: 8000 o 8080\n",
    "* Qdrant: 6333\n",
    "* Streamlit: 8501\n",
    "\n",
    "---\n",
    "\n",
    "## **7. `CMD` – comando di avvio del container**\n",
    "\n",
    "È il comando che viene eseguito **quando il container parte**.\n",
    "Ogni immagine può avere **un solo CMD**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Alternative:\n",
    "\n",
    "```dockerfile\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "CMD [\"streamlit\", \"run\", \"ui/Home.py\", \"--server.port\", \"8501\"]\n",
    "```\n",
    "\n",
    " *Regole:*\n",
    "\n",
    "* se nel `docker run` specifichi un comando manuale, questo **sovrascrive** il CMD;\n",
    "\n",
    "  ```bash\n",
    "  docker run myimage python other_script.py\n",
    "  ```\n",
    "* il CMD deve sempre essere l’ultimo comando del Dockerfile;\n",
    "* usa la sintassi **JSON array** (non shell) per evitare errori di parsing.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. `ENTRYPOINT` – comando fisso di avvio**\n",
    "\n",
    "Simile a `CMD`, ma **non può essere sovrascritto** facilmente.\n",
    "Serve per rendere “eseguibile” il container.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"main.py\"]\n",
    "```\n",
    "\n",
    "→ di default esegue `python main.py`, ma puoi fare:\n",
    "\n",
    "```bash\n",
    "docker run myimage other.py\n",
    "```\n",
    "\n",
    "→ eseguirà `python other.py`.\n",
    "\n",
    " *Regola generale:*\n",
    "\n",
    "* usa `ENTRYPOINT` se vuoi rendere il container eseguibile (CLI tool, script);\n",
    "* usa `CMD` per applicazioni (server, API).\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Altri comandi utili (cenni rapidi)**\n",
    "\n",
    "| Comando       | Funzione                                                            |\n",
    "| ------------- | ------------------------------------------------------------------- |\n",
    "| `ADD`         | Come `COPY`, ma può scaricare URL o scompattare archivi             |\n",
    "| `LABEL`       | Aggiunge metadati all’immagine (autore, versione)                   |\n",
    "| `USER`        | Imposta l’utente che esegue i comandi (non root per sicurezza)      |\n",
    "| `ARG`         | Variabili disponibili solo durante la build (es. `ARG PY_VER=3.11`) |\n",
    "| `ONBUILD`     | Comandi che si attivano solo in immagini derivate                   |\n",
    "| `HEALTHCHECK` | Controlla lo stato del container periodicamente                     |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Esercizio pratico: costruire un Dockerfile completo**\n",
    "\n",
    "1. Crea una cartella `myapp/`\n",
    "\n",
    "   ```\n",
    "   myapp/\n",
    "   ├── Dockerfile\n",
    "   ├── requirements.txt\n",
    "   └── app.py\n",
    "   ```\n",
    "\n",
    "2. In `requirements.txt`:\n",
    "\n",
    "   ```\n",
    "   fastapi==0.114.0\n",
    "   uvicorn==0.30.6\n",
    "   ```\n",
    "\n",
    "3. In `app.py`:\n",
    "\n",
    "   ```python\n",
    "   from fastapi import FastAPI\n",
    "   app = FastAPI()\n",
    "\n",
    "   @app.get(\"/\")\n",
    "   def hello():\n",
    "       return {\"msg\": \"Hello from Docker!\"}\n",
    "   ```\n",
    "\n",
    "4. In `Dockerfile`:\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM python:3.11-slim\n",
    "   WORKDIR /app\n",
    "   COPY requirements.txt .\n",
    "   RUN pip install --no-cache-dir -r requirements.txt\n",
    "   COPY . .\n",
    "   EXPOSE 8080\n",
    "   CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "   ```\n",
    "\n",
    "5. Costruisci e lancia:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t fastapi-demo .\n",
    "   docker run -p 8080:8080 fastapi-demo\n",
    "   ```\n",
    "\n",
    "6. Apri [http://localhost:8080](http://localhost:8080)\n",
    "   → dovresti vedere:\n",
    "   `{\"msg\": \"Hello from Docker!\"}`\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Riepilogo**\n",
    "\n",
    "| Istruzione   | Scopo                      | Esempio                               |\n",
    "| ------------ | -------------------------- | ------------------------------------- |\n",
    "| `FROM`       | Base dell’immagine         | `FROM python:3.11-slim`               |\n",
    "| `WORKDIR`    | Directory di lavoro        | `WORKDIR /app`                        |\n",
    "| `COPY`       | Copia file nel container   | `COPY . .`                            |\n",
    "| `RUN`        | Esegue comandi di build    | `RUN pip install -r requirements.txt` |\n",
    "| `ENV`        | Imposta variabili ambiente | `ENV PYTHONUNBUFFERED=1`              |\n",
    "| `EXPOSE`     | Documenta porte            | `EXPOSE 8080`                         |\n",
    "| `CMD`        | Comando di avvio           | `CMD [\"python\", \"main.py\"]`           |\n",
    "| `ENTRYPOINT` | Comando fisso di avvio     | `ENTRYPOINT [\"python\"]`               |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefa521-a0c6-4337-bd19-7ee71b48bb48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.3 – Multi-Stage Build: spiegazione semplice e chiara**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema da cui nasce**\n",
    "\n",
    "Quando crei un’immagine Docker, spesso hai **due momenti distinti**:\n",
    "\n",
    "1. **La costruzione (build)**\n",
    "   dove installi compilatori, scarichi repository da Git, compili estensioni, ecc.\n",
    "   → serve molta roba (pacchetti di sviluppo, tool, file temporanei).\n",
    "\n",
    "2. **L’esecuzione (runtime)**\n",
    "   dove ti serve solo il risultato finale: il tuo programma e le librerie già pronte.\n",
    "   → tutto il resto (tool, cache, file temporanei) è inutile e appesantisce l’immagine.\n",
    "\n",
    "---\n",
    "\n",
    "###  Senza multi-stage\n",
    "\n",
    "Se fai tutto nello stesso Dockerfile, ti ritrovi un’immagine **enorme** e piena di file inutili.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Risultato:\n",
    "\n",
    "* immagine da **2-3 GB**,\n",
    "* dentro ci sono compilatori, header file, cache pip…\n",
    "* e tutto ciò non serve più a runtime.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. L’idea del multi-stage build**\n",
    "\n",
    "Docker ti permette di dividere la build in **più “fasi” (stages)**.\n",
    "Ogni stage ha la sua immagine base e il suo ambiente.\n",
    "Alla fine puoi **prendere solo quello che ti serve** e buttar via tutto il resto.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* uno **stage builder** fa tutto il lavoro pesante (installa, compila, crea file).\n",
    "* uno **stage finale (runtime)** parte pulito e riceve **solo i file utili** dal builder.\n",
    "\n",
    "---\n",
    "\n",
    "###  Esempio semplice\n",
    "\n",
    "```dockerfile\n",
    "# STAGE 1 – Builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# STAGE 2 – Runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build /app\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* La prima parte (`AS builder`) crea un’immagine temporanea chiamata *builder*.\n",
    "* Installa lì tutte le dipendenze.\n",
    "* La seconda parte (`FROM ... AS runtime`) crea l’immagine finale.\n",
    "* `COPY --from=builder` prende solo ciò che serve dal primo stage.\n",
    "* Il risultato finale è **pulito, piccolo e pronto all’uso**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Cosa succede dentro Docker**\n",
    "\n",
    "Quando Docker costruisce questo file:\n",
    "\n",
    "1. Crea il primo stage (`builder`), installa tutto.\n",
    "2. Poi **scarta** quell’immagine, ma conserva i file copiati.\n",
    "3. Costruisce la seconda immagine (`runtime`), che contiene solo quei file.\n",
    "\n",
    "→ Risultato: la seconda immagine non ha compilatori, cache o file temporanei.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Vantaggi pratici**\n",
    "\n",
    "| Vantaggio                | Descrizione                                       |\n",
    "| ------------------------ | ------------------------------------------------- |\n",
    "| **Immagini più leggere** | Eviti di includere tool di build e cache pip      |\n",
    "| **Build più pulite**     | Separi logica di build da logica di esecuzione    |\n",
    "| **Più sicurezza**        | Meno tool e pacchetti = meno vulnerabilità        |\n",
    "| **Facile da mantenere**  | Ogni fase ha uno scopo chiaro                     |\n",
    "| **Ottimo per CI/CD**     | Puoi riusare gli stessi stage in pipeline diverse |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Esempio reale – Python con librerie AI**\n",
    "\n",
    "Supponiamo di voler costruire un’immagine per un progetto CrewAI o LangChain.\n",
    "Serve scaricare molte dipendenze Python, alcune anche da Git.\n",
    "\n",
    "Ecco come useresti un multi-stage build semplice:\n",
    "\n",
    "```dockerfile\n",
    "# FASE 1 — Builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "\n",
    "# Installa git e altri strumenti solo qui\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends git build-essential\n",
    "\n",
    "# Copia le dipendenze e installale in una directory temporanea\n",
    "COPY requirements.txt .\n",
    "RUN pip install --target=/build/deps -r requirements.txt\n",
    "\n",
    "# FASE 2 — Runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "\n",
    "# Copia solo i file delle librerie già installate\n",
    "COPY --from=builder /build/deps /usr/local/lib/python3.11/site-packages\n",
    "\n",
    "# Copia il codice dell’app\n",
    "COPY . .\n",
    "\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    " Risultato:\n",
    "\n",
    "* L’immagine finale contiene solo Python + le librerie installate + il tuo codice.\n",
    "* Tutti i tool di build e la cache pip **restano nel builder e vengono scartati**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Multi-stage = più di due fasi**\n",
    "\n",
    "Puoi avere anche 3 o più fasi se vuoi separare meglio i compiti.\n",
    "Esempio tipico per un’app AI con API:\n",
    "\n",
    "1. **builder** → prepara le dipendenze (pip o poetry).\n",
    "2. **api-builder** → costruisce file statici o script ottimizzati.\n",
    "3. **runtime** → esegue l’app (FastAPI o Streamlit).\n",
    "\n",
    "Docker ti permette di copiare file da qualunque fase:\n",
    "\n",
    "```dockerfile\n",
    "COPY --from=api-builder /dist /app\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Come dare un nome alle fasi**\n",
    "\n",
    "Ogni fase ha un nome definito da `AS`.\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "...\n",
    "FROM python:3.11-slim AS runtime\n",
    "COPY --from=builder /build /app\n",
    "```\n",
    "\n",
    "Il nome è utile per dire a Docker **da quale stage copiare i file**.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico – Creiamo due immagini a confronto**\n",
    "\n",
    "### A) Dockerfile semplice (senza multi-stage)\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN apt-get update && apt-get install -y git && pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### B) Dockerfile multi-stage\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "RUN apt-get update && apt-get install -y git\n",
    "COPY requirements.txt .\n",
    "RUN pip install --target=/build/deps -r requirements.txt\n",
    "\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build/deps /usr/local/lib/python3.11/site-packages\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### Confronto\n",
    "\n",
    "| Aspetto              | A) Singolo stage | B) Multi-stage         |\n",
    "| -------------------- | ---------------- | ---------------------- |\n",
    "| Dimensione immagine  | 2-3 GB           | ~800 MB                |\n",
    "| Contiene build-tools | ✅ sì             | ❌ no                   |\n",
    "| Sicurezza            | minore           | maggiore               |\n",
    "| Portabilità          | limitata         | alta                   |\n",
    "| Tempo rebuild        | più lento        | più rapido (cache pip) |\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Come si costruisce**\n",
    "\n",
    "Comando identico:\n",
    "\n",
    "```bash\n",
    "docker build -t myapp:latest .\n",
    "```\n",
    "\n",
    "Docker capisce automaticamente che ci sono più fasi e costruisce solo l’ultima (salvando cache intermedia).\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Cosa ricordare**\n",
    "\n",
    "| Concetto                                | Spiegazione                                   |\n",
    "| --------------------------------------- | --------------------------------------------- |\n",
    "| Ogni `FROM` crea una nuova fase         | Le fasi possono avere nomi (`AS builder`)     |\n",
    "| `COPY --from=`                          | Copia file da una fase all’altra              |\n",
    "| Lo stage finale è l’immagine che rimane | Tutto il resto viene eliminato                |\n",
    "| Obiettivo                               | separare build “pesante” da runtime “leggero” |\n",
    "| Beneficio principale                    | immagini più piccole, sicure e veloci         |\n",
    "\n",
    "---\n",
    "\n",
    " **In sintesi**\n",
    "\n",
    "* Il multi-stage non cambia cosa fa Docker, ma **come lo organizza**.\n",
    "* È il modo corretto di costruire immagini **professionali**, soprattutto nel mondo AI.\n",
    "* Ti permette di preparare ambienti complessi (Torch, Transformers, CrewAI, Qdrant) e distribuire solo ciò che serve per l’esecuzione.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78675233-6449-4ff4-9a23-b61ae55c3197",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.4 – ENTRYPOINT per comandi complessi**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. A cosa serve `ENTRYPOINT`**\n",
    "\n",
    "Quando costruisci un’immagine, devi dire a Docker **che cosa fare quando il container parte**.\n",
    "Puoi farlo in due modi:\n",
    "\n",
    "* con `CMD`\n",
    "* con `ENTRYPOINT`\n",
    "\n",
    "Entrambi indicano **il comando di avvio**, ma con una differenza importante:\n",
    "\n",
    "| Comando      | Può essere sovrascritto da `docker run` | Tipico uso                                     |\n",
    "| ------------ | --------------------------------------- | ---------------------------------------------- |\n",
    "| `CMD`        | ✅ sì                                    | eseguire un’app o uno script semplice          |\n",
    "| `ENTRYPOINT` | ❌ no (di default)                       | rendere il container un *programma* eseguibile |\n",
    "\n",
    " `ENTRYPOINT` rende l’immagine “comportarsi” come un comando.\n",
    "Ad esempio, se hai un tool AI che esegue analisi o scraping, vuoi lanciare:\n",
    "\n",
    "```bash\n",
    "docker run my-ai-analyzer input.txt\n",
    "```\n",
    "\n",
    "e far sì che il container esegua qualcosa tipo:\n",
    "\n",
    "```bash\n",
    "python analyze.py input.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Due sintassi possibili**\n",
    "\n",
    "### a) **Exec form (raccomandata)**\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "→ Docker esegue direttamente il processo come se fosse nativo (senza shell).\n",
    "\n",
    "### b) **Shell form**\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT python main.py\n",
    "```\n",
    "\n",
    "→ viene eseguito dentro `/bin/sh -c`, utile se ti servono operatori shell (`&&`, `|`, `;`), ma meno sicuro e meno efficiente.\n",
    "\n",
    " *Best practice*: usa **exec form** (lista JSON) per applicazioni reali, shell form solo per script d’avvio complessi.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. ENTRYPOINT + CMD = combinazione potente**\n",
    "\n",
    "Puoi usare **entrambi**.\n",
    "Docker combina `ENTRYPOINT` e `CMD`:\n",
    "\n",
    "* `ENTRYPOINT` definisce **il programma principale**,\n",
    "* `CMD` definisce **gli argomenti di default**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "CMD [\"--help\"]\n",
    "```\n",
    "\n",
    "→ se lanci:\n",
    "\n",
    "```bash\n",
    "docker run myapp\n",
    "```\n",
    "\n",
    "esegue:\n",
    "`python main.py --help`\n",
    "\n",
    "Ma se lanci:\n",
    "\n",
    "```bash\n",
    "docker run myapp --version\n",
    "```\n",
    "\n",
    "esegue:\n",
    "`python main.py --version`\n",
    "\n",
    "> Docker sostituisce **solo gli argomenti del CMD**, non l’ENTRYPOINT.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **4. ENTRYPOINT + script Bash per comandi complessi**\n",
    "\n",
    "Spesso ti serve eseguire più cose all’avvio (es. inizializzare modelli, verificare database, poi avviare CrewAI).\n",
    "In questo caso puoi usare uno **script shell** come entrypoint.\n",
    "\n",
    "### a) Dockerfile\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install crewai qdrant-client\n",
    "COPY entrypoint.sh /entrypoint.sh\n",
    "RUN chmod +x /entrypoint.sh\n",
    "ENTRYPOINT [\"/entrypoint.sh\"]\n",
    "```\n",
    "\n",
    "### b) `entrypoint.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e  # interrompe se c’è un errore\n",
    "\n",
    "echo \"🧠 Inizializzazione CrewAI...\"\n",
    "python setup_models.py\n",
    "\n",
    "echo \"🗄️  Controllo connessione Qdrant...\"\n",
    "python check_qdrant.py\n",
    "\n",
    "echo \"🚀 Avvio server principale...\"\n",
    "exec python main.py \"$@\"\n",
    "```\n",
    "\n",
    " `exec` è importante: sostituisce il processo Bash con Python, evitando che Docker perda i log o il PID del processo principale.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. ENTRYPOINT con comandi concatenati**\n",
    "\n",
    "Puoi anche combinare comandi multipli direttamente nel Dockerfile, ma solo se necessario:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"/bin/bash\", \"-c\", \"python prepare.py && python main.py\"]\n",
    "```\n",
    "\n",
    "Tuttavia, **non è consigliato** per progetti complessi — molto meglio usare uno script dedicato come visto sopra.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Personalizzare i parametri in `docker run`**\n",
    "\n",
    "Con `ENTRYPOINT`, puoi passare argomenti extra da linea di comando.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "CMD [\"--help\"]\n",
    "```\n",
    "\n",
    "Puoi cambiare i parametri:\n",
    "\n",
    "```bash\n",
    "docker run myapp --input=data.txt --verbose\n",
    "```\n",
    "\n",
    "→ Docker esegue `python main.py --input=data.txt --verbose`\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Esempio complesso: FastAPI + CrewAI orchestrato**\n",
    "\n",
    "Ecco un esempio realistico per un progetto AI con più servizi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "COPY entrypoint.sh /entrypoint.sh\n",
    "RUN chmod +x /entrypoint.sh  #change mode to x, executable\n",
    "ENTRYPOINT [\"/entrypoint.sh\"]\n",
    "```\n",
    "\n",
    "`entrypoint.sh`:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \" Avvio Qdrant (in background)...\"\n",
    "docker-entrypoint.sh qdrant &\n",
    "\n",
    "echo \" Avvio CrewAI Server...\"\n",
    "exec uvicorn app.main:app --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "In Compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  crewai:\n",
    "    build: .\n",
    "    ports: [\"8080:8080\"]\n",
    "    depends_on: [qdrant]\n",
    "```\n",
    "\n",
    "> Lo script fa partire prima Qdrant, poi CrewAI, in modo ordinato e monitorabile.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Differenze tra ENTRYPOINT e CMD (recap)**\n",
    "\n",
    "| Aspetto                         | `ENTRYPOINT`                           | `CMD`                                    |\n",
    "| ------------------------------- | -------------------------------------- | ---------------------------------------- |\n",
    "| Scopo                           | definisce **il programma principale**  | definisce **gli argomenti di default**   |\n",
    "| Sovrascrizione con `docker run` | ❌ no (a meno di usare `--entrypoint`)  | ✅ sì                                     |\n",
    "| Sintassi preferita              | JSON array                             | JSON array                               |\n",
    "| Tipico uso                      | CLI, script di startup, orchestrazione | impostare default o parametri            |\n",
    "| Posizione                       | 1 sola per Dockerfile                  | 1 sola (spesso combinata con ENTRYPOINT) |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a6b76-666e-4f60-9f38-0f34015f8b9b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.5 – Caching layer e `.dockerignore` nei progetti CrewAI**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema reale**\n",
    "\n",
    "I progetti AI (e in particolare CrewAI) hanno due caratteristiche:\n",
    "\n",
    "1. **Dipendenze pesanti**\n",
    "   Torch, Transformers, LangChain, Qdrant-client, OpenAI SDK, ecc.\n",
    "   Ogni `pip install` può impiegare minuti e scaricare centinaia di MB.\n",
    "\n",
    "2. **File locali numerosi e inutili per la build**\n",
    "   cartelle `.git`, `.venv`, `models/`, `__pycache__/`, `data/`, `.env` → inutili nell’immagine.\n",
    "\n",
    "Senza caching e `.dockerignore`, ogni modifica nel codice fa **ripartire tutto da zero**,\n",
    "ricostruendo anche le librerie pesanti e copiando file superflui.\n",
    "Il risultato?\n",
    "\n",
    "* tempi di build lunghi (anche >10 minuti),\n",
    "* immagini da diversi GB,\n",
    "* scarsa portabilità.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cos’è la cache di Docker**\n",
    "\n",
    "Docker costruisce un’immagine **a layer**: ogni istruzione (`FROM`, `RUN`, `COPY`, ecc.) crea un “pezzo” del filesystem.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "* Se **requirements.txt non cambia**, Docker può riutilizzare la cache del layer `RUN pip install`.\n",
    "* Ma se lo modifichi o se `COPY . .` viene prima, **Docker rigenera tutto da zero**.\n",
    "\n",
    " Quindi **l’ordine delle istruzioni conta moltissimo** per la cache.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Best practice per la cache (ordine corretto)**\n",
    "\n",
    "Ordina sempre così:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "# 1️⃣ Copia SOLO requirements (cambia raramente)\n",
    "COPY requirements.txt .\n",
    "\n",
    "# 2️⃣ Installa dipendenze (caching pip)\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --upgrade pip \\\n",
    " && pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 3️⃣ Copia il codice del progetto (cambia spesso)\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "* **`COPY requirements.txt .`**: viene eseguito solo se requirements cambia → cache efficace.\n",
    "* **`COPY . .`**: viene eseguito dopo → evita di invalidare l’installazione pip per ogni piccolo update del codice.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **4. Cos’è `.dockerignore` e perché è fondamentale**\n",
    "\n",
    "`.dockerignore` funziona come `.gitignore`:\n",
    "indica a Docker **quali file NON copiare nel contesto di build** (cioè la directory che Docker invia al demone).\n",
    "\n",
    "Se Docker deve analizzare 5 GB di dati in `data/` o `models/`,\n",
    "li invierà tutti ogni volta, rallentando la build anche se non servono.\n",
    "\n",
    "### Esempio tipico\n",
    "\n",
    "```\n",
    ".git\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "venv/\n",
    ".env\n",
    ".cache/\n",
    "dist/\n",
    "build/\n",
    "models/\n",
    "data/\n",
    "node_modules/\n",
    "outputs/\n",
    "logs/\n",
    "```\n",
    "\n",
    " *Note per CrewAI*:\n",
    "\n",
    "* **`models/`**: non includere mai modelli HF o checkpoint pesanti → montali come volume.\n",
    "* **`data/`**: includila solo se serve nel runtime (dataset statici o demo).\n",
    "* **`.env`**: contiene chiavi API → escludilo sempre per sicurezza.\n",
    "* **`__pycache__/`** e `.pyc` → inutili.\n",
    "* **`node_modules/`** → solo se hai interfaccia React/Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Esempio reale di `.dockerignore` per progetto CrewAI completo**\n",
    "\n",
    "```\n",
    "# File temporanei e di sistema\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "*.log\n",
    ".DS_Store\n",
    "\n",
    "# Ambienti locali\n",
    "venv/\n",
    ".env\n",
    ".venv/\n",
    ".cache/\n",
    "__pypackages__/\n",
    "\n",
    "# Repositori e build\n",
    ".git\n",
    ".gitignore\n",
    "build/\n",
    "dist/\n",
    "*.egg-info/\n",
    "\n",
    "# Dati pesanti\n",
    "models/\n",
    "data/\n",
    "outputs/\n",
    "logs/\n",
    "*.csv\n",
    "*.zip\n",
    "*.tar.gz\n",
    "\n",
    "# Frontend\n",
    "node_modules/\n",
    "npm-debug.log\n",
    "yarn-error.log\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "```\n",
    "\n",
    " In questo modo Docker copia **solo il codice e i file essenziali**,\n",
    "riducendo drasticamente la dimensione del contesto di build.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Come testare l’effetto del `.dockerignore`**\n",
    "\n",
    "Puoi vedere quali file vengono effettivamente inclusi nel contesto:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai-backend .\n",
    "```\n",
    "\n",
    "Durante la build, Docker stampa:\n",
    "\n",
    "```\n",
    "Sending build context to Docker daemon  12.5MB\n",
    "```\n",
    "\n",
    "→ se prima erano 2GB e ora 12MB, `.dockerignore` sta funzionando.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Cache + .dockerignore = performance reale**\n",
    "\n",
    "| Azione                             | Senza ottimizzazione | Con cache + .dockerignore |\n",
    "| ---------------------------------- | -------------------- | ------------------------- |\n",
    "| Prima build                        | 6–8 minuti           | 6–8 minuti                |\n",
    "| Rebuild dopo piccolo cambio codice | 6–8 minuti           | 15–30 secondi             |\n",
    "| Dimensione immagine                | ~2–3 GB              | ~800 MB                   |\n",
    "| Contesto inviato a Docker          | >1 GB                | ~10–20 MB                 |\n",
    "| Rischio di leak `.env`             | alto                 | nullo                     |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Montare cache persistenti per modelli**\n",
    "\n",
    "Per modelli AI pesanti (es. Transformers, Sentence-Embeddings), **non scaricarli ogni volta**.\n",
    "Usa un volume per la cache HuggingFace:\n",
    "\n",
    "```bash\n",
    "docker run -p 8080:8080 \\\n",
    "  -v $PWD/models:/root/.cache/huggingface \\\n",
    "  crewai-backend\n",
    "```\n",
    "\n",
    "Così:\n",
    "\n",
    "* i modelli vengono scaricati una sola volta;\n",
    "* i container successivi li riutilizzano;\n",
    "* l’immagine rimane leggera e veloce da distribuire.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Errori comuni (e come evitarli)**\n",
    "\n",
    "| Errore                      | Causa                                   | Soluzione                     |\n",
    "| --------------------------- | --------------------------------------- | ----------------------------- |\n",
    "| Ogni build reinstalla tutto | `COPY . .` prima del `pip install`      | inverti l’ordine              |\n",
    "| Build lentissima            | contesto enorme (manca `.dockerignore`) | crea `.dockerignore` completo |\n",
    "| Modelli dentro l’immagine   | copia di `models/` o `data/`            | usa volume montato            |\n",
    "| `.env` incluso              | non ignorato                            | aggiungilo a `.dockerignore`  |\n",
    "| Cache pip non usata         | mancanza `--mount=type=cache`           | abilita BuildKit              |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. In sintesi**\n",
    "\n",
    "| Obiettivo                           | Soluzione                                        |\n",
    "| ----------------------------------- | ------------------------------------------------ |\n",
    "| Evitare reinstallazioni inutili     | Copia requirements prima del codice              |\n",
    "| Riutilizzare librerie già scaricate | Usa `--mount=type=cache,target=/root/.cache/pip` |\n",
    "| Evitare file inutili nel contesto   | Usa `.dockerignore` completo                     |\n",
    "| Evitare modelli nell’immagine       | Monta `~/.cache/huggingface` come volume         |\n",
    "| Build più veloci e pulite           | Struttura Dockerfile con caching consapevole     |\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Prova pratica (5 minuti)**\n",
    "\n",
    "1. Crea un file `Dockerfile` con l’ordine corretto e cache pip.\n",
    "2. Crea `.dockerignore` con le regole sopra.\n",
    "3. Fai due build:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t test-cache .\n",
    "   docker build -t test-cache .\n",
    "   ```\n",
    "4. Osserva i tempi: la seconda build deve essere **istantanea** se non hai modificato `requirements.txt`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5b643-ec31-4455-9560-f04fac43167b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 2.6 – Reti per microservizi AI\n",
    "\n",
    "## (FastAPI backend ↔ Qdrant ↔ Streamlit UI)\n",
    "\n",
    "## 1) Concetto chiave: rete bridge + DNS interno\n",
    "\n",
    "* I container **sulla stessa rete Docker** si vedono per **nome di servizio** (DNS interno).\n",
    "* Non serve conoscere l’IP: dal backend puoi chiamare `http://qdrant:6333` invece di `http://172.18.0.3:6333`.\n",
    "* Esporre porte sull’host (`-p`) serve solo se **vuoi accedere da fuori** (es. browser).\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Setup “a mano” (senza Compose)\n",
    "\n",
    "### Crea una rete dedicata\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "```\n",
    "\n",
    "### Avvia Qdrant su quella rete\n",
    "\n",
    "```bash\n",
    "docker run -d --name qdrant \\\n",
    "  --network ai_net \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "```\n",
    "\n",
    "### Avvia il backend FastAPI (CrewAI) sulla stessa rete\n",
    "\n",
    "```bash\n",
    "docker run -d --name backend \\\n",
    "  --network ai_net \\\n",
    "  -p 8080:8080 \\\n",
    "  -e QDRANT_HOST=qdrant \\\n",
    "  -e QDRANT_PORT=6333 \\\n",
    "  myorg/crewai-backend:latest\n",
    "```\n",
    "\n",
    "Nel codice (Python):\n",
    "\n",
    "```python\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\n",
    "  host=os.getenv(\"QDRANT_HOST\", \"qdrant\"),\n",
    "  port=int(os.getenv(\"QDRANT_PORT\", 6333))\n",
    ")\n",
    "```\n",
    "\n",
    "### Avvia Streamlit UI collegata al backend\n",
    "\n",
    "```bash\n",
    "docker run -d --name ui \\\n",
    "  --network ai_net \\\n",
    "  -p 8501:8501 \\\n",
    "  -e API_BASE_URL=http://backend:8080 \\\n",
    "  myorg/streamlit-ui:latest\n",
    "```\n",
    "\n",
    "Nella UI:\n",
    "\n",
    "```python\n",
    "import os, requests\n",
    "API = os.getenv(\"API_BASE_URL\", \"http://backend:8080\")\n",
    "resp = requests.get(f\"{API}/health\").json()\n",
    "```\n",
    "\n",
    "> Risultato: i tre container **si risolvono per nome** (qdrant, backend, ui) e parlano tra loro senza dover conoscere IP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c66fd-55c0-49ab-9efc-6a91518c3bc9",
   "metadata": {},
   "source": [
    "# **3.1 – Introduzione a Docker Compose per AI stacks**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Perché esiste Docker Compose**\n",
    "\n",
    "Quando lavori con Docker, ogni container è **isolato e indipendente**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* Un container ospita il **backend FastAPI** (CrewAI).\n",
    "* Un altro container ospita **Qdrant**, il database vettoriale.\n",
    "* Un altro ancora la **UI Streamlit**.\n",
    "\n",
    "Con `docker run`, dovresti avviarli tutti **a mano**, collegarli a una **rete**, assegnare **porte**, gestire **volumi**, variabili, dipendenze, e ricordarti tutti i parametri ogni volta.\n",
    "\n",
    "Esempio di quanto diventa scomodo:\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "\n",
    "docker run -d --name qdrant \\\n",
    "  --network ai_net \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "\n",
    "docker run -d --name backend \\\n",
    "  --network ai_net \\\n",
    "  -p 8080:8080 \\\n",
    "  -e QDRANT_HOST=qdrant \\\n",
    "  -e QDRANT_PORT=6333 \\\n",
    "  myorg/crewai-backend:latest\n",
    "\n",
    "docker run -d --name ui \\\n",
    "  --network ai_net \\\n",
    "  -p 8501:8501 \\\n",
    "  -e API_BASE_URL=http://backend:8080 \\\n",
    "  myorg/streamlit-ui:latest\n",
    "```\n",
    "\n",
    "Funziona, ma è **lungo, fragile e ripetitivo**.\n",
    "Serve un modo per **descrivere tutto questo in un solo file**, leggibile e versionabile.\n",
    "Quel file è **`docker-compose.yml`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cos’è Docker Compose**\n",
    "\n",
    "Docker Compose è uno **strumento di orchestrazione locale**.\n",
    "Serve per **definire e gestire più container come un’unica applicazione**.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* Scrivi **tutta la configurazione** (immagini, porte, variabili, volumi, reti, dipendenze)\n",
    "* in un file YAML chiamato `docker-compose.yml`\n",
    "* e poi avvii tutto con **un solo comando**:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Docker Compose:\n",
    "\n",
    "1. Crea automaticamente la rete interna tra i servizi.\n",
    "2. Crea i volumi definiti nel file.\n",
    "3. Costruisce le immagini se hai indicato `build:`.\n",
    "4. Lancia i container nell’ordine giusto (`depends_on`).\n",
    "5. Permette di spegnere tutto con un solo `docker compose down`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Struttura logica di un file `docker-compose.yml`**\n",
    "\n",
    "Un file Compose segue questa **struttura ad albero**:\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"       # (opzionale)\n",
    "services:            # i container dell'applicazione\n",
    "  <nome_servizio>:\n",
    "    image: ...       # oppure build: ...\n",
    "    ports:\n",
    "    environment:\n",
    "    volumes:\n",
    "    depends_on:\n",
    "volumes:              # volumi persistenti\n",
    "networks:             # (opzionale) reti personalizzate\n",
    "```\n",
    "\n",
    "Ogni **servizio** rappresenta un container.\n",
    "Ogni container può avere:\n",
    "\n",
    "* variabili d’ambiente,\n",
    "* porte esposte,\n",
    "* volumi da montare,\n",
    "* dipendenze da altri servizi.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Esempio reale per uno stack AI**\n",
    "\n",
    "Immagina di avere un progetto con:\n",
    "\n",
    "* **CrewAI backend** (FastAPI),\n",
    "* **Qdrant** (vector DB),\n",
    "* **Streamlit UI**.\n",
    "\n",
    "Ecco come lo descriveresti:\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    ports:\n",
    "      - \"6333:6333\"\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "      interval: 10s\n",
    "      timeout: 3s\n",
    "      retries: 5\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    environment:\n",
    "      - QDRANT_HOST=qdrant\n",
    "      - QDRANT_PORT=6333\n",
    "    volumes:\n",
    "      - ./config:/app/config:ro\n",
    "      - ./models:/root/.cache/huggingface\n",
    "    depends_on:\n",
    "      qdrant:\n",
    "        condition: service_healthy\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    environment:\n",
    "      - API_BASE_URL=http://backend:8080\n",
    "    depends_on:\n",
    "      - backend\n",
    "\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Spiegazione riga per riga**\n",
    "\n",
    "### 🔹 `version: \"3.9\"`\n",
    "\n",
    "Serve per indicare la versione dello schema Compose.\n",
    "Nelle versioni recenti è **opzionale**: Compose la riconosce automaticamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `services:`\n",
    "\n",
    "È la sezione principale.\n",
    "Ogni chiave al suo interno rappresenta un container (un servizio indipendente).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `qdrant:`\n",
    "\n",
    "Il nome del servizio.\n",
    "Diventa anche **hostname interno**: il backend potrà connettersi a `http://qdrant:6333`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `image: qdrant/qdrant:v1.10.0`\n",
    "\n",
    "Specifica quale immagine Docker usare.\n",
    "Può essere una:\n",
    "\n",
    "* immagine pubblica (`python:3.11`, `qdrant/qdrant`)\n",
    "* immagine privata (`myorg/backend:latest`)\n",
    "* o una da costruire localmente con `build:`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `build: ./backend`\n",
    "\n",
    "Indica che Compose deve costruire l’immagine a partire dal Dockerfile nella cartella `backend/`.\n",
    "\n",
    "Se hai già pubblicato la tua immagine (es. su Docker Hub o un registry interno), puoi usare:\n",
    "\n",
    "```yaml\n",
    "image: myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `ports:`\n",
    "\n",
    "Serve per **mappare** le porte del container verso l’host.\n",
    "\n",
    "```yaml\n",
    "ports:\n",
    "  - \"8080:8080\"  # (host:container)\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "`localhost:8080` → porta 8080 dentro il container backend.\n",
    "Puoi aprire la tua UI su `localhost:8501` o le API su `localhost:8080`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `environment:`\n",
    "\n",
    "Definisce variabili d’ambiente dentro il container.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "environment:\n",
    "  - QDRANT_HOST=qdrant\n",
    "  - QDRANT_PORT=6333\n",
    "```\n",
    "\n",
    "Nel codice Python:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.getenv(\"QDRANT_HOST\")  # => \"qdrant\"\n",
    "```\n",
    "\n",
    "Puoi anche leggerle da un file `.env` esterno (Compose lo supporta nativamente).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `volumes:`\n",
    "\n",
    "Serve per **montare directory persistenti** o **cartelle locali** nel container.\n",
    "\n",
    "Tipi di volume:\n",
    "\n",
    "* **Bind mount**: collega una cartella locale.\n",
    "\n",
    "  ```yaml\n",
    "  - ./config:/app/config:ro\n",
    "  ```\n",
    "\n",
    "  → leggi i file YAML di CrewAI dal tuo computer (solo lettura).\n",
    "\n",
    "* **Volume gestito da Docker**:\n",
    "\n",
    "  ```yaml\n",
    "  - qdrant_data:/qdrant/storage\n",
    "  ```\n",
    "\n",
    "  → storage persistente mantenuto da Docker (non sparisce a ogni `down`).\n",
    "\n",
    "La sezione finale:\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "crea il volume se non esiste.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `depends_on:`\n",
    "\n",
    "Definisce le **dipendenze di avvio**.\n",
    "Docker avvia prima i servizi da cui dipendi.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "depends_on:\n",
    "  qdrant:\n",
    "    condition: service_healthy\n",
    "```\n",
    "\n",
    "→ il backend parte **solo quando Qdrant risponde al suo healthcheck**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `healthcheck:`\n",
    "\n",
    "Serve per dire a Docker come verificare che un servizio sia “vivo”.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "healthcheck:\n",
    "  test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "  interval: 10s\n",
    "  timeout: 3s\n",
    "  retries: 5\n",
    "```\n",
    "\n",
    "Docker controlla Qdrant ogni 10 secondi e aggiorna il suo stato interno (healthy/unhealthy).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `volumes:` (sezione finale)\n",
    "\n",
    "Qui definisci **tutti i volumi gestiti da Docker**.\n",
    "Ogni voce è un volume persistente.\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "Serve per mantenere i dati anche dopo un `docker compose down`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Come funziona la rete in Compose**\n",
    "\n",
    "Compose crea automaticamente **una rete privata** per tutti i servizi del file.\n",
    "I container si vedono per **nome del servizio**, come se fosse un DNS.\n",
    "\n",
    "| Servizio | Nome DNS interno | Porta interna |\n",
    "| -------- | ---------------- | ------------- |\n",
    "| qdrant   | `qdrant`         | 6333          |\n",
    "| backend  | `backend`        | 8080          |\n",
    "| ui       | `ui`             | 8501          |\n",
    "\n",
    "Quindi nel backend puoi scrivere:\n",
    "\n",
    "```python\n",
    "client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "```\n",
    "\n",
    "e non serve l’IP.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Comandi principali**\n",
    "\n",
    "| Comando                            | Descrizione                         |\n",
    "| ---------------------------------- | ----------------------------------- |\n",
    "| `docker compose up -d`             | avvia tutti i servizi in background |\n",
    "| `docker compose ps`                | mostra i container attivi           |\n",
    "| `docker compose logs -f backend`   | visualizza i log del backend        |\n",
    "| `docker compose exec backend bash` | entra nel container backend         |\n",
    "| `docker compose down`              | ferma e rimuove tutto               |\n",
    "| `docker compose build backend`     | ricostruisce solo il backend        |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Benefici concreti per progetti AI**\n",
    "\n",
    "| Problema                      | Soluzione con Compose                           |\n",
    "| ----------------------------- | ----------------------------------------------- |\n",
    "| Setup manuale lungo           | Un solo comando `docker compose up`             |\n",
    "| Gestione reti e nomi          | DNS interno automatico (`backend`, `qdrant`)    |\n",
    "| Dati persi a ogni restart     | Volumi persistenti gestiti                      |\n",
    "| Avvio non sincronizzato       | `depends_on` + `healthcheck`                    |\n",
    "| Ambiente locale riproducibile | Tutto descritto in YAML, condivisibile nel repo |\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizio pratico**\n",
    "\n",
    "1. Crea la struttura:\n",
    "\n",
    "   ```\n",
    "   project/\n",
    "   ├─ backend/ (con Dockerfile e app.py)\n",
    "   ├─ ui/ (Streamlit)\n",
    "   ├─ docker-compose.yml\n",
    "   └─ config/\n",
    "   ```\n",
    "2. Copia il file Compose di esempio.\n",
    "3. Avvia:\n",
    "\n",
    "   ```bash\n",
    "   docker compose up -d\n",
    "   ```\n",
    "4. Apri la UI su `localhost:8501` e verifica che si connetta al backend (che parla con Qdrant).\n",
    "\n",
    "---\n",
    "\n",
    "## **10. In sintesi**\n",
    "\n",
    "* Docker Compose è il **collante** dei container.\n",
    "* Descrive tutto in un unico file: servizi, reti, volumi, porte, variabili.\n",
    "* Ti permette di **avviare uno stack AI completo con un solo comando**.\n",
    "* È lo standard per orchestrare ambienti **CrewAI + Qdrant + UI** in locale o in CI/CD.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd614aa-098e-4c12-97eb-b0ebca5ed179",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 3.2 — Dockerfile & Compose *production-grade* per AI\n",
    "\n",
    "## A) Dockerfile “da produzione” (CPU)\n",
    "\n",
    "Obiettivi: immagine piccola, build riproducibile, niente tool di build nello stage finale, utente non-root, log immediati.\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "\n",
    "############################\n",
    "# STAGE 1 — builder\n",
    "############################\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "\n",
    "# Dipendenze minime per build (solo qui)\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "      build-essential git curl ca-certificates \\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copia solo i requirements per massimizzare la cache\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Prepara wheelhouse (cache pip con BuildKit)\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --upgrade pip wheel \\\n",
    " && pip wheel --no-deps --no-cache-dir -r requirements.txt -w /wheels\n",
    "\n",
    "############################\n",
    "# STAGE 2 — runtime\n",
    "############################\n",
    "FROM python:3.11-slim AS runtime\n",
    "ENV PYTHONUNBUFFERED=1 PYTHONDONTWRITEBYTECODE=1 PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "\n",
    "# Utente non-root\n",
    "RUN useradd -m -u 10001 appuser\n",
    "WORKDIR /app\n",
    "\n",
    "# Installa SOLO dalle wheel precompilate (niente compilers in runtime)\n",
    "COPY --from=builder /wheels /wheels\n",
    "COPY requirements.txt .\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --no-index --find-links=/wheels -r requirements.txt \\\n",
    " && rm -rf /wheels\n",
    "\n",
    "# Copia codice\n",
    "COPY . .\n",
    "RUN chown -R appuser:appuser /app\n",
    "USER appuser\n",
    "\n",
    "EXPOSE 8080\n",
    "# Healthcheck leggero (se l’app espone /health)\n",
    "# HEALTHCHECK --interval=30s --timeout=3s --retries=3 CMD curl -fsS http://localhost:8080/health || exit 1\n",
    "\n",
    "CMD [\"uvicorn\",\"app.main:app\",\"--host\",\"0.0.0.0\",\"--port\",\"8080\"]\n",
    "```\n",
    "\n",
    "**.dockerignore (essenziale)**\n",
    "\n",
    "```\n",
    ".git\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    ".env\n",
    "venv/\n",
    "models/\n",
    "data/\n",
    "dist/\n",
    "build/\n",
    "node_modules/\n",
    "```\n",
    "\n",
    "> Per AI: **non** inserire modelli/weights nell’immagine → monta la cache HF come volume.\n",
    "\n",
    "---\n",
    "\n",
    "## B) Dockerfile GPU (NVIDIA) “runtime-only”\n",
    "\n",
    "Quando ti serve CUDA, usa base **runtime**; se compili estensioni, usa **devel** solo nel builder:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel AS builder\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --upgrade pip wheel \\\n",
    " && pip wheel --no-deps --no-cache-dir -r requirements.txt -w /wheels\n",
    "\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime AS runtime\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "WORKDIR /app\n",
    "COPY --from=builder /wheels /wheels\n",
    "COPY requirements.txt .\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --no-index --find-links=/wheels -r requirements.txt \\\n",
    " && rm -rf /wheels\n",
    "COPY . .\n",
    "EXPOSE 8080\n",
    "CMD [\"uvicorn\",\"app.main:app\",\"--host\",\"0.0.0.0\",\"--port\",\"8080\"]\n",
    "```\n",
    "\n",
    "> Host: driver NVIDIA + NVIDIA Container Toolkit. A runtime usa `--gpus all`.\n",
    "\n",
    "---\n",
    "\n",
    "## C) Compose “da produzione”: robustezza, ordine di avvio, limiti risorse\n",
    "\n",
    "### docker-compose.yml (CPU-only)\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "    # NON esporre in prod se non serve\n",
    "    # ports: [\"6333:6333\"]\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "      interval: 10s\n",
    "      timeout: 3s\n",
    "      retries: 5\n",
    "    restart: unless-stopped\n",
    "\n",
    "  backend:\n",
    "    image: myorg/crewai-backend:prod   # oppure build: ./backend\n",
    "    depends_on:\n",
    "      qdrant:\n",
    "        condition: service_healthy\n",
    "    environment:\n",
    "      QDRANT_HOST: qdrant\n",
    "      QDRANT_PORT: \"6333\"\n",
    "      # chiavi via env_file o secrets manager\n",
    "    ports: [\"8080:8080\"]     # esponi solo ciò che serve\n",
    "    volumes:\n",
    "      - ./config:/app/config:ro\n",
    "      - ./models:/root/.cache/huggingface\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          cpus: \"2.0\"\n",
    "          memory: \"4g\"\n",
    "    restart: unless-stopped\n",
    "\n",
    "  ui:\n",
    "    image: myorg/streamlit-ui:prod     # oppure build: ./ui\n",
    "    depends_on:\n",
    "      - backend\n",
    "    environment:\n",
    "      API_BASE_URL: http://backend:8080\n",
    "    ports: [\"8501:8501\"]\n",
    "    restart: unless-stopped\n",
    "\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "### Varianti utili\n",
    "\n",
    "* **GPU profile (solo dove supportato)**:\n",
    "\n",
    "  ```yaml\n",
    "  services:\n",
    "    backend-gpu:\n",
    "      image: myorg/crewai-backend:cuda\n",
    "      deploy:\n",
    "        resources:\n",
    "          reservations:\n",
    "            devices:\n",
    "              - capabilities: [\"gpu\"]\n",
    "      # ports/volumes/environment come sopra\n",
    "      profiles: [\"gpu\"]\n",
    "  ```\n",
    "\n",
    "  Avvio: `docker compose --profile gpu up -d`\n",
    "\n",
    "* **env_file** per caricare variabili:\n",
    "\n",
    "  ```yaml\n",
    "  backend:\n",
    "    env_file: [.env]\n",
    "  ```\n",
    "\n",
    "  > Non committare `.env`. Usa vault o secret manager in prod.\n",
    "\n",
    "* **Reti dedicate (opzionale)**:\n",
    "\n",
    "  ```yaml\n",
    "  networks:\n",
    "    private:\n",
    "  services:\n",
    "    qdrant:  { networks: [private] }\n",
    "    backend: { networks: [private] }\n",
    "    ui:      { networks: [private] }\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## D) Strategie di rebuild selettivo & cicli di sviluppo\n",
    "\n",
    "* Ricostruire solo un servizio:\n",
    "\n",
    "  ```bash\n",
    "  docker compose build backend && docker compose up -d backend\n",
    "  ```\n",
    "* Ricostruire e rialzare tutto:\n",
    "\n",
    "  ```bash\n",
    "  docker compose up -d --build\n",
    "  ```\n",
    "* Log mirati e shell:\n",
    "\n",
    "  ```bash\n",
    "  docker compose logs -f backend\n",
    "  docker compose exec backend bash\n",
    "  ```\n",
    "* **Sviluppo hot-reload (solo dev)**: monta il codice\n",
    "\n",
    "  ```yaml\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    volumes:\n",
    "      - ./backend:/app\n",
    "  ```\n",
    "\n",
    "  In produzione rimuovi questo bind mount: usa l’immagine immutabile.\n",
    "\n",
    "---\n",
    "\n",
    "## E) Healthcheck “seri” (FastAPI)\n",
    "\n",
    "Aggiungi un endpoint `GET /health` nel backend (risposta rapida, no DB pesanti).\n",
    "Compose:\n",
    "\n",
    "```yaml\n",
    "backend:\n",
    "  # ...\n",
    "  healthcheck:\n",
    "    test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:8080/health\"]\n",
    "    interval: 10s\n",
    "    timeout: 3s\n",
    "    retries: 5\n",
    "```\n",
    "\n",
    "E usa `depends_on: condition: service_healthy` per orchestrare l’avvio corretto con Qdrant.\n",
    "\n",
    "---\n",
    "\n",
    "## F) Sicurezza minima\n",
    "\n",
    "* **Utente non-root** nello stage runtime (già visto nei Dockerfile).\n",
    "* Non esporre servizi interni (Qdrant, Postgres) se non necessario.\n",
    "* Monta config **read-only** (`:ro`).\n",
    "* Nessuna chiave nel Dockerfile → passa via `env_file` o secret manager.\n",
    "* Aggiorna regolarmente immagini base; valuta scanner (Trivy/Docker Scout) in CI.\n",
    "\n",
    "---\n",
    "\n",
    "## G) Performance & costi immagine\n",
    "\n",
    "* `.dockerignore` curato (niente `models/`, `data/`, `venv/`, `.env`).\n",
    "* **Multi-stage** + wheelhouse: runtime snello.\n",
    "* **Cache pip BuildKit**: `--mount=type=cache,target=/root/.cache/pip`.\n",
    "* Per GPU: **stage builder = devel**, **stage finale = runtime**.\n",
    "* **Modelli HF fuori dall’immagine** → volume `./models:/root/.cache/huggingface`.\n",
    "\n",
    "---\n",
    "\n",
    "## H) Mini-checklist *prod-ready*\n",
    "\n",
    "* [ ] Dockerfile multi-stage, runtime senza tool di build\n",
    "* [ ] Utente non-root, `PYTHONUNBUFFERED=1`\n",
    "* [ ] `.dockerignore` completo\n",
    "* [ ] Healthcheck backend & Qdrant, `depends_on` con `service_healthy`\n",
    "* [ ] Volumi persistenti (Qdrant), cache HF montata\n",
    "* [ ] Porte esposte solo dove serve\n",
    "* [ ] Limiti risorse (CPU/MEM) e profili GPU se necessari\n",
    "* [ ] Segreti via `env_file`/secret manager (mai nel Dockerfile)\n",
    "* [ ] Strategie di rebuild selettivo (`compose build <svc>`)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
