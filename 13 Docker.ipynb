{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5052f859-6d31-4e2e-8f97-99d3cd301236",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **1.1 ‚Äì Perch√© Docker √® cruciale nel mondo AI: ambienti riproducibili e isolati**\n",
    "\n",
    "---\n",
    "\n",
    "## **Contesto**\n",
    "\n",
    "Nel mondo dell‚ÄôAI engineering, il codice raramente vive da solo.\n",
    "Un singolo progetto pu√≤ includere:\n",
    "\n",
    "* una **CrewAI Flow pipeline** composta da pi√π agenti;\n",
    "* una **base di conoscenza indicizzata** su Qdrant o FAISS;\n",
    "* una **UI Streamlit** o FastAPI per interazione utente;\n",
    "* un **database PostgreSQL** per log, tracciamento e valutazione;\n",
    "* librerie Python ad alta complessit√† (Torch, Transformers, OpenAI, LangChain, ecc.);\n",
    "* e talvolta anche **accelerazione GPU**.\n",
    "\n",
    "In questo ecosistema complesso, anche un piccolo cambiamento nella versione di Python, Torch o CUDA pu√≤ **rompere la compatibilit√†** dell‚Äôintero progetto.\n",
    "√à qui che entra in gioco Docker.\n",
    "\n",
    "---\n",
    "\n",
    "## **Concetto chiave: riproducibilit√† e isolamento**\n",
    "\n",
    "### 1. **Riproducibilit√†**\n",
    "\n",
    "Docker permette di impacchettare tutto ci√≤ che serve per far girare un‚Äôapplicazione ‚Äî **codice, dipendenze, librerie, variabili d‚Äôambiente, sistema operativo** ‚Äî in un‚Äôimmagine immutabile.\n",
    "Chiunque esegua quell‚Äôimmagine, su qualunque macchina, ottiene **esattamente lo stesso comportamento**.\n",
    "\n",
    "> **Esempio pratico**\n",
    "> Un flow CrewAI funziona sulla tua macchina, ma non sul server remoto perch√© il server usa Python 3.10 mentre tu hai 3.11.\n",
    "> Con Docker, entrambi eseguite **la stessa immagine**, basata sullo stesso ambiente (`FROM python:3.11-slim`), e il comportamento sar√† identico.\n",
    "\n",
    "### 2. **Isolamento**\n",
    "\n",
    "Ogni container Docker √® **un ambiente isolato** dal sistema operativo host e dagli altri container:\n",
    "\n",
    "* Non condivide processi, pacchetti o variabili d‚Äôambiente.\n",
    "* Pu√≤ avere una rete privata e filesystem dedicato.\n",
    "* Se un container va in crash o consuma troppa RAM, **non impatta gli altri**.\n",
    "\n",
    "Questo isolamento √® cruciale in sistemi AI con **pi√π microservizi**:\n",
    "\n",
    "* il backend CrewAI non interferisce con Qdrant,\n",
    "* Qdrant non influisce sul database PostgreSQL,\n",
    "* e ogni parte pu√≤ essere aggiornata o riavviata indipendentemente.\n",
    "\n",
    "---\n",
    "\n",
    "## **Perch√© √® cruciale per l‚ÄôAI moderna**\n",
    "\n",
    "### 1. **Gestione delle dipendenze**\n",
    "\n",
    "Progetti AI usano spesso librerie non allineate tra loro:\n",
    "\n",
    "* `torch==2.3.0` richiede una versione specifica di CUDA,\n",
    "* `transformers==4.44` pu√≤ rompere LangChain se non aggiornato,\n",
    "* `qdrant-client` ha binding Rust/Python sensibili alla versione.\n",
    "\n",
    "Con Docker puoi bloccare **esattamente le versioni** nel Dockerfile, garantendo che il progetto sia stabile nel tempo.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Reproducible Research e MLOps**\n",
    "\n",
    "In MLOps e AI engineering, la **riproducibilit√† degli esperimenti** √® un requisito critico.\n",
    "Con Docker puoi:\n",
    "\n",
    "* rieseguire esattamente una pipeline anche mesi dopo;\n",
    "* distribuire lo stesso ambiente a un collega o server;\n",
    "* garantire che l‚Äôesperimento su cui √® stato addestrato un modello sia documentato e verificabile.\n",
    "\n",
    "Molte aziende e laboratori (OpenAI, Hugging Face, Meta AI) **versionano i propri ambienti Docker** insieme al codice.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Distribuzione e scalabilit√†**\n",
    "\n",
    "Un container √® un‚Äôunit√† standard, facilmente distribuibile:\n",
    "\n",
    "* Puoi spostarlo da un laptop a un server cloud o a un cluster Kubernetes;\n",
    "* Puoi scalare lo stesso container su pi√π nodi senza riconfigurare nulla;\n",
    "* Ogni microservizio CrewAI (rag, retriever, evaluator, frontend) pu√≤ essere un container separato.\n",
    "\n",
    "Esempio tipico di stack AI containerizzato:\n",
    "\n",
    "```\n",
    "crew-backend     -> container FastAPI con CrewAI\n",
    "qdrant-db        -> container Qdrant ufficiale\n",
    "postgres-logs    -> container PostgreSQL\n",
    "streamlit-ui     -> container Streamlit con API utente\n",
    "```\n",
    "\n",
    "Con un solo comando:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "tutto l‚Äôambiente prende vita, identico su ogni macchina.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Isolamento GPU e AI workloads**\n",
    "\n",
    "Docker supporta nativamente l‚Äôaccesso alle GPU tramite:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all\n",
    "```\n",
    "\n",
    "o, in Compose:\n",
    "\n",
    "```yaml\n",
    "deploy:\n",
    "  resources:\n",
    "    reservations:\n",
    "      devices:\n",
    "        - capabilities: [gpu]\n",
    "```\n",
    "\n",
    "Questo permette di:\n",
    "\n",
    "* eseguire modelli AI pesanti in container,\n",
    "* isolare il carico GPU da altri processi,\n",
    "* e distribuire workload AI in cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## **Analogia concettuale**\n",
    "\n",
    "> Pensa a Docker come a un ‚Äú**laboratorio virtuale sigillato**‚Äù.\n",
    "> Dentro ci sono le tue provette (codice, librerie, modelli), il tuo microscopio (framework AI), e perfino il manuale d‚Äôuso (Dockerfile).\n",
    "> Nessuno pu√≤ sporcare il tuo ambiente e tu puoi ricrearlo all‚Äôinfinito.\n",
    "\n",
    "---\n",
    "\n",
    "## **Esercizio pratico (10 minuti)**\n",
    "\n",
    "1. Lancia un container Python:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it python:3.11 bash\n",
    "   ```\n",
    "2. Installa alcune librerie:\n",
    "\n",
    "   ```bash\n",
    "   pip install crewai qdrant-client\n",
    "   ```\n",
    "3. Esci e rilancia il container: scopri che le librerie **non persistono**.\n",
    "   ‚Üí Capirai che ogni container √® **ephemeral** e **isolato**.\n",
    "4. Rilancia con volume montato:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it -v $(pwd)/app:/app python:3.11 bash\n",
    "   ```\n",
    "\n",
    "   Ora tutto ci√≤ che salvi in `/app` persiste localmente.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d1b00-113e-4c93-a97c-8d26d5aaf7f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.2 ‚Äì Differenze tra venv, Conda, VM e container**\n",
    "\n",
    "Nel mondo dell‚ÄôAI engineering esistono diversi modi per isolare un ambiente di sviluppo o di esecuzione. Prima di capire a fondo Docker, √® fondamentale distinguere tra **ambienti virtuali (venv, Conda)** e **macchine virtuali (VM)**, cos√¨ da comprendere dove si colloca la containerizzazione.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Virtualenv e venv**\n",
    "\n",
    "Gli ambienti virtuali in Python (creati con `venv` o `virtualenv`) sono **isolatori di pacchetti**: permettono di avere versioni di librerie diverse da quelle del sistema operativo, ma non isolano il sistema vero e proprio.\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install crewai qdrant-client\n",
    "```\n",
    "\n",
    "In questo caso:\n",
    "\n",
    "* L‚Äôambiente virtuale **usa sempre lo stesso Python** dell‚Äôhost;\n",
    "* Tutto gira **sullo stesso sistema operativo**;\n",
    "* Non puoi controllare la versione di OS, CUDA o driver GPU;\n",
    "* Se aggiorni globalmente una libreria come `torch`, potresti rompere un altro progetto.\n",
    "\n",
    "√à utile per **sviluppo locale**, ma non garantisce **riproducibilit√† perfetta**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Conda environment**\n",
    "\n",
    "Conda √® uno strumento pi√π avanzato, molto diffuso in ambito data science.\n",
    "Pu√≤ gestire non solo librerie Python, ma anche **pacchetti di sistema** (come `ffmpeg`, `libtorch`, `cuda`).\n",
    "\n",
    "```bash\n",
    "conda create -n crewai python=3.11\n",
    "conda activate crewai\n",
    "conda install pytorch cudatoolkit=12.1 -c pytorch\n",
    "```\n",
    "\n",
    "Conda risolve molti problemi di compatibilit√†, ma:\n",
    "\n",
    "* Gli ambienti restano **legati al sistema operativo**;\n",
    "* Non √® portabile tra sistemi (un env Linux non gira su Windows);\n",
    "* Le versioni dei driver e delle librerie native (CUDA, cuDNN, Rust) restano dipendenti dall‚Äôhost.\n",
    "\n",
    "In altre parole, **Conda isola le librerie, non il sistema**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Virtual Machines (VM)**\n",
    "\n",
    "Le macchine virtuali (VM) isolano tutto: sistema operativo, kernel, driver, file system.\n",
    "Ogni VM √® un computer completo, con un suo OS e risorse dedicate (CPU, RAM, disco).\n",
    "\n",
    "Vantaggi:\n",
    "\n",
    "* Isolamento totale.\n",
    "* Puoi avere sistemi operativi diversi sull‚Äôhost (es. Linux su Windows).\n",
    "\n",
    "Svantaggi:\n",
    "\n",
    "* Ogni VM pesa **diversi GB**;\n",
    "* L‚Äôavvio √® lento;\n",
    "* Consuma molta memoria e CPU;\n",
    "* Duplicare o aggiornare ambienti √® costoso.\n",
    "\n",
    "Per esempio, se un progetto CrewAI richiede 4 microservizi in VM, ognuno con un OS Linux, avresti 4 sistemi completi da mantenere, aggiornare e gestire: un incubo in produzione.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Docker container**\n",
    "\n",
    "Docker rappresenta un **punto di equilibrio perfetto** tra i due mondi:\n",
    "\n",
    "* Leggero come un ambiente virtuale;\n",
    "* Isolato come una macchina virtuale.\n",
    "\n",
    "I container non contengono un sistema operativo completo: condividono il **kernel dell‚Äôhost**, ma mantengono filesystem, processi e librerie isolati.\n",
    "Questo riduce drasticamente i tempi di avvio e il consumo di risorse.\n",
    "\n",
    "### Esempio:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11-slim bash\n",
    "```\n",
    "\n",
    "Questo comando:\n",
    "\n",
    "* Scarica un‚Äôimmagine contenente Linux minimale + Python 3.11;\n",
    "* Avvia un container isolato;\n",
    "* In meno di 1 secondo sei dentro un sistema pulito.\n",
    "\n",
    "Puoi poi installare CrewAI, Qdrant, LangChain o Streamlit senza toccare il tuo sistema locale.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Differenze riassuntive**\n",
    "\n",
    "| Caratteristica         | venv / virtualenv | Conda         | Virtual Machine           | Docker Container             |\n",
    "| ---------------------- | ----------------- | ------------- | ------------------------- | ---------------------------- |\n",
    "| Isolamento OS          | ‚ùå                 | ‚ùå             | ‚úÖ                         | ‚úÖ (parziale, condiviso)      |\n",
    "| Peso                   | üîπ Leggero        | üîπ Medio      | ‚ö´ Pesante                 | üîπ Leggero                   |\n",
    "| Avvio                  | Immediato         | Immediato     | Lento (minuti)            | Istantaneo                   |\n",
    "| Portabilit√†            | ‚ùå                 | ‚ùå             | ‚úÖ (con immagine)          | ‚úÖ                            |\n",
    "| GPU accesso diretto    | ‚úÖ (locale)        | ‚úÖ             | ‚ö†Ô∏è complesso              | ‚úÖ (via driver NVIDIA/ROCm)   |\n",
    "| Riproducibilit√† totale | ‚ùå                 | ‚ö†Ô∏è Parziale   | ‚úÖ                         | ‚úÖ                            |\n",
    "| Uso ideale             | Dev locale        | ML lab locale | Sistemi legacy o completi | Produzione AI e microservizi |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Esempio pratico**\n",
    "\n",
    "Immagina di dover distribuire un sistema AI composto da:\n",
    "\n",
    "* `CrewAI` backend per l‚Äôorchestrazione,\n",
    "* `Qdrant` per la ricerca vettoriale,\n",
    "* `Streamlit` come interfaccia utente.\n",
    "\n",
    "### Con venv:\n",
    "\n",
    "Ogni sviluppatore deve installare manualmente Python, CrewAI, Qdrant, Streamlit, configurare le porte e i database ‚Äî altissimo rischio di errore.\n",
    "\n",
    "### Con Docker:\n",
    "\n",
    "Basta clonare il progetto e lanciare:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "Tutto si avvia in container separati, gi√† configurati.\n",
    "L‚Äôambiente sar√† identico per ogni persona e ogni server.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Analogia semplice**\n",
    "\n",
    "* **venv**: come usare scatole per tenere separati gli oggetti sulla stessa scrivania.\n",
    "* **VM**: come avere scrivanie diverse in stanze diverse.\n",
    "* **Docker**: come avere scatole sigillate identiche, che puoi spostare ovunque e aprire ovunque, gi√† pronte all‚Äôuso.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550baa4-7aa9-435e-8620-6d0c6f59332a",
   "metadata": {},
   "source": [
    "\n",
    "# **1.3 ‚Äì Architettura Docker: client, daemon, immagini, container e registry**\n",
    "\n",
    "Per comprendere davvero Docker ‚Äî e non solo ‚Äúusarlo‚Äù ‚Äî bisogna capirne la **struttura interna**: come comunica, chi fa cosa e dove avviene l‚Äôesecuzione reale dei container.\n",
    "Molti sviluppatori usano Docker per anni senza conoscere la differenza tra *client* e *daemon*: questo punto serve a eliminare quella confusione, cos√¨ da lavorare in modo consapevole e sicuro.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. L‚Äôarchitettura generale**\n",
    "\n",
    "Docker √® composto da **quattro elementi principali**:\n",
    "\n",
    "1. **Docker Client** ‚Üí l‚Äôinterfaccia con cui tu interagisci.\n",
    "2. **Docker Daemon (dockerd)** ‚Üí il motore che esegue davvero i container.\n",
    "3. **Docker Images** ‚Üí i ‚Äúmodelli‚Äù o blueprint dei container.\n",
    "4. **Docker Containers** ‚Üí le istanze in esecuzione delle immagini.\n",
    "5. **Docker Registry** ‚Üí il magazzino remoto dove le immagini vengono salvate e condivise.\n",
    "\n",
    "Tutti questi componenti lavorano insieme come un sistema client-server.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Il Client**\n",
    "\n",
    "Il **client** √® tutto ci√≤ che usi per comunicare con Docker:\n",
    "\n",
    "* il comando `docker` nel terminale,\n",
    "* o l‚Äôinterfaccia grafica Docker Desktop.\n",
    "\n",
    "Quando scrivi:\n",
    "\n",
    "```bash\n",
    "docker run python:3.11\n",
    "```\n",
    "\n",
    "il client **non esegue direttamente** il container.\n",
    "In realt√†, invia una richiesta API al Daemon Docker in background (dockerd), che √® il vero motore.\n",
    "\n",
    "Docker Client pu√≤ anche collegarsi a un daemon remoto, ad esempio su un server cloud:\n",
    "\n",
    "```bash\n",
    "export DOCKER_HOST=ssh://user@server\n",
    "```\n",
    "\n",
    "In questo modo, puoi controllare container su un‚Äôaltra macchina come se fossero locali.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Il Daemon (dockerd)**\n",
    "\n",
    "Il **Docker Daemon** √® il processo che:\n",
    "\n",
    "* riceve comandi dal client,\n",
    "* scarica immagini,\n",
    "* crea, avvia e ferma container,\n",
    "* gestisce volumi, reti e log.\n",
    "\n",
    "√à lui a parlare con il kernel del sistema operativo per impostare **namespaces**, **cgroups**, e filesystem copy-on-write.\n",
    "\n",
    "In pratica, √® il ‚Äúcuore‚Äù del sistema Docker.\n",
    "\n",
    "Su Linux gira come processo di sistema, su macOS e Windows √® incapsulato all‚Äôinterno di una VM leggera (perch√© Docker richiede kernel Linux).\n",
    "\n",
    "---\n",
    "\n",
    "### Esempio di flusso reale:\n",
    "\n",
    "Quando esegui:\n",
    "\n",
    "```bash\n",
    "docker run -d -p 8000:8000 --name crew_backend crewai:latest\n",
    "```\n",
    "\n",
    "accade in realt√† questo:\n",
    "\n",
    "1. Il client Docker invia la richiesta al daemon (`dockerd`).\n",
    "2. Il daemon controlla se l‚Äôimmagine `crewai:latest` esiste localmente.\n",
    "\n",
    "   * Se no, la scarica dal registry.\n",
    "3. Crea un container a partire dall‚Äôimmagine.\n",
    "4. Isola il processo, assegna rete, volumi e risorse.\n",
    "5. Avvia il container e monitora il suo stato.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Le Immagini**\n",
    "\n",
    "Un‚Äôimmagine √® un **pacchetto immutabile** che contiene:\n",
    "\n",
    "* un sistema operativo minimale (es. Debian Slim),\n",
    "* tutte le dipendenze necessarie,\n",
    "* e il tuo codice (CrewAI, Qdrant, Streamlit, ecc.).\n",
    "\n",
    "Ogni immagine √® composta da **layer**, ognuno dei quali rappresenta una modifica:\n",
    "\n",
    "* layer di base (es. Python),\n",
    "* layer con le librerie installate,\n",
    "* layer con il codice dell‚Äôapplicazione.\n",
    "\n",
    "Esempio di Dockerfile semplificato:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Quando la build parte, ogni comando crea un layer.\n",
    "Docker li **mette in cache**, quindi se non modifichi `requirements.txt`, non ricostruisce tutto da zero.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. I Container**\n",
    "\n",
    "Il **container** √® l‚Äôistanza in esecuzione di un‚Äôimmagine.\n",
    "√à un processo isolato, con il suo filesystem, rete e risorse dedicate.\n",
    "\n",
    "Concettualmente:\n",
    "\n",
    "* un‚Äôimmagine √® come una **classe** in programmazione;\n",
    "* un container √® **un oggetto** istanziato da quella classe.\n",
    "\n",
    "Puoi avere pi√π container dalla stessa immagine:\n",
    "\n",
    "```bash\n",
    "docker run -d --name crewai1 crewai:latest\n",
    "docker run -d --name crewai2 crewai:latest\n",
    "```\n",
    "\n",
    "Entrambi eseguono lo stesso codice, ma in ambienti separati.\n",
    "\n",
    "I container sono **ephemeral**: se li elimini (`docker rm`), spariscono, ma puoi sempre ricrearli dalla stessa immagine.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Il Registry**\n",
    "\n",
    "Il **registry** √® un archivio remoto per immagini Docker.\n",
    "I pi√π noti sono:\n",
    "\n",
    "* **Docker Hub** (pubblico),\n",
    "* **GitHub Container Registry (GHCR)**,\n",
    "* **GitLab Container Registry**,\n",
    "* o registry privati aziendali (es. AWS ECR, Azure Container Registry).\n",
    "\n",
    "Il registry √® per le immagini ci√≤ che GitHub √® per il codice:\n",
    "ti permette di **versionare**, **condividere** e **distribuire** in modo centralizzato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker build -t myorg/crewai-backend:1.0 .\n",
    "docker push myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "Ora chiunque, da un‚Äôaltra macchina, pu√≤ eseguire:\n",
    "\n",
    "```bash\n",
    "docker run myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "e avr√† esattamente il tuo ambiente.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Schema riassuntivo**\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ        Docker Client       ‚îÇ\n",
    "‚îÇ (CLI / Docker Desktop UI)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚îÇ API REST\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ       Docker Daemon        ‚îÇ\n",
    "‚îÇ     (dockerd in Linux)     ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ\n",
    "‚îÇ  ‚îÇ   Images      ‚îÇ   Vol. ‚îÇ‚îÇ\n",
    "‚îÇ  ‚îÇ   Containers  ‚îÇ   Net. ‚îÇ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "             ‚îÇ Pull / Push\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ       Docker Registry      ‚îÇ\n",
    "‚îÇ (Docker Hub / GHCR / ECR)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Come si lega all‚ÄôAI engineering**\n",
    "\n",
    "Capire l‚Äôarchitettura Docker serve anche a **diagnosticare errori frequenti** in ambienti AI:\n",
    "\n",
    "* Se un container non parte, non √® ‚ÄúDocker rotto‚Äù: √® il daemon che non riceve o non riesegue il processo.\n",
    "* Se un‚Äôimmagine non viene trovata, il problema √® nel registry o nei permessi di push/pull.\n",
    "* Se un volume non si monta, √® la gestione del layer filesystem del daemon.\n",
    "\n",
    "In pipeline AI con CrewAI, Qdrant e Streamlit, tutto ruota intorno a questo flusso:\n",
    "\n",
    "* il **client** (Compose o CLI) invia la configurazione;\n",
    "* il **daemon** crea i servizi come container isolati;\n",
    "* le **immagini** rappresentano ogni microservizio AI;\n",
    "* i **registry** custodiscono le versioni deployabili.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizio pratico (15 minuti)**\n",
    "\n",
    "1. Esegui:\n",
    "\n",
    "   ```bash\n",
    "   docker run hello-world\n",
    "   ```\n",
    "\n",
    "   Poi verifica cosa accade nel daemon con:\n",
    "\n",
    "   ```bash\n",
    "   docker ps -a\n",
    "   docker images\n",
    "   docker info\n",
    "   ```\n",
    "2. Scarica manualmente un‚Äôimmagine:\n",
    "\n",
    "   ```bash\n",
    "   docker pull python:3.11-slim\n",
    "   ```\n",
    "\n",
    "   e osserva i layer scaricati.\n",
    "3. Ispeziona l‚Äôimmagine:\n",
    "\n",
    "   ```bash\n",
    "   docker inspect python:3.11-slim\n",
    "   ```\n",
    "\n",
    "Capirai come **client**, **daemon** e **registry** interagiscono nel mondo reale.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd26bc2-61db-4ad0-921f-c4dc480924b1",
   "metadata": {},
   "source": [
    "\n",
    "# **1.4 ‚Äì Come Docker gestisce librerie pesanti (Torch, CUDA, ROCm, Transformers)**\n",
    "\n",
    "Quando si containerizza un‚Äôapplicazione AI, non si parla pi√π solo di Python e dipendenze leggere.\n",
    "L‚Äôambiente deve spesso includere:\n",
    "\n",
    "* **PyTorch** o **TensorFlow**, librerie enormi con binding nativi in C++ o CUDA;\n",
    "* **CUDA Toolkit** o **ROCm**, per l‚Äôaccelerazione su GPU NVIDIA o AMD;\n",
    "* **Transformers** e modelli LLM, spesso di diversi GB di peso.\n",
    "\n",
    "Docker pu√≤ gestire tutto questo in modo efficiente, ma serve capire come funziona ‚Äúsotto il cofano‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Docker e le librerie native**\n",
    "\n",
    "Una libreria come `torch` non √® solo Python puro: include componenti compilati in C/C++ e spesso richiede l‚Äôaccesso diretto a driver e device hardware.\n",
    "\n",
    "Nel sistema host, queste librerie vengono installate con il supporto nativo del sistema operativo (es. `/usr/lib/cuda`).\n",
    "Nel container, invece, **non esiste nulla di preinstallato**: devi fornire tu l‚Äôambiente completo.\n",
    "\n",
    "Docker lo risolve in due modi:\n",
    "\n",
    "1. usando **immagini base specifiche per GPU**, gi√† predisposte da NVIDIA o AMD;\n",
    "2. esponendo i **driver GPU dell‚Äôhost** al container tramite un layer d‚Äôintegrazione (NVIDIA Container Toolkit o ROCm runtime).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Immagini base NVIDIA e CUDA**\n",
    "\n",
    "NVIDIA mantiene immagini ufficiali con CUDA e PyTorch preconfigurati, ad esempio:\n",
    "\n",
    "* `nvidia/cuda`\n",
    "* `pytorch/pytorch`\n",
    "* `tensorflow/tensorflow`\n",
    "\n",
    "Queste immagini contengono:\n",
    "\n",
    "* il sistema operativo base (Ubuntu o Debian),\n",
    "* CUDA Toolkit (compilatori, librerie, runtime),\n",
    "* i driver utente per l‚Äôaccelerazione GPU,\n",
    "* e a volte anche PyTorch preinstallato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Quando esegui il container, puoi dare accesso alla GPU dell‚Äôhost:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all my-ai-container\n",
    "```\n",
    "\n",
    "Il container non ha bisogno di driver NVIDIA interni: utilizza quelli **gi√† presenti sull‚Äôhost**, esposti attraverso il toolkit.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. NVIDIA Container Toolkit**\n",
    "\n",
    "Il **NVIDIA Container Toolkit** √® ci√≤ che permette a Docker di parlare con la GPU.\n",
    "Funziona come un ponte tra il sistema host e il container.\n",
    "\n",
    "Installazione (Linux):\n",
    "\n",
    "```bash\n",
    "sudo apt install -y nvidia-container-toolkit\n",
    "sudo systemctl restart docker\n",
    "```\n",
    "\n",
    "Dopo questa configurazione, puoi:\n",
    "\n",
    "* lanciare container con GPU accessibile (`--gpus all`);\n",
    "* monitorare la GPU dal container (`nvidia-smi`);\n",
    "* eseguire modelli Torch e TensorFlow accelerati.\n",
    "\n",
    "Senza questo toolkit, Docker non pu√≤ accedere alle GPU dell‚Äôhost, perch√© il kernel non ‚Äúvede‚Äù i device.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. ROCm e GPU AMD**\n",
    "\n",
    "Per GPU AMD, il meccanismo √® simile ma basato su **ROCm** (Radeon Open Compute).\n",
    "AMD fornisce immagini ufficiali con supporto ROCm preinstallato, ad esempio:\n",
    "\n",
    "* `rocm/pytorch`\n",
    "* `rocm/tensorflow`\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM rocm/pytorch:latest\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "CMD [\"python\", \"train.py\"]\n",
    "```\n",
    "\n",
    "L‚Äôhost deve avere i driver ROCm installati e accessibili.\n",
    "Docker non gestisce direttamente la GPU AMD: la espone come device `/dev/kfd` o `/dev/dri`, e il container la utilizza tramite i runtime ROCm interni.\n",
    "\n",
    "Avvio:\n",
    "\n",
    "```bash\n",
    "docker run --device=/dev/kfd --device=/dev/dri my-rocm-container\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Transformers e modelli di grandi dimensioni**\n",
    "\n",
    "Le librerie **Transformers** e **Diffusers** di Hugging Face portano un‚Äôaltra sfida: i modelli sono enormi (GB di pesi binari), spesso scaricati da remoto.\n",
    "\n",
    "Best practice:\n",
    "\n",
    "* monta una **cache condivisa** per i modelli, per non riscaricarli a ogni build;\n",
    "* non includere i pesi dentro l‚Äôimmagine Docker;\n",
    "* usa un volume dedicato o un percorso esterno.\n",
    "\n",
    "Esempio in Compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  crewai:\n",
    "    build: .\n",
    "    volumes:\n",
    "      - ./models:/root/.cache/huggingface\n",
    "```\n",
    "\n",
    "In questo modo:\n",
    "\n",
    "* i modelli restano persistenti anche se ricrei il container;\n",
    "* pi√π container possono condividere la stessa cache.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Dimensioni delle immagini e ottimizzazione**\n",
    "\n",
    "Quando si aggiungono PyTorch, CUDA e Transformers, le immagini possono facilmente superare i **5‚Äì10 GB**.\n",
    "Per ottimizzarle:\n",
    "\n",
    "1. **Usa multi-stage build**\n",
    "\n",
    "   * Compila o installa solo ci√≤ che serve in un primo stage.\n",
    "   * Copia solo i binari finali nello stage runtime.\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel as build\n",
    "   RUN pip install crewai qdrant-client\n",
    "\n",
    "   FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "   COPY --from=build /opt/conda /opt/conda\n",
    "   CMD [\"python\", \"main.py\"]\n",
    "   ```\n",
    "\n",
    "2. **Evita apt inutili**\n",
    "\n",
    "   * Ogni `RUN apt-get install` crea un layer.\n",
    "   * Pulisci la cache (`rm -rf /var/lib/apt/lists/*`).\n",
    "\n",
    "3. **Usa immagini ‚Äúslim‚Äù o ‚Äúruntime‚Äù**\n",
    "\n",
    "   * Le immagini `-devel` contengono compilatori e header (necessari solo in build).\n",
    "   * In produzione basta `-runtime`.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Testare GPU e librerie in container**\n",
    "\n",
    "Per verificare che Docker stia usando correttamente la GPU:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all --rm pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime nvidia-smi\n",
    "```\n",
    "\n",
    "Output atteso:\n",
    "\n",
    "```\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.40       Driver Version: 550.40       CUDA Version: 12.1     |\n",
    "| GPU Name: RTX 4090      Memory Usage: 2345MiB / 24576MiB                    |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "Poi, per testare Torch:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "‚Üí `True`\n",
    "\n",
    "Questo conferma che il container accede ai driver GPU host e pu√≤ eseguire modelli accelerati.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Integrazione con CrewAI e Qdrant**\n",
    "\n",
    "Quando costruisci pipeline reali con **CrewAI**, **Qdrant** e **LLM**, separa sempre i componenti:\n",
    "\n",
    "* il container ‚ÄúAI compute‚Äù (PyTorch, Transformers, CUDA/ROCm);\n",
    "* il container ‚Äúvector DB‚Äù (Qdrant o Milvus);\n",
    "* e il container ‚Äúinterface‚Äù (Streamlit o FastAPI).\n",
    "\n",
    "Questo approccio:\n",
    "\n",
    "* evita conflitti tra librerie native (Torch, Rust, SQLite, ecc.),\n",
    "* riduce le dimensioni di ciascun container,\n",
    "* permette di scalare indipendentemente il componente AI compute.\n",
    "\n",
    "Esempio di Compose parziale:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  ai-compute:\n",
    "    build: ./ai\n",
    "    deploy:\n",
    "      resources:\n",
    "        reservations:\n",
    "          devices:\n",
    "            - capabilities: [gpu]\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "  streamlit:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Riepilogo concettuale**\n",
    "\n",
    "| Elemento                                    | Ruolo in Docker                                          | Note                                                     |\n",
    "| ------------------------------------------- | -------------------------------------------------------- | -------------------------------------------------------- |\n",
    "| **PyTorch / TensorFlow**                    | Librerie Python con binding C/CUDA                       | Devono essere installate su immagini compatibili con GPU |\n",
    "| **CUDA / ROCm**                             | Layer di accesso GPU                                     | Esposto dal sistema host, non incluso nei container      |\n",
    "| **Transformers / Diffusers**                | Framework LLM e modelli                                  | Gestire cache e volumi condivisi                         |\n",
    "| **NVIDIA Container Toolkit / ROCm runtime** | Ponte hardware ‚Üí container                               | Necessario per esporre device GPU                        |\n",
    "| **Best practice**                           | Usa immagini preconfigurate, multi-stage e cache modelli | Evita build pesanti e duplicazione di dati               |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dab0bb-b62c-40bb-b5af-7a9c6fd12f54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.5 ‚Äì Setup ambiente (Windows): installazione Docker Desktop e configurazione GPU (NVIDIA o ROCm)**\n",
    "\n",
    "Su Windows, Docker non viene eseguito nativamente: lavora all‚Äôinterno di una macchina virtuale Linux gestita dal **motore WSL 2 (Windows Subsystem for Linux)**.\n",
    "Questo √® il componente che permette a Docker di avere un vero kernel Linux e quindi di eseguire correttamente container basati su immagini come `python:3.11-slim`, `pytorch/pytorch`, o `qdrant/qdrant`.\n",
    "\n",
    "L‚Äôobiettivo di questo setup √® garantire:\n",
    "\n",
    "* un‚Äôinstallazione pulita e stabile di Docker Desktop;\n",
    "* l‚Äôattivazione di **WSL 2** e del **kernel Linux**;\n",
    "* il corretto **accesso alla GPU** (NVIDIA o AMD) da parte dei container;\n",
    "* la possibilit√† di eseguire stack AI completi (CrewAI + Qdrant + Streamlit) con accelerazione hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Prerequisiti di sistema**\n",
    "\n",
    "### Requisiti minimi\n",
    "\n",
    "* **Windows 10** (versione 2004 o superiore) oppure **Windows 11**\n",
    "* **64 bit**\n",
    "* **CPU con virtualizzazione hardware abilitata** (Intel VT-x o AMD-V)\n",
    "* Almeno **8 GB di RAM** (consigliati 16 GB per AI)\n",
    "* Connessione Internet per scaricare immagini e tool\n",
    "\n",
    "### Requisiti GPU\n",
    "\n",
    "* **Per NVIDIA:** driver 470+ e toolkit CUDA 11 o superiore\n",
    "* **Per AMD:** driver ROCm 6.0+ con supporto a HIP (solo Windows 11 attualmente sperimentale)\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Installazione di WSL 2**\n",
    "\n",
    "WSL 2 √® il motore Linux su cui Docker Desktop si appoggia.\n",
    "Per installarlo:\n",
    "\n",
    "Apri **PowerShell come Amministratore** e digita:\n",
    "\n",
    "```bash\n",
    "wsl --install\n",
    "```\n",
    "\n",
    "Questo comando:\n",
    "\n",
    "* attiva i componenti ‚ÄúPiattaforma macchina virtuale‚Äù e ‚ÄúSottosistema Windows per Linux‚Äù;\n",
    "* installa automaticamente Ubuntu come distribuzione predefinita;\n",
    "* abilita il kernel Linux.\n",
    "\n",
    "Dopo il riavvio, verifica che tutto sia attivo:\n",
    "\n",
    "```bash\n",
    "wsl -l -v\n",
    "```\n",
    "\n",
    "Dovresti vedere un output simile a:\n",
    "\n",
    "```\n",
    "  NAME      STATE           VERSION\n",
    "* Ubuntu    Running         2\n",
    "```\n",
    "\n",
    "Se `VERSION` √® 1, aggiorna con:\n",
    "\n",
    "```bash\n",
    "wsl --set-version Ubuntu 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Installazione di Docker Desktop**\n",
    "\n",
    "1. Vai al sito ufficiale:\n",
    "   üîó [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)\n",
    "2. Scarica **Docker Desktop for Windows**.\n",
    "3. Durante l‚Äôinstallazione, **assicurati di selezionare ‚ÄúUse WSL 2 based engine‚Äù**.\n",
    "4. Dopo l‚Äôinstallazione, riavvia il sistema.\n",
    "5. Avvia Docker Desktop e apri il terminale PowerShell o Ubuntu WSL per testare:\n",
    "\n",
    "   ```bash\n",
    "   docker run hello-world\n",
    "   ```\n",
    "\n",
    "   Se il messaggio dice ‚ÄúHello from Docker!‚Äù, l‚Äôinstallazione √® riuscita.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Configurazione GPU ‚Äì NVIDIA**\n",
    "\n",
    "Per usare PyTorch o TensorFlow con accelerazione GPU all‚Äôinterno di container, serve il **NVIDIA Container Toolkit**.\n",
    "\n",
    "### Passaggi\n",
    "\n",
    "1. Assicurati che i driver NVIDIA siano aggiornati:\n",
    "\n",
    "   * Apri `nvidia-smi` nel prompt.\n",
    "     Se restituisce un output valido, i driver sono attivi.\n",
    "\n",
    "2. Installa **NVIDIA Container Toolkit** (dalla WSL Ubuntu):\n",
    "\n",
    "   ```bash\n",
    "   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n",
    "   curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n",
    "   curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n",
    "     sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
    "   sudo apt-get update\n",
    "   sudo apt-get install -y nvidia-container-toolkit\n",
    "   sudo systemctl restart docker\n",
    "   ```\n",
    "\n",
    "3. Verifica:\n",
    "\n",
    "   ```bash\n",
    "   docker run --rm --gpus all nvidia/cuda:12.1-base nvidia-smi\n",
    "   ```\n",
    "\n",
    "   Se compare la tua GPU, Docker √® configurato per CUDA.\n",
    "\n",
    "4. Ora puoi eseguire modelli CrewAI o Torch nel container:\n",
    "\n",
    "   ```bash\n",
    "   docker run --gpus all -it pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "   ```\n",
    "\n",
    "   Output atteso: `True`\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Configurazione GPU ‚Äì AMD (ROCm)**\n",
    "\n",
    "> ‚ö†Ô∏è Su Windows il supporto ROCm via Docker √® ancora **sperimentale**.\n",
    "> Si consiglia di usare **Ubuntu WSL** con ROCm installato o, meglio, una macchina Linux nativa.\n",
    "\n",
    "Per sistemi che supportano ROCm (es. RX 7900 XTX, MI 210, ecc.):\n",
    "\n",
    "1. Installa driver ROCm per Windows 11:\n",
    "   üîó [https://www.amd.com/en/developer/resources/rocm.html](https://www.amd.com/en/developer/resources/rocm.html)\n",
    "2. Installa Docker Desktop come sopra.\n",
    "3. Apri WSL Ubuntu e verifica la presenza dei device:\n",
    "\n",
    "   ```bash\n",
    "   ls /dev | grep kfd\n",
    "   ```\n",
    "4. Avvia container ROCm:\n",
    "\n",
    "   ```bash\n",
    "   docker run --device=/dev/kfd --device=/dev/dri rocm/pytorch:latest\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Test finale**\n",
    "\n",
    "Una volta completata l‚Äôinstallazione:\n",
    "\n",
    "```bash\n",
    "docker run hello-world\n",
    "docker run -it python:3.11-slim bash\n",
    "```\n",
    "\n",
    "Se entrambi i comandi funzionano, Docker e WSL 2 sono configurati correttamente.\n",
    "\n",
    "Per GPU:\n",
    "\n",
    "* Verifica CUDA: `docker run --gpus all nvidia/cuda:12.1-base nvidia-smi`\n",
    "* Oppure PyTorch: `docker run --gpus all pytorch/pytorch python -c \"import torch; print(torch.cuda.is_available())\"`\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Consigli pratici per progetti AI**\n",
    "\n",
    "* **Disattiva ‚ÄúUse Windows containers‚Äù**: assicurati che Docker Desktop usi container **Linux-based**.\n",
    "* **Assegna risorse adeguate** (Settings ‚Üí Resources):\n",
    "  CPU ‚â• 4 core, RAM ‚â• 8 GB, GPU enabled.\n",
    "* **Condividi le directory di lavoro** (Settings ‚Üí Resources ‚Üí File Sharing): aggiungi la cartella del progetto.\n",
    "* **Evita di costruire immagini dentro WSL** se usi IDE Windows: costruiscile da terminale Docker Desktop o da VS Code + Docker Extension per mantenere il contesto coerente.\n",
    "* **Aggiorna WSL regolarmente**:\n",
    "\n",
    "  ```bash\n",
    "  wsl --update\n",
    "  ```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab8e22-fa05-40ee-8b5f-398616d2fd39",
   "metadata": {},
   "source": [
    "# **1.6 ‚Äì Comandi base e ciclo di vita di un container**\n",
    "\n",
    "Quando esegui un container, Docker lo tratta come un **processo isolato**: pu√≤ essere avviato, messo in pausa, riavviato o rimosso.\n",
    "Per gestirlo, Docker fornisce una serie di comandi CLI che ti permettono di **controllare ogni fase del suo ciclo di vita**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Concetto di ciclo di vita**\n",
    "\n",
    "Un container nasce da un‚Äôimmagine ed esegue un processo principale (il *command* o *entrypoint* definito nel Dockerfile).\n",
    "Dalla creazione alla rimozione, pu√≤ passare attraverso vari stati:\n",
    "\n",
    "```\n",
    "created ‚Üí running ‚Üí stopped ‚Üí removed\n",
    "```\n",
    "\n",
    "Ogni fase √® gestita da comandi specifici, che vediamo subito.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `docker ps` ‚Äì Visualizzare i container attivi**\n",
    "\n",
    "Mostra la lista dei container attualmente in esecuzione.\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "```\n",
    "CONTAINER ID   IMAGE                  COMMAND                  STATUS         PORTS                  NAMES\n",
    "f2a45b8c11df   qdrant/qdrant:latest   \"/usr/bin/qdrant\"        Up 5 minutes   6333/tcp, 6334/tcp    qdrant_db\n",
    "d3a21ce6c442   crewai:latest          \"python main.py\"         Up 2 minutes   8080/tcp              crew_backend\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker ps -a` ‚Üí mostra **tutti i container**, anche quelli stoppati.\n",
    "* `docker ps -q` ‚Üí mostra solo gli ID (utile negli script).\n",
    "* `docker ps --filter \"status=exited\"` ‚Üí filtra per stato.\n",
    "\n",
    " *Uso tipico in AI pipelines:*\n",
    "Verificare che `qdrant`, `crewai` e `streamlit` siano effettivamente attivi in uno stack multi-container.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `docker exec` ‚Äì Entrare o eseguire comandi dentro un container**\n",
    "\n",
    "Permette di eseguire un comando in un container gi√† in esecuzione, o di aprire una shell interattiva.\n",
    "\n",
    "```bash\n",
    "docker exec -it <container_name> bash\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker exec -it crew_backend bash\n",
    "```\n",
    "\n",
    "Ora sei ‚Äúdentro‚Äù il container come se fosse un piccolo Linux isolato.\n",
    "Puoi navigare, leggere log, o testare Python:\n",
    "\n",
    "```bash\n",
    "python\n",
    "import crewai\n",
    "```\n",
    "\n",
    "### Varianti:\n",
    "\n",
    "* `docker exec crew_backend ls /app` ‚Üí esegue un singolo comando e restituisce l‚Äôoutput.\n",
    "* `-i` = interattivo (input), `-t` = terminale (TTY).\n",
    "\n",
    " *Esempio pratico:*\n",
    "Se il container `crewai` non risponde, puoi entrare e controllare il file `/app/main.py` o la presenza delle chiavi `.env`.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `docker logs` ‚Äì Leggere i log del container**\n",
    "\n",
    "Mostra l‚Äôoutput standard (`stdout` e `stderr`) del processo principale del container.\n",
    "√à uno dei comandi pi√π usati per il debugging.\n",
    "\n",
    "```bash\n",
    "docker logs crew_backend\n",
    "```\n",
    "\n",
    "Esempio di output:\n",
    "\n",
    "```\n",
    "[INFO] CrewAI server started on port 8080\n",
    "[INFO] Connected to Qdrant at qdrant_db:6333\n",
    "[WARNING] Missing OpenAI API key - using fallback model\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker logs -f crew_backend` ‚Üí *follow mode*, segue in tempo reale i log (come `tail -f`).\n",
    "* `docker logs --since 10m crew_backend` ‚Üí mostra solo gli ultimi 10 minuti.\n",
    "* `docker logs -n 50 crew_backend` ‚Üí ultimi 50 log lines.\n",
    "\n",
    " *Uso tipico:*\n",
    "Quando un microservizio AI fallisce all‚Äôavvio, questo comando mostra errori di import, di connessione o di chiavi API mancanti.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `docker inspect` ‚Äì Analizzare in profondit√† container o immagini**\n",
    "\n",
    "Fornisce tutte le informazioni tecniche di un container o di un‚Äôimmagine in formato JSON.\n",
    "√à fondamentale per capire configurazioni, reti, volumi e variabili d‚Äôambiente.\n",
    "\n",
    "```bash\n",
    "docker inspect crew_backend\n",
    "```\n",
    "\n",
    "Output (estratto semplificato):\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"Id\": \"d3a21ce6c442...\",\n",
    "    \"State\": { \"Status\": \"running\", \"Pid\": 1342 },\n",
    "    \"Mounts\": [\n",
    "      { \"Source\": \"/home/michael/app\", \"Destination\": \"/app\" }\n",
    "    ],\n",
    "    \"NetworkSettings\": {\n",
    "      \"IPAddress\": \"172.18.0.3\",\n",
    "      \"Ports\": { \"8080/tcp\": [{ \"HostPort\": \"8080\" }] }\n",
    "    },\n",
    "    \"Config\": {\n",
    "      \"Env\": [\"OPENAI_API_KEY=sk-...\", \"MODE=production\"],\n",
    "      \"Cmd\": [\"python\", \"main.py\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "### Opzioni utili:\n",
    "\n",
    "* `docker inspect --format='{{.NetworkSettings.IPAddress}}' crew_backend`\n",
    "  ‚Üí mostra solo l‚ÄôIP interno.\n",
    "* `docker inspect -f '{{.Config.Env}}' crew_backend`\n",
    "  ‚Üí mostra le variabili d‚Äôambiente.\n",
    "\n",
    " *Uso tipico:*\n",
    "Scoprire su quale rete interna √® connesso un container CrewAI per permettere a Streamlit o Qdrant di comunicare correttamente.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Comandi complementari del ciclo di vita**\n",
    "\n",
    "### Avvio e stop container\n",
    "\n",
    "```bash\n",
    "docker start crew_backend\n",
    "docker stop crew_backend\n",
    "```\n",
    "\n",
    "### Riavvio rapido\n",
    "\n",
    "```bash\n",
    "docker restart crew_backend\n",
    "```\n",
    "\n",
    "### Creazione e rimozione\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_backend crewai:latest\n",
    "docker rm crew_backend\n",
    "```\n",
    "\n",
    " *Nota:* un container rimosso non cancella l‚Äôimmagine da cui √® stato creato.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Visualizzare immagini e volumi**\n",
    "\n",
    "Per vedere le immagini salvate localmente:\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "```\n",
    "\n",
    "Per vedere i volumi (dove risiedono i dati persistenti):\n",
    "\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "Esempio tipico in uno stack CrewAI:\n",
    "\n",
    "```\n",
    "REPOSITORY          TAG       SIZE\n",
    "crewai              latest    2.3GB\n",
    "qdrant/qdrant       v1.10.0   650MB\n",
    "python              3.11-slim 140MB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico (20 minuti)**\n",
    "\n",
    "1. Avvia un container Python:\n",
    "\n",
    "   ```bash\n",
    "   docker run -d --name pytest python:3.11-slim sleep 300\n",
    "   ```\n",
    "2. Verifica che sia attivo:\n",
    "\n",
    "   ```bash\n",
    "   docker ps\n",
    "   ```\n",
    "3. Entra nel container:\n",
    "\n",
    "   ```bash\n",
    "   docker exec -it pytest bash\n",
    "   ```\n",
    "4. Installa qualcosa al suo interno (es. `pip install numpy`), poi esci.\n",
    "5. Leggi i log:\n",
    "\n",
    "   ```bash\n",
    "   docker logs pytest\n",
    "   ```\n",
    "6. Ispeziona:\n",
    "\n",
    "   ```bash\n",
    "   docker inspect pytest\n",
    "   ```\n",
    "7. Ferma e rimuovi:\n",
    "\n",
    "   ```bash\n",
    "   docker stop pytest\n",
    "   docker rm pytest\n",
    "   ```\n",
    "\n",
    "Questo ciclo ti mostra come **nascita, esecuzione e distruzione** di un container avvengono in modo trasparente e controllato.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Riepilogo pratico**\n",
    "\n",
    "| Comando                | Funzione principale                  | Uso tipico               |\n",
    "| ---------------------- | ------------------------------------ | ------------------------ |\n",
    "| `docker ps`            | Elenca container attivi              | Controllo dello stato    |\n",
    "| `docker exec`          | Entra o esegue comandi nel container | Debug o test rapido      |\n",
    "| `docker logs`          | Legge i log del container            | Diagnosi di errori       |\n",
    "| `docker inspect`       | Mostra configurazione completa       | Analisi rete, env, mount |\n",
    "| `docker start/stop/rm` | Gestione ciclo di vita               | Riavvio, cleanup         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d290372-c08f-4f52-95f3-a9ec7627f53a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.7 ‚Äì Gestione ambienti AI interattivi (`docker run -it python:3.11 bash`)**\n",
    "\n",
    "Molti sviluppatori AI lavorano con ambienti virtuali o notebook locali, ma questo spesso porta a conflitti tra versioni di librerie, Python o CUDA.\n",
    "Con Docker puoi creare **ambienti di sviluppo temporanei e isolati**, pronti all‚Äôuso, perfetti per testare rapidamente nuove librerie, modelli o configurazioni di CrewAI.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Concetto di ambiente interattivo**\n",
    "\n",
    "Un container Docker pu√≤ essere usato in due modi:\n",
    "\n",
    "* come **servizio**, in esecuzione continua (es. un backend CrewAI, un database Qdrant);\n",
    "* oppure come **ambiente interattivo**, dove lavori dentro una shell Linux pulita, come se fosse una macchina virtuale leggera.\n",
    "\n",
    "Il comando chiave √®:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11 bash\n",
    "```\n",
    "\n",
    "Vediamo cosa succede in dettaglio.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Analisi del comando**\n",
    "\n",
    "| Parte         | Significato                                                        |\n",
    "| ------------- | ------------------------------------------------------------------ |\n",
    "| `docker run`  | crea e avvia un container basato su un‚Äôimmagine                    |\n",
    "| `-i`          | abilita l‚Äôinput interattivo (stdin aperto)                         |\n",
    "| `-t`          | assegna un terminale TTY per interazione umana                     |\n",
    "| `python:3.11` | immagine base ufficiale di Python (Debian + Python 3.11)           |\n",
    "| `bash`        | comando da eseguire all‚Äôavvio del container (avvia una shell Bash) |\n",
    "\n",
    "Il risultato √® un prompt interattivo dentro un sistema Linux minimale, con Python gi√† installato.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```\n",
    "root@0a3b82f3d87c:/# python\n",
    "Python 3.11.9 (main, May 10 2024, 10:11:00)\n",
    ">>> import sys\n",
    ">>> sys.version\n",
    "'3.11.9'\n",
    "```\n",
    "\n",
    "Ora sei **dentro un container** isolato dal tuo sistema Windows o macOS, e tutto ci√≤ che fai (installazioni, file, modifiche) resta confinato l√¨ dentro.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Caratteristiche di un ambiente interattivo Docker**\n",
    "\n",
    "1. **Pulito:** ogni container parte sempre dallo stesso stato iniziale.\n",
    "2. **Isolato:** non interferisce con librerie o file dell‚Äôhost.\n",
    "3. **Temporaneo:** se lo chiudi senza salvare, sparisce (utile per test rapidi).\n",
    "4. **Reproducibile:** puoi ricrearlo identico in ogni momento.\n",
    "5. **Leggero:** avvio in meno di un secondo.\n",
    "\n",
    " √à perfetto per testare rapidamente:\n",
    "\n",
    "* librerie nuove (`pip install crewai qdrant-client`);\n",
    "* modelli (`from transformers import pipeline`);\n",
    "* bug di compatibilit√† (`import torch; torch.cuda.is_available()`).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Lavorare dentro il container**\n",
    "\n",
    "Una volta dentro la shell:\n",
    "\n",
    "```bash\n",
    "root@0a3b82f3d87c:/#\n",
    "```\n",
    "\n",
    "Puoi usare comandi Linux e Python normalmente:\n",
    "\n",
    "```bash\n",
    "apt update && apt install nano -y\n",
    "pip install crewai qdrant-client langchain\n",
    "python\n",
    "```\n",
    "\n",
    "Tutto funzioner√† come in un vero sistema Linux, ma:\n",
    "\n",
    "* i file restano **solo nel container**;\n",
    "* quando esci (`exit` o `Ctrl+D`), il container si ferma;\n",
    "* al riavvio sar√† ‚Äúvuoto‚Äù se non hai salvato nulla su un volume (vedremo tra poco come farlo).\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Uscire e rientrare**\n",
    "\n",
    "Esci con:\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "Il container resta fermo ma non scompare.\n",
    "Puoi vederlo con:\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "E rientrare con:\n",
    "\n",
    "```bash\n",
    "docker start -ai <container_id>\n",
    "```\n",
    "\n",
    "oppure eliminarlo:\n",
    "\n",
    "```bash\n",
    "docker rm <container_id>\n",
    "```\n",
    "\n",
    " *Consiglio*: dai un nome ai tuoi container per non confonderli:\n",
    "\n",
    "```bash\n",
    "docker run -it --name crew_env python:3.11 bash\n",
    "```\n",
    "\n",
    "Poi puoi riprenderlo facilmente:\n",
    "\n",
    "```bash\n",
    "docker start -ai crew_env\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Montare una cartella locale (persistenza)**\n",
    "\n",
    "Per evitare che tutto vada perso alla chiusura, puoi **montare una directory dell‚Äôhost** nel container:\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash   # su Windows PowerShell\n",
    "```\n",
    "\n",
    "oppure\n",
    "\n",
    "```bash\n",
    "docker run -it -v $(pwd):/app python:3.11 bash # su Linux/macOS\n",
    "```\n",
    "\n",
    "Ora la cartella corrente del tuo computer √® visibile in `/app` dentro il container.\n",
    "Puoi crearci file, script o notebook:\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "nano test.py\n",
    "python test.py\n",
    "```\n",
    "\n",
    "Tutto resta salvato anche dopo l‚Äôuscita, perch√© i file vivono nel filesystem dell‚Äôhost.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Eseguire Python direttamente**\n",
    "\n",
    "Puoi saltare la shell e avviare Python in un solo step:\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11\n",
    "```\n",
    "\n",
    "oppure eseguire un comando singolo:\n",
    "\n",
    "```bash\n",
    "docker run --rm python:3.11 python -c \"print('Hello AI World')\"\n",
    "```\n",
    "\n",
    "L‚Äôopzione `--rm` elimina automaticamente il container una volta terminato.\n",
    "\n",
    " *Utile per test rapidi di librerie CrewAI, LangChain, HuggingFace o Qdrant-client senza installarle localmente.*\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Testare la GPU in un ambiente interattivo**\n",
    "\n",
    "Se hai configurato NVIDIA Container Toolkit:\n",
    "\n",
    "```bash\n",
    "docker run -it --gpus all pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime bash\n",
    "```\n",
    "\n",
    "Poi dentro:\n",
    "\n",
    "```bash\n",
    "python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "‚Üí `True` significa che Docker sta usando la tua GPU correttamente.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Pulizia e gestione**\n",
    "\n",
    "Dopo aver terminato gli esperimenti, puoi pulire facilmente:\n",
    "\n",
    "```bash\n",
    "docker ps -a            # mostra tutti i container\n",
    "docker rm <id>          # rimuove un container\n",
    "docker images           # mostra immagini\n",
    "docker rmi python:3.11  # rimuove un‚Äôimmagine se vuoi liberare spazio\n",
    "```\n",
    "\n",
    " *Docker Desktop mostra tutto anche graficamente, utile per i primi tempi.*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **11. In sintesi**\n",
    "\n",
    "| Azione                       | Comando                           |\n",
    "| ---------------------------- | --------------------------------- |\n",
    "| Avvia ambiente interattivo   | `docker run -it python:3.11 bash` |\n",
    "| Assegna un nome al container | `--name crew_env`                 |\n",
    "| Monta una directory locale   | `-v %cd%:/app`                    |\n",
    "| Riaccedi al container        | `docker start -ai crew_env`       |\n",
    "| Elimina container e immagine | `docker rm` / `docker rmi`        |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8d414-7e4a-4edb-9f43-0b208bdd5414",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **Docker ‚Äì Recap dei Comandi Fondamentali**\n",
    "\n",
    "| **Comando**                                                      | **Funzione**                                              | **Esempio pratico / Descrizione**                                       |\n",
    "| ---------------------------------------------------------------- | --------------------------------------------------------- | ----------------------------------------------------------------------- |\n",
    "| `docker run <img>`                                               | Crea e avvia un container da un‚Äôimmagine                  | `docker run hello-world` ‚Üí esegue un test di installazione              |\n",
    "| `docker run -it <img> bash`                                      | Avvia un container **interattivo** con terminale          | `docker run -it python:3.11 bash` ‚Üí entra in un ambiente Python isolato |\n",
    "| `docker run -it --name <nome>`                                   | Crea container con nome personalizzato                    | `docker run -it --name crew_env python:3.11 bash`                       |\n",
    "| `docker run --rm <img>`                                          | Esegue container temporaneo e lo elimina alla chiusura    | `docker run --rm python:3.11 python -c \"print('Hello')\"`                |\n",
    "| `docker run -v <path_host>:<path_container>`                     | Monta una cartella locale dentro il container             | `docker run -it -v %cd%:/app python:3.11 bash`                          |\n",
    "| `docker run --gpus all <img>`                                    | Espone GPU NVIDIA/AMD al container                        | `docker run --gpus all pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime`   |\n",
    "| `docker ps`                                                      | Mostra i container attivi                                 | `docker ps` ‚Üí elenca solo quelli in esecuzione                          |\n",
    "| `docker ps -a`                                                   | Mostra tutti i container, inclusi quelli fermati          | Utile per controllare container creati o terminati                      |\n",
    "| `docker exec -it <container> bash`                               | Apre shell Bash dentro un container attivo                | `docker exec -it crew_backend bash`                                     |\n",
    "| `docker exec <container> <cmd>`                                  | Esegue un singolo comando dentro un container             | `docker exec crew_backend ls /app`                                      |\n",
    "| `docker logs <container>`                                        | Mostra i log standard del container                       | `docker logs -f crew_backend` ‚Üí segue in tempo reale i log              |\n",
    "| `docker inspect <container>`                                     | Mostra info dettagliate (rete, mount, env, porte)         | `docker inspect qdrant_db`                                              |\n",
    "| `docker inspect -f '{{.NetworkSettings.IPAddress}}' <container>` | Estrae solo l‚ÄôIP interno del container                    | utile per connessioni manuali tra servizi                               |\n",
    "| `docker images`                                                  | Elenca tutte le immagini salvate localmente               | Mostra repository, tag, dimensione e ID                                 |\n",
    "| `docker pull <img>`                                              | Scarica un‚Äôimmagine dal registry (Docker Hub, GHCR, ecc.) | `docker pull python:3.11-slim`                                          |\n",
    "| `docker build -t <nome>:<tag> .`                                 | Crea un‚Äôimmagine a partire da un Dockerfile               | `docker build -t crewai-backend:1.0 .`                                  |\n",
    "| `docker tag <img> <registry>/<repo>:<tag>`                       | Aggiunge un tag per pushare un‚Äôimmagine                   | `docker tag crewai:1.0 myorg/crewai:1.0`                                |\n",
    "| `docker push <repo>`                                             | Carica un‚Äôimmagine sul registry remoto                    | `docker push myorg/crewai:1.0`                                          |\n",
    "| `docker start <container>`                                       | Riavvia un container fermato                              | `docker start crew_backend`                                             |\n",
    "| `docker stop <container>`                                        | Ferma un container attivo                                 | `docker stop crew_backend`                                              |\n",
    "| `docker restart <container>`                                     | Riavvia il container (stop + start)                       | utile per applicare aggiornamenti                                       |\n",
    "| `docker rm <container>`                                          | Rimuove un container fermo                                | `docker rm crew_backend`                                                |\n",
    "| `docker rmi <image>`                                             | Rimuove un‚Äôimmagine locale                                | `docker rmi python:3.11-slim`                                           |\n",
    "| `docker volume ls`                                               | Elenca i volumi persistenti                               | utile per dataset, modelli o DB                                         |\n",
    "| `docker network ls`                                              | Elenca le reti Docker                                     | utile per capire come comunicano i microservizi                         |\n",
    "| `docker compose up -d`                                           | Avvia pi√π container definiti in `docker-compose.yml`      | `docker compose up -d` ‚Üí lancia CrewAI + Qdrant + Streamlit             |\n",
    "| `docker compose down`                                            | Ferma e rimuove tutti i container dello stack             | Cleanup completo di uno stack AI                                        |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120d9fe-a5db-4aa3-a201-a66268bfeb28",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  **Esercizi sui comandi base Docker**\n",
    "\n",
    "---\n",
    "\n",
    "##  **SEZIONE 1 ‚Äì TRACCE (per esercitarsi in autonomia)**\n",
    "\n",
    "### üîπ **Esercizio 1 ‚Äì Primo container interattivo**\n",
    "\n",
    "Crea un container interattivo basato su `python:3.11`, entra al suo interno, installa qualche libreria AI (es. `crewai` e `qdrant-client`), e verifica che funzioni.\n",
    "Chiudi il container e scopri se al riavvio le librerie sono ancora presenti.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 2 ‚Äì Persistenza tramite volume**\n",
    "\n",
    "Ripeti l‚Äôesercizio 1, ma questa volta monta una cartella locale in `/app` dentro il container, salva un file Python e verifica che resti sul disco anche dopo aver chiuso il container.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 3 ‚Äì Creare e rinominare container**\n",
    "\n",
    "Crea due container basati su `python:3.11`:\n",
    "\n",
    "* uno con il nome `crew_test`\n",
    "* uno con il nome `qdrant_test`\n",
    "\n",
    "Elenca i container, fermali e rimuovili entrambi.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 4 ‚Äì Esaminare container attivi**\n",
    "\n",
    "Esegui un container in background (`-d`) basato su `python:3.11-slim` che esegua il comando:\n",
    "\n",
    "```bash\n",
    "python -c \"import time; [print('running...') or time.sleep(2) for _ in range(5)]\"\n",
    "```\n",
    "\n",
    "Poi:\n",
    "\n",
    "1. Controlla che sia attivo.\n",
    "2. Leggi i log del container.\n",
    "3. Ispeziona la sua configurazione (IP, comando, stato).\n",
    "4. Attendi che termini e verifica lo stato con `docker ps -a`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 5 ‚Äì Interagire con un container esistente**\n",
    "\n",
    "Crea un container in background con:\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_env python:3.11 sleep 300\n",
    "```\n",
    "\n",
    "Poi:\n",
    "\n",
    "* entra dentro il container con `docker exec -it`;\n",
    "* crea un file `test.txt`;\n",
    "* leggi il contenuto dall‚Äôhost senza entrare nel container;\n",
    "* infine fermalo e rimuovilo.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 6 ‚Äì Analisi dettagliata**\n",
    "\n",
    "Crea un container basato su `python:3.11`, assegnagli un nome (`analyze_me`) e avvialo.\n",
    "Usa `docker inspect` per:\n",
    "\n",
    "1. Estrarre il suo indirizzo IP interno;\n",
    "2. Verificare il comando di avvio;\n",
    "3. Controllare se ha variabili d‚Äôambiente predefinite.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 7 ‚Äì Pulizia e gestione immagini**\n",
    "\n",
    "1. Elenca le immagini presenti sul tuo sistema.\n",
    "2. Cancella le immagini che non ti servono.\n",
    "3. Rimuovi tutti i container non pi√π in uso.\n",
    "4. Pulisci il sistema con `docker system prune`.\n",
    "5. Controlla quanto spazio hai liberato.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#  **SEZIONE 2 ‚Äì SOLUZIONI GUIDATE PASSO PASSO**\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 1 ‚Äì Primo container interattivo**\n",
    "\n",
    "**1. Avvia il container:**\n",
    "\n",
    "```bash\n",
    "docker run -it python:3.11 bash\n",
    "```\n",
    "\n",
    "**2. All‚Äôinterno:**\n",
    "\n",
    "```bash\n",
    "pip install crewai qdrant-client\n",
    "python -c \"import crewai, qdrant_client; print('ok')\"\n",
    "```\n",
    "\n",
    "**3. Esci:**\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n",
    "\n",
    "**4. Controlla lo stato:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "Il container √® fermo ma ancora presente.\n",
    "Riavvialo:\n",
    "\n",
    "```bash\n",
    "docker start -ai <container_id>\n",
    "```\n",
    "\n",
    "Verifica: le librerie **non sono pi√π installate** ‚Äî il container √® effimero.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 2 ‚Äì Persistenza tramite volume**\n",
    "\n",
    "**1. Avvia il container con volume montato:**\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash\n",
    "```\n",
    "\n",
    "(su Linux/macOS: `-v $(pwd):/app`)\n",
    "\n",
    "**2. All‚Äôinterno del container:**\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "echo \"print('Hello from Docker')\" > hello.py\n",
    "python hello.py\n",
    "```\n",
    "\n",
    "**3. Esci e controlla nella cartella locale:**\n",
    "Il file `hello.py` √® rimasto ‚Üí la persistenza funziona.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 3 ‚Äì Creare e rinominare container**\n",
    "\n",
    "**1. Crea i container:**\n",
    "\n",
    "```bash\n",
    "docker run -it --name crew_test python:3.11 bash\n",
    "docker run -it --name qdrant_test python:3.11 bash\n",
    "```\n",
    "\n",
    "(esci subito da entrambi con `exit`)\n",
    "\n",
    "**2. Elenca i container:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "**3. Ferma e rimuovi:**\n",
    "\n",
    "```bash\n",
    "docker stop crew_test qdrant_test\n",
    "docker rm crew_test qdrant_test\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 4 ‚Äì Esaminare container attivi**\n",
    "\n",
    "**1. Esegui in background:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name test_logger python:3.11-slim python -c \"import time; [print('running...') or time.sleep(2) for _ in range(5)]\"\n",
    "```\n",
    "\n",
    "**2. Controlla stato:**\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "**3. Leggi log:**\n",
    "\n",
    "```bash\n",
    "docker logs test_logger\n",
    "```\n",
    "\n",
    "**4. Ispeziona:**\n",
    "\n",
    "```bash\n",
    "docker inspect test_logger\n",
    "```\n",
    "\n",
    "**5. Dopo 10 secondi:**\n",
    "\n",
    "```bash\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "Il container avr√† `STATUS: Exited`.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 5 ‚Äì Interagire con un container esistente**\n",
    "\n",
    "**1. Avvia container in background:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name crew_env python:3.11 sleep 300\n",
    "```\n",
    "\n",
    "**2. Entra dentro:**\n",
    "\n",
    "```bash\n",
    "docker exec -it crew_env bash\n",
    "```\n",
    "\n",
    "**3. Crea file:**\n",
    "\n",
    "```bash\n",
    "echo \"Docker test OK\" > /tmp/test.txt\n",
    "exit\n",
    "```\n",
    "\n",
    "**4. Leggi contenuto da host:**\n",
    "\n",
    "```bash\n",
    "docker exec crew_env cat /tmp/test.txt\n",
    "```\n",
    "\n",
    "**5. Ferma e rimuovi:**\n",
    "\n",
    "```bash\n",
    "docker stop crew_env\n",
    "docker rm crew_env\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 6 ‚Äì Analisi dettagliata**\n",
    "\n",
    "**1. Crea container:**\n",
    "\n",
    "```bash\n",
    "docker run -d --name analyze_me python:3.11 sleep 60\n",
    "```\n",
    "\n",
    "**2. Estrarre IP:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.NetworkSettings.IPAddress}}' analyze_me\n",
    "```\n",
    "\n",
    "**3. Comando di avvio:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.Config.Cmd}}' analyze_me\n",
    "```\n",
    "\n",
    "**4. Variabili d‚Äôambiente:**\n",
    "\n",
    "```bash\n",
    "docker inspect -f '{{.Config.Env}}' analyze_me\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **Esercizio 7 ‚Äì Pulizia e gestione immagini**\n",
    "\n",
    "**1. Elenca immagini e container:**\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "**2. Cancella tutto ci√≤ che non serve:**\n",
    "\n",
    "```bash\n",
    "docker rm $(docker ps -aq)\n",
    "docker rmi $(docker images -q)\n",
    "```\n",
    "\n",
    "**3. Pulizia generale:**\n",
    "\n",
    "```bash\n",
    "docker system prune -af\n",
    "```\n",
    "\n",
    "**4. Controlla spazio:**\n",
    "\n",
    "```bash\n",
    "docker system df\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff3bc-c9c1-4bbf-9122-da8517d59d2c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1.8 ‚Äì Persistenza notebook/data (`-v`, `--mount`, `--network`)**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema della volatilit√† nei container**\n",
    "\n",
    "Per impostazione predefinita, i container Docker sono **temporanei**.\n",
    "Se li elimini, tutto ci√≤ che era stato scritto dentro (file, notebook, database, modelli scaricati) sparisce.\n",
    "Questo comportamento √® ottimo per test e build pulite, ma in progetti AI √® **inaccettabile**:\n",
    "\n",
    "* vogliamo mantenere **dataset e notebook** tra sessioni,\n",
    "* salvare **cache di modelli Hugging Face**,\n",
    "* preservare **indici vettoriali di Qdrant** o **file SQLite di CrewAI**.\n",
    "\n",
    "Docker offre due modi principali per salvare i dati:\n",
    "\n",
    "* **Volumi** (gestiti da Docker, con `-v` o `--mount`)\n",
    "* **Bind mount** (collega una cartella dell‚Äôhost)\n",
    "\n",
    "Vediamoli nel dettaglio.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Persistenza con `-v` (bind mount)**\n",
    "\n",
    "Il metodo pi√π semplice e immediato per rendere persistenti i dati √® collegare una **cartella locale dell‚Äôhost** a una directory del container.\n",
    "\n",
    "### Esempio:\n",
    "\n",
    "```bash\n",
    "docker run -it -v %cd%:/app python:3.11 bash   # Windows PowerShell\n",
    "```\n",
    "\n",
    "oppure su Linux/macOS:\n",
    "\n",
    "```bash\n",
    "docker run -it -v $(pwd):/app python:3.11 bash\n",
    "```\n",
    "\n",
    "All‚Äôinterno del container, tutto ci√≤ che scrivi in `/app` viene salvato nella tua directory locale.\n",
    "\n",
    "### Test rapido:\n",
    "\n",
    "```bash\n",
    "cd /app\n",
    "echo \"print('Persistente!')\" > test.py\n",
    "exit\n",
    "```\n",
    "\n",
    "Il file `test.py` esiste ancora nel tuo computer locale.\n",
    "\n",
    " **Uso tipico in AI:**\n",
    "\n",
    "* salvare notebook Jupyter (`.ipynb`);\n",
    "* scrivere output JSON o CSV di CrewAI;\n",
    "* mantenere la cache Hugging Face (`/root/.cache/huggingface`).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Persistenza con `--mount` (volumi gestiti da Docker)**\n",
    "\n",
    "`--mount` √® un metodo pi√π moderno e leggibile rispetto a `-v`.\n",
    "Offre maggiore controllo e chiarezza, soprattutto negli script o nei file Compose.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```bash\n",
    "docker run -it --mount type=bind,source=%cd%,target=/app python:3.11 bash\n",
    "```\n",
    "\n",
    "Equivalente a `-v %cd%:/app`, ma pi√π esplicito e robusto.\n",
    "Puoi anche montare **volumi gestiti da Docker**, non solo cartelle locali.\n",
    "\n",
    "### Esempio con volume Docker:\n",
    "\n",
    "```bash\n",
    "docker volume create crew_data\n",
    "docker run -it --mount source=crew_data,target=/app python:3.11 bash\n",
    "```\n",
    "\n",
    "Tutto ci√≤ che salvi in `/app` √® conservato nel volume, anche se elimini il container.\n",
    "Puoi elencare i volumi:\n",
    "\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "e ispezionarli:\n",
    "\n",
    "```bash\n",
    "docker volume inspect crew_data\n",
    "```\n",
    "\n",
    " **Uso tipico in AI:**\n",
    "\n",
    "* salvare database Qdrant (`/qdrant/storage`),\n",
    "* dati CrewAI (`/data`),\n",
    "* cache modelli condivisa tra pi√π container.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Differenza tra `-v` e `--mount`**\n",
    "\n",
    "| Caratteristica  | `-v`                   | `--mount`                               |\n",
    "| --------------- | ---------------------- | --------------------------------------- |\n",
    "| Sintassi        | pi√π corta              | pi√π leggibile e sicura                  |\n",
    "| Tipo            | supporta bind e volume | supporta bind, volume e tmpfs           |\n",
    "| Specificit√†     | stringa unica          | parametri chiari (type, source, target) |\n",
    "| Consigliato per | uso rapido             | ambienti complessi o Compose file       |\n",
    "\n",
    " In produzione e in file `docker-compose.yml`, **usa sempre `--mount`** o la forma YAML di `volumes:`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Persistenza di notebook e dati**\n",
    "\n",
    "Se vuoi eseguire **Jupyter Notebook in container**, devi montare la directory del progetto:\n",
    "\n",
    "```bash\n",
    "docker run -it -p 8888:8888 -v %cd%:/notebooks jupyter/base-notebook\n",
    "```\n",
    "\n",
    "Apri il browser su `localhost:8888` e troverai tutti i tuoi file locali visibili in `/notebooks`.\n",
    "\n",
    "Ogni notebook salvato l√¨ resta anche dopo il riavvio del container.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Persistenza dei modelli AI**\n",
    "\n",
    "Le librerie Hugging Face salvano modelli scaricati in:\n",
    "\n",
    "```\n",
    "~/.cache/huggingface\n",
    "```\n",
    "\n",
    "Se vuoi evitare di riscaricarli ogni volta, monta la cache come volume persistente:\n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "  -v %USERPROFILE%\\.cache\\huggingface:/root/.cache/huggingface \\\n",
    "  pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime bash\n",
    "```\n",
    "\n",
    "Ora ogni container condivider√† la stessa cache dei modelli.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Persistenza di database e vector store**\n",
    "\n",
    "### Qdrant:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "```\n",
    "\n",
    "Il volume `qdrant_data` mantiene l‚Äôindice vettoriale anche dopo il riavvio.\n",
    "\n",
    "### PostgreSQL (es. per CrewAI logs):\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 5432:5432 \\\n",
    "  -v pg_data:/var/lib/postgresql/data \\\n",
    "  -e POSTGRES_PASSWORD=crewpass \\\n",
    "  postgres:15\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Reti personalizzate (`--network`)**\n",
    "\n",
    "In un progetto AI multi-container, serve spesso far comunicare i servizi tra loro (es. CrewAI ‚Üí Qdrant ‚Üí Streamlit).\n",
    "Per farlo Docker offre le **reti bridge personalizzate**.\n",
    "\n",
    "### Creare una rete:\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "```\n",
    "\n",
    "### Eseguire container collegati alla stessa rete:\n",
    "\n",
    "```bash\n",
    "docker run -d --name qdrant --network ai_net qdrant/qdrant:v1.10.0\n",
    "docker run -it --name crew_backend --network ai_net python:3.11 bash\n",
    "```\n",
    "\n",
    "Ora, da dentro `crew_backend`, puoi connetterti a `qdrant` usando:\n",
    "\n",
    "```python\n",
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "```\n",
    "\n",
    " *Non serve conoscere l‚ÄôIP*, Docker risolve automaticamente i nomi dei container come host DNS.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizi pratici**\n",
    "\n",
    "### üîπ **Esercizio 1 ‚Äì Volume locale**\n",
    "\n",
    "1. Crea una cartella `C:\\docker_test`.\n",
    "2. Avvia un container con:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it -v C:\\docker_test:/app python:3.11 bash\n",
    "   ```\n",
    "3. Dentro `/app`, crea `test.py` e scrivi qualcosa.\n",
    "4. Chiudi, verifica che il file sia rimasto nella cartella locale.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 2 ‚Äì Volume Docker**\n",
    "\n",
    "1. Crea volume:\n",
    "\n",
    "   ```bash\n",
    "   docker volume create crew_data\n",
    "   ```\n",
    "2. Avvia container:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it --mount source=crew_data,target=/data python:3.11 bash\n",
    "   ```\n",
    "3. Crea file `/data/persist.txt`.\n",
    "4. Esci e rimuovi il container.\n",
    "5. Avvia un nuovo container con lo stesso volume e verifica che il file esista ancora.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Esercizio 3 ‚Äì Rete condivisa**\n",
    "\n",
    "1. Crea rete:\n",
    "\n",
    "   ```bash\n",
    "   docker network create ai_net\n",
    "   ```\n",
    "2. Avvia Qdrant:\n",
    "\n",
    "   ```bash\n",
    "   docker run -d --name qdrant --network ai_net qdrant/qdrant:v1.10.0\n",
    "   ```\n",
    "3. Avvia Python backend:\n",
    "\n",
    "   ```bash\n",
    "   docker run -it --network ai_net python:3.11 bash\n",
    "   ```\n",
    "4. Dentro Python:\n",
    "\n",
    "   ```python\n",
    "   from qdrant_client import QdrantClient\n",
    "   client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "   print(client.get_collections())\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Riepilogo**\n",
    "\n",
    "| Comando / Opzione               | Funzione                             | Esempio tipico AI                      |\n",
    "| ------------------------------- | ------------------------------------ | -------------------------------------- |\n",
    "| `-v host:container`             | Collega cartella locale (bind mount) | Notebook, codice sorgente              |\n",
    "| `--mount source=...,target=...` | Volume gestito da Docker             | Cache modelli, database, indici Qdrant |\n",
    "| `docker volume create <name>`   | Crea volume persistente              | `docker volume create crew_data`       |\n",
    "| `docker network create <name>`  | Crea rete personalizzata             | `docker network create ai_net`         |\n",
    "| `--network <name>`              | Collega container alla stessa rete   | `--network ai_net`                     |\n",
    "| `docker volume ls`              | Mostra volumi                        | Verifica storage CrewAI                |\n",
    "| `docker network ls`             | Mostra reti                          | Debug connessioni tra container        |\n",
    "\n",
    "---\n",
    "\n",
    "Docker non √® solo ‚Äúun contenitore‚Äù: √® un **ecosistema di filesystem, reti e processi**.\n",
    "Per un AI Engineer, capire come usare `-v`, `--mount` e `--network` significa saper costruire **pipeline CrewAI e RAG persistenti**, scalabili e interconnesse in modo professionale.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8a185-6049-44ea-b5c7-a8ca3223d88e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.1 ‚Äì Cos‚Äô√® un Dockerfile**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Definizione**\n",
    "\n",
    "Un **Dockerfile** √® un semplice **file di testo** che contiene **le istruzioni** per costruire un‚Äôimmagine Docker.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* descrive **passo dopo passo** come creare un ambiente completo (sistema operativo, librerie, codice, comandi d‚Äôavvio);\n",
    "* Docker lo ‚Äúlegge‚Äù e, seguendo quelle istruzioni, costruisce un‚Äôimmagine pronta all‚Äôuso;\n",
    "* quell‚Äôimmagine pu√≤ poi essere eseguita su qualsiasi computer o server con Docker installato, **sempre nello stesso modo**.\n",
    "\n",
    "√à, a tutti gli effetti, **la ricetta dell‚Äôambiente di esecuzione**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Analogia**\n",
    "\n",
    "Pensa al Dockerfile come a una **ricetta di cucina**:\n",
    "\n",
    "* Ogni riga √® un ingrediente o un‚Äôazione (es. ‚Äúinstalla Python‚Äù, ‚Äúcopia il codice‚Äù).\n",
    "* Docker √® il cuoco che la legge e prepara il piatto (l‚Äôimmagine).\n",
    "* L‚Äôimmagine finale √® il **piatto pronto** (un ambiente completo e isolato).\n",
    "* Quando ‚Äúservi il piatto‚Äù (cio√® lanci un container), Docker prende quell‚Äôimmagine e la esegue come un piccolo sistema operativo in miniatura.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Perch√© serve**\n",
    "\n",
    "Nel mondo AI o software moderno, lavorare su progetti complessi come:\n",
    "\n",
    "* **CrewAI** (pi√π agenti, librerie AI, dipendenze pesanti),\n",
    "* **LangChain** (diverse versioni di pacchetti),\n",
    "* **Qdrant** o **PostgreSQL** (database separati),\n",
    "* **Streamlit** o **FastAPI** (frontend e API),\n",
    "\n",
    "significa dover gestire decine di librerie e ambienti.\n",
    "Un Dockerfile risolve questo problema: crea un ambiente **standardizzato e replicabile**, che chiunque pu√≤ ricostruire con un solo comando.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Come funziona**\n",
    "\n",
    "Docker legge il Dockerfile **dall‚Äôalto verso il basso**.\n",
    "Ogni istruzione crea un ‚Äú**layer**‚Äù dell‚Äôimmagine: un piccolo pezzo di filesystem.\n",
    "L‚Äôinsieme di questi layer forma l‚Äôimmagine finale.\n",
    "\n",
    "Esempio semplificato:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Vediamolo in parole:\n",
    "\n",
    "1. **FROM python:3.11-slim** ‚Üí usa come base un sistema Linux con Python 3.11 gi√† installato.\n",
    "2. **WORKDIR /app** ‚Üí imposta la directory di lavoro.\n",
    "3. **COPY . .** ‚Üí copia i file del progetto nel container.\n",
    "4. **RUN pip install -r requirements.txt** ‚Üí installa le librerie.\n",
    "5. **CMD [\"python\", \"main.py\"]** ‚Üí definisce il comando da eseguire quando il container parte.\n",
    "\n",
    "Il risultato sar√† un‚Äôimmagine Docker con:\n",
    "\n",
    "* Python 3.11\n",
    "* tutte le librerie del progetto\n",
    "* il codice copiato\n",
    "* pronta per avviarsi con `python main.py`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Creare e usare un Dockerfile**\n",
    "\n",
    "1. Crea un file chiamato `Dockerfile` (senza estensione).\n",
    "2. Scrivi le istruzioni dentro.\n",
    "3. Costruisci l‚Äôimmagine con:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t nome-immagine .\n",
    "   ```\n",
    "\n",
    "   (`-t` = tag, `.` = directory corrente dove si trova il Dockerfile)\n",
    "4. Avvia un container da quell‚Äôimmagine:\n",
    "\n",
    "   ```bash\n",
    "   docker run nome-immagine\n",
    "   ```\n",
    "\n",
    "Esempio completo:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai-backend .\n",
    "docker run -it crewai-backend\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Struttura tipica**\n",
    "\n",
    "Ogni Dockerfile segue un ordine logico:\n",
    "\n",
    "| Sezione        | Istruzione                 | Funzione                                                  |\n",
    "| -------------- | -------------------------- | --------------------------------------------------------- |\n",
    "| Base           | `FROM`                     | Sceglie l‚Äôimmagine di partenza (es. Python, Node, Ubuntu) |\n",
    "| Setup          | `RUN`                      | Esegue comandi (es. installazioni, aggiornamenti)         |\n",
    "| Copia codice   | `COPY` / `ADD`             | Copia file dal computer nel container                     |\n",
    "| Configurazione | `ENV`, `WORKDIR`, `EXPOSE` | Imposta variabili e directory                             |\n",
    "| Avvio          | `CMD` / `ENTRYPOINT`       | Definisce il comando di esecuzione                        |\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Differenza tra immagine e container**\n",
    "\n",
    "* Il **Dockerfile** costruisce l‚Äô**immagine** (il modello).\n",
    "* Da quell‚Äôimmagine si possono creare pi√π **container** (le istanze in esecuzione).\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai:latest .\n",
    "docker run -d --name crew1 crewai:latest\n",
    "docker run -d --name crew2 crewai:latest\n",
    "```\n",
    "\n",
    "‚Üí stesso ambiente, due container indipendenti.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico**\n",
    "\n",
    "1. Crea una nuova cartella:\n",
    "\n",
    "   ```\n",
    "   docker_test/\n",
    "   ‚îú‚îÄ‚îÄ Dockerfile\n",
    "   ‚îî‚îÄ‚îÄ main.py\n",
    "   ```\n",
    "2. In `main.py` scrivi:\n",
    "\n",
    "   ```python\n",
    "   print(\"Hello from Docker!\")\n",
    "   ```\n",
    "3. In `Dockerfile`:\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM python:3.11-slim\n",
    "   WORKDIR /app\n",
    "   COPY . .\n",
    "   CMD [\"python\", \"main.py\"]\n",
    "   ```\n",
    "4. Costruisci e avvia:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t hello-docker .\n",
    "   docker run hello-docker\n",
    "   ```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Hello from Docker!\n",
    "```\n",
    "\n",
    "Ora hai creato la tua prima immagine personalizzata.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. In sintesi**\n",
    "\n",
    "| Concetto             | Descrizione                                                   |\n",
    "| -------------------- | ------------------------------------------------------------- |\n",
    "| Dockerfile           | File di testo con istruzioni per costruire un ambiente Docker |\n",
    "| Immagine             | L‚Äôambiente creato a partire dal Dockerfile                    |\n",
    "| Container            | L‚Äôistanza in esecuzione dell‚Äôimmagine                         |\n",
    "| `docker build`       | Crea l‚Äôimmagine                                               |\n",
    "| `docker run`         | Esegue il container                                           |\n",
    "| `FROM`               | Base del sistema                                              |\n",
    "| `RUN`, `COPY`, `CMD` | Istruzioni principali                                         |\n",
    "\n",
    "---\n",
    "\n",
    "Un Dockerfile √® quindi **il cuore di ogni progetto containerizzato**.\n",
    "Nei prossimi punti impareremo:\n",
    "\n",
    "* come ottimizzarlo per AI (ridurre peso e tempi di build),\n",
    "* come gestire dipendenze, cache e volumi,\n",
    "* e come scrivere Dockerfile modulari per pipeline CrewAI reali.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ddb26-0897-4a66-9c9f-b3f8982b52de",
   "metadata": {},
   "source": [
    "\n",
    "# **2.2 ‚Äì Istruzioni fondamentali del Dockerfile**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. `FROM` ‚Äì l‚Äôimmagine di base**\n",
    "\n",
    "√à **sempre la prima riga** di un Dockerfile.\n",
    "Serve per specificare **da quale sistema operativo o ambiente di partenza** costruire la tua immagine.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "```\n",
    "\n",
    "‚Üí parte da Debian ‚Äúslim‚Äù con Python 3.11 gi√† installato.\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
    "```\n",
    "\n",
    "‚Üí parte da un ambiente gi√† pronto per PyTorch con CUDA e cuDNN.\n",
    "\n",
    "### Regole:\n",
    "\n",
    "* puoi usare **immagini ufficiali** (es. python, node, ubuntu) o personalizzate;\n",
    "* √® possibile **cambiare base** in base al progetto (CPU-only o GPU);\n",
    "* ogni immagine base contiene gi√† un piccolo sistema Linux.\n",
    "\n",
    " *Best practice per AI:*\n",
    "\n",
    "* per ambienti CPU: `python:3.11-slim`;\n",
    "* per GPU NVIDIA: `pytorch/pytorch:<ver>-cuda<xx>-runtime`;\n",
    "* per GPU AMD: `rocm/pytorch:latest`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `WORKDIR` ‚Äì directory di lavoro**\n",
    "\n",
    "Definisce **la cartella in cui verranno eseguiti tutti i comandi successivi** (come `RUN`, `COPY`, `CMD`, ecc.).\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "‚Üí Tutti i comandi successivi verranno eseguiti come se fossi dentro `/app`.\n",
    "\n",
    "Puoi definirne pi√π d‚Äôuno:\n",
    "\n",
    "```dockerfile\n",
    "WORKDIR /usr/src\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "‚Üí il secondo sovrascrive il primo (come un `cd`).\n",
    "\n",
    " *Best practice:*\n",
    "Usa sempre `WORKDIR` e **non** `/` o directory di sistema per scrivere i tuoi file.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `COPY` ‚Äì copia file dall‚Äôhost al container**\n",
    "\n",
    "Serve per trasferire file e cartelle dal tuo computer (host) all‚Äôinterno dell‚Äôimmagine.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "‚Üí copia tutti i file della directory corrente nel container (nella `WORKDIR`).\n",
    "\n",
    "Puoi anche essere pi√π specifico:\n",
    "\n",
    "```dockerfile\n",
    "COPY requirements.txt .\n",
    "COPY src/ ./src\n",
    "```\n",
    "\n",
    " *Suggerimenti:*\n",
    "\n",
    "* escludi file inutili con `.dockerignore` (es. `.git`, `__pycache__`, `venv`, `data/`);\n",
    "* mantieni ordine: prima copia i file di dipendenze (`requirements.txt`), poi il codice.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `RUN` ‚Äì esegue comandi durante la build**\n",
    "\n",
    "`RUN` viene eseguito **mentre si costruisce l‚Äôimmagine**, non quando il container parte.\n",
    "Serve per installare librerie, creare directory, aggiornare pacchetti, ecc.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "RUN apt-get update && apt-get install -y git\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "```\n",
    "\n",
    "Ogni `RUN` crea un **nuovo layer** dell‚Äôimmagine.\n",
    "\n",
    " *Ottimizzazione:*\n",
    "\n",
    "* combina pi√π comandi con `&&` per ridurre i layer;\n",
    "* pulisci la cache di apt per alleggerire l‚Äôimmagine:\n",
    "\n",
    "  ```dockerfile\n",
    "  RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*\n",
    "  ```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `ENV` ‚Äì definisce variabili d‚Äôambiente**\n",
    "\n",
    "Le variabili definite con `ENV` sono visibili **dentro il container** a runtime.\n",
    "Molto utile per chiavi API, configurazioni o impostazioni di Python.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "```dockerfile\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV OPENAI_API_KEY=\"sk-xxxxx\"\n",
    "```\n",
    "\n",
    "Puoi anche dichiararle tutte insieme:\n",
    "\n",
    "```dockerfile\n",
    "ENV PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PYTHONUNBUFFERED=1 \\\n",
    "    PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "```\n",
    "\n",
    " *Best practice per AI:*\n",
    "\n",
    "* imposta sempre `PYTHONUNBUFFERED=1` ‚Üí output immediato nei log;\n",
    "* evita di scrivere chiavi sensibili nel Dockerfile ‚Üí passa le variabili con `-e` nel `docker run`.\n",
    "\n",
    "Esempio runtime:\n",
    "\n",
    "```bash\n",
    "docker run -e OPENAI_API_KEY=$OPENAI_API_KEY crewai-backend\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. `EXPOSE` ‚Äì documenta le porte usate**\n",
    "\n",
    "Serve per **indicare quale porta interna del container** viene usata dal servizio.\n",
    "Non apre realmente la porta, ma aiuta Docker a sapere come mappare correttamente.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "EXPOSE 8080\n",
    "```\n",
    "\n",
    "‚Üí Il container comunica sulla porta 8080.\n",
    "Poi, quando lo lanci:\n",
    "\n",
    "```bash\n",
    "docker run -p 8080:8080 crewai-backend\n",
    "```\n",
    "\n",
    "la porta 8080 del container √® raggiungibile come `localhost:8080`.\n",
    "\n",
    " *Best practice:*\n",
    "\n",
    "* API backend: 8000 o 8080\n",
    "* Qdrant: 6333\n",
    "* Streamlit: 8501\n",
    "\n",
    "---\n",
    "\n",
    "## **7. `CMD` ‚Äì comando di avvio del container**\n",
    "\n",
    "√à il comando che viene eseguito **quando il container parte**.\n",
    "Ogni immagine pu√≤ avere **un solo CMD**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Alternative:\n",
    "\n",
    "```dockerfile\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "CMD [\"streamlit\", \"run\", \"ui/Home.py\", \"--server.port\", \"8501\"]\n",
    "```\n",
    "\n",
    " *Regole:*\n",
    "\n",
    "* se nel `docker run` specifichi un comando manuale, questo **sovrascrive** il CMD;\n",
    "\n",
    "  ```bash\n",
    "  docker run myimage python other_script.py\n",
    "  ```\n",
    "* il CMD deve sempre essere l‚Äôultimo comando del Dockerfile;\n",
    "* usa la sintassi **JSON array** (non shell) per evitare errori di parsing.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. `ENTRYPOINT` ‚Äì comando fisso di avvio**\n",
    "\n",
    "Simile a `CMD`, ma **non pu√≤ essere sovrascritto** facilmente.\n",
    "Serve per rendere ‚Äúeseguibile‚Äù il container.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"main.py\"]\n",
    "```\n",
    "\n",
    "‚Üí di default esegue `python main.py`, ma puoi fare:\n",
    "\n",
    "```bash\n",
    "docker run myimage other.py\n",
    "```\n",
    "\n",
    "‚Üí eseguir√† `python other.py`.\n",
    "\n",
    " *Regola generale:*\n",
    "\n",
    "* usa `ENTRYPOINT` se vuoi rendere il container eseguibile (CLI tool, script);\n",
    "* usa `CMD` per applicazioni (server, API).\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Altri comandi utili (cenni rapidi)**\n",
    "\n",
    "| Comando       | Funzione                                                            |\n",
    "| ------------- | ------------------------------------------------------------------- |\n",
    "| `ADD`         | Come `COPY`, ma pu√≤ scaricare URL o scompattare archivi             |\n",
    "| `LABEL`       | Aggiunge metadati all‚Äôimmagine (autore, versione)                   |\n",
    "| `USER`        | Imposta l‚Äôutente che esegue i comandi (non root per sicurezza)      |\n",
    "| `ARG`         | Variabili disponibili solo durante la build (es. `ARG PY_VER=3.11`) |\n",
    "| `ONBUILD`     | Comandi che si attivano solo in immagini derivate                   |\n",
    "| `HEALTHCHECK` | Controlla lo stato del container periodicamente                     |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Esercizio pratico: costruire un Dockerfile completo**\n",
    "\n",
    "1. Crea una cartella `myapp/`\n",
    "\n",
    "   ```\n",
    "   myapp/\n",
    "   ‚îú‚îÄ‚îÄ Dockerfile\n",
    "   ‚îú‚îÄ‚îÄ requirements.txt\n",
    "   ‚îî‚îÄ‚îÄ app.py\n",
    "   ```\n",
    "\n",
    "2. In `requirements.txt`:\n",
    "\n",
    "   ```\n",
    "   fastapi==0.114.0\n",
    "   uvicorn==0.30.6\n",
    "   ```\n",
    "\n",
    "3. In `app.py`:\n",
    "\n",
    "   ```python\n",
    "   from fastapi import FastAPI\n",
    "   app = FastAPI()\n",
    "\n",
    "   @app.get(\"/\")\n",
    "   def hello():\n",
    "       return {\"msg\": \"Hello from Docker!\"}\n",
    "   ```\n",
    "\n",
    "4. In `Dockerfile`:\n",
    "\n",
    "   ```dockerfile\n",
    "   FROM python:3.11-slim\n",
    "   WORKDIR /app\n",
    "   COPY requirements.txt .\n",
    "   RUN pip install --no-cache-dir -r requirements.txt\n",
    "   COPY . .\n",
    "   EXPOSE 8080\n",
    "   CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "   ```\n",
    "\n",
    "5. Costruisci e lancia:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t fastapi-demo .\n",
    "   docker run -p 8080:8080 fastapi-demo\n",
    "   ```\n",
    "\n",
    "6. Apri [http://localhost:8080](http://localhost:8080)\n",
    "   ‚Üí dovresti vedere:\n",
    "   `{\"msg\": \"Hello from Docker!\"}`\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Riepilogo**\n",
    "\n",
    "| Istruzione   | Scopo                      | Esempio                               |\n",
    "| ------------ | -------------------------- | ------------------------------------- |\n",
    "| `FROM`       | Base dell‚Äôimmagine         | `FROM python:3.11-slim`               |\n",
    "| `WORKDIR`    | Directory di lavoro        | `WORKDIR /app`                        |\n",
    "| `COPY`       | Copia file nel container   | `COPY . .`                            |\n",
    "| `RUN`        | Esegue comandi di build    | `RUN pip install -r requirements.txt` |\n",
    "| `ENV`        | Imposta variabili ambiente | `ENV PYTHONUNBUFFERED=1`              |\n",
    "| `EXPOSE`     | Documenta porte            | `EXPOSE 8080`                         |\n",
    "| `CMD`        | Comando di avvio           | `CMD [\"python\", \"main.py\"]`           |\n",
    "| `ENTRYPOINT` | Comando fisso di avvio     | `ENTRYPOINT [\"python\"]`               |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefa521-a0c6-4337-bd19-7ee71b48bb48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.3 ‚Äì Multi-Stage Build: spiegazione semplice e chiara**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema da cui nasce**\n",
    "\n",
    "Quando crei un‚Äôimmagine Docker, spesso hai **due momenti distinti**:\n",
    "\n",
    "1. **La costruzione (build)**\n",
    "   dove installi compilatori, scarichi repository da Git, compili estensioni, ecc.\n",
    "   ‚Üí serve molta roba (pacchetti di sviluppo, tool, file temporanei).\n",
    "\n",
    "2. **L‚Äôesecuzione (runtime)**\n",
    "   dove ti serve solo il risultato finale: il tuo programma e le librerie gi√† pronte.\n",
    "   ‚Üí tutto il resto (tool, cache, file temporanei) √® inutile e appesantisce l‚Äôimmagine.\n",
    "\n",
    "---\n",
    "\n",
    "###  Senza multi-stage\n",
    "\n",
    "Se fai tutto nello stesso Dockerfile, ti ritrovi un‚Äôimmagine **enorme** e piena di file inutili.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Risultato:\n",
    "\n",
    "* immagine da **2-3 GB**,\n",
    "* dentro ci sono compilatori, header file, cache pip‚Ä¶\n",
    "* e tutto ci√≤ non serve pi√π a runtime.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. L‚Äôidea del multi-stage build**\n",
    "\n",
    "Docker ti permette di dividere la build in **pi√π ‚Äúfasi‚Äù (stages)**.\n",
    "Ogni stage ha la sua immagine base e il suo ambiente.\n",
    "Alla fine puoi **prendere solo quello che ti serve** e buttar via tutto il resto.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* uno **stage builder** fa tutto il lavoro pesante (installa, compila, crea file).\n",
    "* uno **stage finale (runtime)** parte pulito e riceve **solo i file utili** dal builder.\n",
    "\n",
    "---\n",
    "\n",
    "###  Esempio semplice\n",
    "\n",
    "```dockerfile\n",
    "# STAGE 1 ‚Äì Builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# STAGE 2 ‚Äì Runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build /app\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* La prima parte (`AS builder`) crea un‚Äôimmagine temporanea chiamata *builder*.\n",
    "* Installa l√¨ tutte le dipendenze.\n",
    "* La seconda parte (`FROM ... AS runtime`) crea l‚Äôimmagine finale.\n",
    "* `COPY --from=builder` prende solo ci√≤ che serve dal primo stage.\n",
    "* Il risultato finale √® **pulito, piccolo e pronto all‚Äôuso**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Cosa succede dentro Docker**\n",
    "\n",
    "Quando Docker costruisce questo file:\n",
    "\n",
    "1. Crea il primo stage (`builder`), installa tutto.\n",
    "2. Poi **scarta** quell‚Äôimmagine, ma conserva i file copiati.\n",
    "3. Costruisce la seconda immagine (`runtime`), che contiene solo quei file.\n",
    "\n",
    "‚Üí Risultato: la seconda immagine non ha compilatori, cache o file temporanei.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Vantaggi pratici**\n",
    "\n",
    "| Vantaggio                | Descrizione                                       |\n",
    "| ------------------------ | ------------------------------------------------- |\n",
    "| **Immagini pi√π leggere** | Eviti di includere tool di build e cache pip      |\n",
    "| **Build pi√π pulite**     | Separi logica di build da logica di esecuzione    |\n",
    "| **Pi√π sicurezza**        | Meno tool e pacchetti = meno vulnerabilit√†        |\n",
    "| **Facile da mantenere**  | Ogni fase ha uno scopo chiaro                     |\n",
    "| **Ottimo per CI/CD**     | Puoi riusare gli stessi stage in pipeline diverse |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Esempio reale ‚Äì Python con librerie AI**\n",
    "\n",
    "Supponiamo di voler costruire un‚Äôimmagine per un progetto CrewAI o LangChain.\n",
    "Serve scaricare molte dipendenze Python, alcune anche da Git.\n",
    "\n",
    "Ecco come useresti un multi-stage build semplice:\n",
    "\n",
    "```dockerfile\n",
    "# FASE 1 ‚Äî Builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "\n",
    "# Installa git e altri strumenti solo qui\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends git build-essential\n",
    "\n",
    "# Copia le dipendenze e installale in una directory temporanea\n",
    "COPY requirements.txt .\n",
    "RUN pip install --target=/build/deps -r requirements.txt\n",
    "\n",
    "# FASE 2 ‚Äî Runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "\n",
    "# Copia solo i file delle librerie gi√† installate\n",
    "COPY --from=builder /build/deps /usr/local/lib/python3.11/site-packages\n",
    "\n",
    "# Copia il codice dell‚Äôapp\n",
    "COPY . .\n",
    "\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    " Risultato:\n",
    "\n",
    "* L‚Äôimmagine finale contiene solo Python + le librerie installate + il tuo codice.\n",
    "* Tutti i tool di build e la cache pip **restano nel builder e vengono scartati**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Multi-stage = pi√π di due fasi**\n",
    "\n",
    "Puoi avere anche 3 o pi√π fasi se vuoi separare meglio i compiti.\n",
    "Esempio tipico per un‚Äôapp AI con API:\n",
    "\n",
    "1. **builder** ‚Üí prepara le dipendenze (pip o poetry).\n",
    "2. **api-builder** ‚Üí costruisce file statici o script ottimizzati.\n",
    "3. **runtime** ‚Üí esegue l‚Äôapp (FastAPI o Streamlit).\n",
    "\n",
    "Docker ti permette di copiare file da qualunque fase:\n",
    "\n",
    "```dockerfile\n",
    "COPY --from=api-builder /dist /app\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Come dare un nome alle fasi**\n",
    "\n",
    "Ogni fase ha un nome definito da `AS`.\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "...\n",
    "FROM python:3.11-slim AS runtime\n",
    "COPY --from=builder /build /app\n",
    "```\n",
    "\n",
    "Il nome √® utile per dire a Docker **da quale stage copiare i file**.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Esercizio pratico ‚Äì Creiamo due immagini a confronto**\n",
    "\n",
    "### A) Dockerfile semplice (senza multi-stage)\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN apt-get update && apt-get install -y git && pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### B) Dockerfile multi-stage\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "RUN apt-get update && apt-get install -y git\n",
    "COPY requirements.txt .\n",
    "RUN pip install --target=/build/deps -r requirements.txt\n",
    "\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build/deps /usr/local/lib/python3.11/site-packages\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "### Confronto\n",
    "\n",
    "| Aspetto              | A) Singolo stage | B) Multi-stage         |\n",
    "| -------------------- | ---------------- | ---------------------- |\n",
    "| Dimensione immagine  | 2-3 GB           | ~800 MB                |\n",
    "| Contiene build-tools | ‚úÖ s√¨             | ‚ùå no                   |\n",
    "| Sicurezza            | minore           | maggiore               |\n",
    "| Portabilit√†          | limitata         | alta                   |\n",
    "| Tempo rebuild        | pi√π lento        | pi√π rapido (cache pip) |\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Come si costruisce**\n",
    "\n",
    "Comando identico:\n",
    "\n",
    "```bash\n",
    "docker build -t myapp:latest .\n",
    "```\n",
    "\n",
    "Docker capisce automaticamente che ci sono pi√π fasi e costruisce solo l‚Äôultima (salvando cache intermedia).\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Cosa ricordare**\n",
    "\n",
    "| Concetto                                | Spiegazione                                   |\n",
    "| --------------------------------------- | --------------------------------------------- |\n",
    "| Ogni `FROM` crea una nuova fase         | Le fasi possono avere nomi (`AS builder`)     |\n",
    "| `COPY --from=`                          | Copia file da una fase all‚Äôaltra              |\n",
    "| Lo stage finale √® l‚Äôimmagine che rimane | Tutto il resto viene eliminato                |\n",
    "| Obiettivo                               | separare build ‚Äúpesante‚Äù da runtime ‚Äúleggero‚Äù |\n",
    "| Beneficio principale                    | immagini pi√π piccole, sicure e veloci         |\n",
    "\n",
    "---\n",
    "\n",
    " **In sintesi**\n",
    "\n",
    "* Il multi-stage non cambia cosa fa Docker, ma **come lo organizza**.\n",
    "* √à il modo corretto di costruire immagini **professionali**, soprattutto nel mondo AI.\n",
    "* Ti permette di preparare ambienti complessi (Torch, Transformers, CrewAI, Qdrant) e distribuire solo ci√≤ che serve per l‚Äôesecuzione.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78675233-6449-4ff4-9a23-b61ae55c3197",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.4 ‚Äì ENTRYPOINT per comandi complessi**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. A cosa serve `ENTRYPOINT`**\n",
    "\n",
    "Quando costruisci un‚Äôimmagine, devi dire a Docker **che cosa fare quando il container parte**.\n",
    "Puoi farlo in due modi:\n",
    "\n",
    "* con `CMD`\n",
    "* con `ENTRYPOINT`\n",
    "\n",
    "Entrambi indicano **il comando di avvio**, ma con una differenza importante:\n",
    "\n",
    "| Comando      | Pu√≤ essere sovrascritto da `docker run` | Tipico uso                                     |\n",
    "| ------------ | --------------------------------------- | ---------------------------------------------- |\n",
    "| `CMD`        | ‚úÖ s√¨                                    | eseguire un‚Äôapp o uno script semplice          |\n",
    "| `ENTRYPOINT` | ‚ùå no (di default)                       | rendere il container un *programma* eseguibile |\n",
    "\n",
    " `ENTRYPOINT` rende l‚Äôimmagine ‚Äúcomportarsi‚Äù come un comando.\n",
    "Ad esempio, se hai un tool AI che esegue analisi o scraping, vuoi lanciare:\n",
    "\n",
    "```bash\n",
    "docker run my-ai-analyzer input.txt\n",
    "```\n",
    "\n",
    "e far s√¨ che il container esegua qualcosa tipo:\n",
    "\n",
    "```bash\n",
    "python analyze.py input.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Due sintassi possibili**\n",
    "\n",
    "### a) **Exec form (raccomandata)**\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "‚Üí Docker esegue direttamente il processo come se fosse nativo (senza shell).\n",
    "\n",
    "### b) **Shell form**\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT python main.py\n",
    "```\n",
    "\n",
    "‚Üí viene eseguito dentro `/bin/sh -c`, utile se ti servono operatori shell (`&&`, `|`, `;`), ma meno sicuro e meno efficiente.\n",
    "\n",
    " *Best practice*: usa **exec form** (lista JSON) per applicazioni reali, shell form solo per script d‚Äôavvio complessi.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. ENTRYPOINT + CMD = combinazione potente**\n",
    "\n",
    "Puoi usare **entrambi**.\n",
    "Docker combina `ENTRYPOINT` e `CMD`:\n",
    "\n",
    "* `ENTRYPOINT` definisce **il programma principale**,\n",
    "* `CMD` definisce **gli argomenti di default**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "CMD [\"--help\"]\n",
    "```\n",
    "\n",
    "‚Üí se lanci:\n",
    "\n",
    "```bash\n",
    "docker run myapp\n",
    "```\n",
    "\n",
    "esegue:\n",
    "`python main.py --help`\n",
    "\n",
    "Ma se lanci:\n",
    "\n",
    "```bash\n",
    "docker run myapp --version\n",
    "```\n",
    "\n",
    "esegue:\n",
    "`python main.py --version`\n",
    "\n",
    "> Docker sostituisce **solo gli argomenti del CMD**, non l‚ÄôENTRYPOINT.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **4. ENTRYPOINT + script Bash per comandi complessi**\n",
    "\n",
    "Spesso ti serve eseguire pi√π cose all‚Äôavvio (es. inizializzare modelli, verificare database, poi avviare CrewAI).\n",
    "In questo caso puoi usare uno **script shell** come entrypoint.\n",
    "\n",
    "### a) Dockerfile\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install crewai qdrant-client\n",
    "COPY entrypoint.sh /entrypoint.sh\n",
    "RUN chmod +x /entrypoint.sh\n",
    "ENTRYPOINT [\"/entrypoint.sh\"]\n",
    "```\n",
    "\n",
    "### b) `entrypoint.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e  # interrompe se c‚Äô√® un errore\n",
    "\n",
    "echo \"üß† Inizializzazione CrewAI...\"\n",
    "python setup_models.py\n",
    "\n",
    "echo \"üóÑÔ∏è  Controllo connessione Qdrant...\"\n",
    "python check_qdrant.py\n",
    "\n",
    "echo \"üöÄ Avvio server principale...\"\n",
    "exec python main.py \"$@\"\n",
    "```\n",
    "\n",
    " `exec` √® importante: sostituisce il processo Bash con Python, evitando che Docker perda i log o il PID del processo principale.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. ENTRYPOINT con comandi concatenati**\n",
    "\n",
    "Puoi anche combinare comandi multipli direttamente nel Dockerfile, ma solo se necessario:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"/bin/bash\", \"-c\", \"python prepare.py && python main.py\"]\n",
    "```\n",
    "\n",
    "Tuttavia, **non √® consigliato** per progetti complessi ‚Äî molto meglio usare uno script dedicato come visto sopra.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Personalizzare i parametri in `docker run`**\n",
    "\n",
    "Con `ENTRYPOINT`, puoi passare argomenti extra da linea di comando.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "ENTRYPOINT [\"python\", \"main.py\"]\n",
    "CMD [\"--help\"]\n",
    "```\n",
    "\n",
    "Puoi cambiare i parametri:\n",
    "\n",
    "```bash\n",
    "docker run myapp --input=data.txt --verbose\n",
    "```\n",
    "\n",
    "‚Üí Docker esegue `python main.py --input=data.txt --verbose`\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Esempio complesso: FastAPI + CrewAI orchestrato**\n",
    "\n",
    "Ecco un esempio realistico per un progetto AI con pi√π servizi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "COPY entrypoint.sh /entrypoint.sh\n",
    "RUN chmod +x /entrypoint.sh  #change mode to x, executable\n",
    "ENTRYPOINT [\"/entrypoint.sh\"]\n",
    "```\n",
    "\n",
    "`entrypoint.sh`:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \" Avvio Qdrant (in background)...\"\n",
    "docker-entrypoint.sh qdrant &\n",
    "\n",
    "echo \" Avvio CrewAI Server...\"\n",
    "exec uvicorn app.main:app --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "In Compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  crewai:\n",
    "    build: .\n",
    "    ports: [\"8080:8080\"]\n",
    "    depends_on: [qdrant]\n",
    "```\n",
    "\n",
    "> Lo script fa partire prima Qdrant, poi CrewAI, in modo ordinato e monitorabile.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Differenze tra ENTRYPOINT e CMD (recap)**\n",
    "\n",
    "| Aspetto                         | `ENTRYPOINT`                           | `CMD`                                    |\n",
    "| ------------------------------- | -------------------------------------- | ---------------------------------------- |\n",
    "| Scopo                           | definisce **il programma principale**  | definisce **gli argomenti di default**   |\n",
    "| Sovrascrizione con `docker run` | ‚ùå no (a meno di usare `--entrypoint`)  | ‚úÖ s√¨                                     |\n",
    "| Sintassi preferita              | JSON array                             | JSON array                               |\n",
    "| Tipico uso                      | CLI, script di startup, orchestrazione | impostare default o parametri            |\n",
    "| Posizione                       | 1 sola per Dockerfile                  | 1 sola (spesso combinata con ENTRYPOINT) |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a6b76-666e-4f60-9f38-0f34015f8b9b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **2.5 ‚Äì Caching layer e `.dockerignore` nei progetti CrewAI**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Il problema reale**\n",
    "\n",
    "I progetti AI (e in particolare CrewAI) hanno due caratteristiche:\n",
    "\n",
    "1. **Dipendenze pesanti**\n",
    "   Torch, Transformers, LangChain, Qdrant-client, OpenAI SDK, ecc.\n",
    "   Ogni `pip install` pu√≤ impiegare minuti e scaricare centinaia di MB.\n",
    "\n",
    "2. **File locali numerosi e inutili per la build**\n",
    "   cartelle `.git`, `.venv`, `models/`, `__pycache__/`, `data/`, `.env` ‚Üí inutili nell‚Äôimmagine.\n",
    "\n",
    "Senza caching e `.dockerignore`, ogni modifica nel codice fa **ripartire tutto da zero**,\n",
    "ricostruendo anche le librerie pesanti e copiando file superflui.\n",
    "Il risultato?\n",
    "\n",
    "* tempi di build lunghi (anche >10 minuti),\n",
    "* immagini da diversi GB,\n",
    "* scarsa portabilit√†.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cos‚Äô√® la cache di Docker**\n",
    "\n",
    "Docker costruisce un‚Äôimmagine **a layer**: ogni istruzione (`FROM`, `RUN`, `COPY`, ecc.) crea un ‚Äúpezzo‚Äù del filesystem.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "* Se **requirements.txt non cambia**, Docker pu√≤ riutilizzare la cache del layer `RUN pip install`.\n",
    "* Ma se lo modifichi o se `COPY . .` viene prima, **Docker rigenera tutto da zero**.\n",
    "\n",
    " Quindi **l‚Äôordine delle istruzioni conta moltissimo** per la cache.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Best practice per la cache (ordine corretto)**\n",
    "\n",
    "Ordina sempre cos√¨:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "# 1Ô∏è‚É£ Copia SOLO requirements (cambia raramente)\n",
    "COPY requirements.txt .\n",
    "\n",
    "# 2Ô∏è‚É£ Installa dipendenze (caching pip)\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install --upgrade pip \\\n",
    " && pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 3Ô∏è‚É£ Copia il codice del progetto (cambia spesso)\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "* **`COPY requirements.txt .`**: viene eseguito solo se requirements cambia ‚Üí cache efficace.\n",
    "* **`COPY . .`**: viene eseguito dopo ‚Üí evita di invalidare l‚Äôinstallazione pip per ogni piccolo update del codice.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **4. Cos‚Äô√® `.dockerignore` e perch√© √® fondamentale**\n",
    "\n",
    "`.dockerignore` funziona come `.gitignore`:\n",
    "indica a Docker **quali file NON copiare nel contesto di build** (cio√® la directory che Docker invia al demone).\n",
    "\n",
    "Se Docker deve analizzare 5 GB di dati in `data/` o `models/`,\n",
    "li invier√† tutti ogni volta, rallentando la build anche se non servono.\n",
    "\n",
    "### Esempio tipico\n",
    "\n",
    "```\n",
    ".git\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "venv/\n",
    ".env\n",
    ".cache/\n",
    "dist/\n",
    "build/\n",
    "models/\n",
    "data/\n",
    "node_modules/\n",
    "outputs/\n",
    "logs/\n",
    "```\n",
    "\n",
    " *Note per CrewAI*:\n",
    "\n",
    "* **`models/`**: non includere mai modelli HF o checkpoint pesanti ‚Üí montali come volume.\n",
    "* **`data/`**: includila solo se serve nel runtime (dataset statici o demo).\n",
    "* **`.env`**: contiene chiavi API ‚Üí escludilo sempre per sicurezza.\n",
    "* **`__pycache__/`** e `.pyc` ‚Üí inutili.\n",
    "* **`node_modules/`** ‚Üí solo se hai interfaccia React/Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Esempio reale di `.dockerignore` per progetto CrewAI completo**\n",
    "\n",
    "```\n",
    "# File temporanei e di sistema\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    "*.log\n",
    ".DS_Store\n",
    "\n",
    "# Ambienti locali\n",
    "venv/\n",
    ".env\n",
    ".venv/\n",
    ".cache/\n",
    "__pypackages__/\n",
    "\n",
    "# Repositori e build\n",
    ".git\n",
    ".gitignore\n",
    "build/\n",
    "dist/\n",
    "*.egg-info/\n",
    "\n",
    "# Dati pesanti\n",
    "models/\n",
    "data/\n",
    "outputs/\n",
    "logs/\n",
    "*.csv\n",
    "*.zip\n",
    "*.tar.gz\n",
    "\n",
    "# Frontend\n",
    "node_modules/\n",
    "npm-debug.log\n",
    "yarn-error.log\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "```\n",
    "\n",
    " In questo modo Docker copia **solo il codice e i file essenziali**,\n",
    "riducendo drasticamente la dimensione del contesto di build.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Come testare l‚Äôeffetto del `.dockerignore`**\n",
    "\n",
    "Puoi vedere quali file vengono effettivamente inclusi nel contesto:\n",
    "\n",
    "```bash\n",
    "docker build -t crewai-backend .\n",
    "```\n",
    "\n",
    "Durante la build, Docker stampa:\n",
    "\n",
    "```\n",
    "Sending build context to Docker daemon  12.5MB\n",
    "```\n",
    "\n",
    "‚Üí se prima erano 2GB e ora 12MB, `.dockerignore` sta funzionando.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Cache + .dockerignore = performance reale**\n",
    "\n",
    "| Azione                             | Senza ottimizzazione | Con cache + .dockerignore |\n",
    "| ---------------------------------- | -------------------- | ------------------------- |\n",
    "| Prima build                        | 6‚Äì8 minuti           | 6‚Äì8 minuti                |\n",
    "| Rebuild dopo piccolo cambio codice | 6‚Äì8 minuti           | 15‚Äì30 secondi             |\n",
    "| Dimensione immagine                | ~2‚Äì3 GB              | ~800 MB                   |\n",
    "| Contesto inviato a Docker          | >1 GB                | ~10‚Äì20 MB                 |\n",
    "| Rischio di leak `.env`             | alto                 | nullo                     |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Montare cache persistenti per modelli**\n",
    "\n",
    "Per modelli AI pesanti (es. Transformers, Sentence-Embeddings), **non scaricarli ogni volta**.\n",
    "Usa un volume per la cache HuggingFace:\n",
    "\n",
    "```bash\n",
    "docker run -p 8080:8080 \\\n",
    "  -v $PWD/models:/root/.cache/huggingface \\\n",
    "  crewai-backend\n",
    "```\n",
    "\n",
    "Cos√¨:\n",
    "\n",
    "* i modelli vengono scaricati una sola volta;\n",
    "* i container successivi li riutilizzano;\n",
    "* l‚Äôimmagine rimane leggera e veloce da distribuire.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Errori comuni (e come evitarli)**\n",
    "\n",
    "| Errore                      | Causa                                   | Soluzione                     |\n",
    "| --------------------------- | --------------------------------------- | ----------------------------- |\n",
    "| Ogni build reinstalla tutto | `COPY . .` prima del `pip install`      | inverti l‚Äôordine              |\n",
    "| Build lentissima            | contesto enorme (manca `.dockerignore`) | crea `.dockerignore` completo |\n",
    "| Modelli dentro l‚Äôimmagine   | copia di `models/` o `data/`            | usa volume montato            |\n",
    "| `.env` incluso              | non ignorato                            | aggiungilo a `.dockerignore`  |\n",
    "| Cache pip non usata         | mancanza `--mount=type=cache`           | abilita BuildKit              |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. In sintesi**\n",
    "\n",
    "| Obiettivo                           | Soluzione                                        |\n",
    "| ----------------------------------- | ------------------------------------------------ |\n",
    "| Evitare reinstallazioni inutili     | Copia requirements prima del codice              |\n",
    "| Riutilizzare librerie gi√† scaricate | Usa `--mount=type=cache,target=/root/.cache/pip` |\n",
    "| Evitare file inutili nel contesto   | Usa `.dockerignore` completo                     |\n",
    "| Evitare modelli nell‚Äôimmagine       | Monta `~/.cache/huggingface` come volume         |\n",
    "| Build pi√π veloci e pulite           | Struttura Dockerfile con caching consapevole     |\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Prova pratica (5 minuti)**\n",
    "\n",
    "1. Crea un file `Dockerfile` con l‚Äôordine corretto e cache pip.\n",
    "2. Crea `.dockerignore` con le regole sopra.\n",
    "3. Fai due build:\n",
    "\n",
    "   ```bash\n",
    "   docker build -t test-cache .\n",
    "   docker build -t test-cache .\n",
    "   ```\n",
    "4. Osserva i tempi: la seconda build deve essere **istantanea** se non hai modificato `requirements.txt`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5b643-ec31-4455-9560-f04fac43167b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 2.6 ‚Äì Reti per microservizi AI\n",
    "\n",
    "## (FastAPI backend ‚Üî Qdrant ‚Üî Streamlit UI)\n",
    "\n",
    "## 1) Concetto chiave: rete bridge + DNS interno\n",
    "\n",
    "* I container **sulla stessa rete Docker** si vedono per **nome di servizio** (DNS interno).\n",
    "* Non serve conoscere l‚ÄôIP: dal backend puoi chiamare `http://qdrant:6333` invece di `http://172.18.0.3:6333`.\n",
    "* Esporre porte sull‚Äôhost (`-p`) serve solo se **vuoi accedere da fuori** (es. browser).\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Setup ‚Äúa mano‚Äù (senza Compose)\n",
    "\n",
    "### Crea una rete dedicata\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "```\n",
    "\n",
    "### Avvia Qdrant su quella rete\n",
    "\n",
    "```bash\n",
    "docker run -d --name qdrant \\\n",
    "  --network ai_net \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "```\n",
    "\n",
    "### Avvia il backend FastAPI (CrewAI) sulla stessa rete\n",
    "\n",
    "```bash\n",
    "docker run -d --name backend \\\n",
    "  --network ai_net \\\n",
    "  -p 8080:8080 \\\n",
    "  -e QDRANT_HOST=qdrant \\\n",
    "  -e QDRANT_PORT=6333 \\\n",
    "  myorg/crewai-backend:latest\n",
    "```\n",
    "\n",
    "Nel codice (Python):\n",
    "\n",
    "```python\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\n",
    "  host=os.getenv(\"QDRANT_HOST\", \"qdrant\"),\n",
    "  port=int(os.getenv(\"QDRANT_PORT\", 6333))\n",
    ")\n",
    "```\n",
    "\n",
    "### Avvia Streamlit UI collegata al backend\n",
    "\n",
    "```bash\n",
    "docker run -d --name ui \\\n",
    "  --network ai_net \\\n",
    "  -p 8501:8501 \\\n",
    "  -e API_BASE_URL=http://backend:8080 \\\n",
    "  myorg/streamlit-ui:latest\n",
    "```\n",
    "\n",
    "Nella UI:\n",
    "\n",
    "```python\n",
    "import os, requests\n",
    "API = os.getenv(\"API_BASE_URL\", \"http://backend:8080\")\n",
    "resp = requests.get(f\"{API}/health\").json()\n",
    "```\n",
    "\n",
    "> Risultato: i tre container **si risolvono per nome** (qdrant, backend, ui) e parlano tra loro senza dover conoscere IP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86649358-4a17-4451-bcfe-45b56ba5be65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5b7e5a4-c141-4f37-a31a-ce9e87eb7586",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Cosa sono le wheels in Python\n",
    "\n",
    "Una *wheel* (`.whl`) √® un **pacchetto binario precompilato** di una libreria Python.\n",
    "Rappresenta il formato di distribuzione moderno e ottimizzato che `pip` pu√≤ installare direttamente, senza la necessit√† di compilare codice sorgente durante l‚Äôinstallazione.\n",
    "\n",
    "Le wheels sono il successore dei vecchi pacchetti sorgente (`.tar.gz`, chiamati *source distributions* o *sdist*) e permettono di ridurre drasticamente i tempi di installazione.\n",
    "\n",
    "---\n",
    "\n",
    "## Differenza tra wheel e source package\n",
    "\n",
    "Quando si esegue un‚Äôinstallazione con `pip`, ad esempio:\n",
    "\n",
    "```bash\n",
    "pip install numpy\n",
    "```\n",
    "\n",
    "`pip` cerca su PyPI due possibili tipi di pacchetti:\n",
    "\n",
    "1. **Wheel (`.whl`)**\n",
    "   Contiene il codice Python gi√† compilato e pronto per la versione specifica di Python e per il sistema operativo.\n",
    "   L‚Äôinstallazione √® immediata.\n",
    "\n",
    "2. **Source Distribution (`.tar.gz`)**\n",
    "   Contiene solo il sorgente del pacchetto.\n",
    "   Per installarlo, `pip` deve compilare il codice, operazione che richiede la presenza di compilatori e librerie di sistema (ad esempio `gcc`, `build-essential`, `python3-dev`).\n",
    "   √à pi√π lento e pi√π soggetto a errori di compilazione.\n",
    "\n",
    "---\n",
    "\n",
    "## Struttura di una wheel\n",
    "\n",
    "Esempio di nome di file:\n",
    "\n",
    "```\n",
    "torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl\n",
    "```\n",
    "\n",
    "* `torch`: nome del pacchetto\n",
    "* `2.3.0`: versione del pacchetto\n",
    "* `cp311`: compatibilit√† con Python 3.11 (CPython)\n",
    "* `manylinux1_x86_64`: compilato per Linux 64-bit, compatibile con lo standard manylinux\n",
    "\n",
    "---\n",
    "\n",
    "## Perch√© le wheels sono fondamentali nei Dockerfile\n",
    "\n",
    "Durante la costruzione di un‚Äôimmagine Docker (`docker build`), √® preferibile che:\n",
    "\n",
    "1. La build sia veloce.\n",
    "2. Non siano richiesti compilatori o header system-level.\n",
    "3. L‚Äôimmagine finale sia il pi√π leggera possibile.\n",
    "\n",
    "Compilare pacchetti da sorgente (ad esempio PyTorch, Transformers, NumPy) dentro un container √® lento e richiede l‚Äôinstallazione di tool di build.\n",
    "Le *wheels* risolvono questo problema perch√© possono essere precompilate in uno *stage di build* e poi riutilizzate nello *stage di runtime*.\n",
    "\n",
    "---\n",
    "\n",
    "## Esempio pratico con multi-stage build\n",
    "\n",
    "### Stage 1 ‚Äì Builder\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN apt-get update && apt-get install -y build-essential git \\\n",
    " && pip install --upgrade pip wheel \\\n",
    " && pip wheel --no-deps --no-cache-dir -r requirements.txt -w /wheels\n",
    "```\n",
    "\n",
    "Questo comando crea una directory `/wheels` contenente le versioni precompilate di tutte le librerie specificate in `requirements.txt`.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```\n",
    "/wheels/\n",
    "‚îú‚îÄ fastapi-0.110.0-py3-none-any.whl\n",
    "‚îú‚îÄ uvicorn-0.30.0-py3-none-any.whl\n",
    "‚îú‚îÄ numpy-1.26.4-cp311-cp311-manylinux_x86_64.whl\n",
    "‚îî‚îÄ torch-2.3.0-cp311-cp311-manylinux_x86_64.whl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Stage 2 ‚Äì Runtime\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /wheels /wheels\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-index --find-links=/wheels -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\",\"app:app\",\"--host\",\"0.0.0.0\",\"--port\",\"8080\"]\n",
    "```\n",
    "\n",
    "Questo secondo stage:\n",
    "\n",
    "* copia le wheels gi√† compilate dal builder;\n",
    "* installa i pacchetti da quelle wheel senza accedere a PyPI;\n",
    "* non necessita di compilatori o strumenti di sviluppo.\n",
    "\n",
    "Il risultato √® un container finale pi√π leggero, veloce da costruire e pi√π sicuro.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantaggi pratici dell‚Äôuso delle wheels\n",
    "\n",
    "| Aspetto                  | Vantaggio                                               |\n",
    "| ------------------------ | ------------------------------------------------------- |\n",
    "| Velocit√† di build        | Installazione istantanea da pacchetti precompilati      |\n",
    "| Stabilit√†                | Nessuna dipendenza da compilatori o librerie di sistema |\n",
    "| Dimensione dell‚Äôimmagine | Meno tool di build ‚Üí runtime pi√π leggero                |\n",
    "| Sicurezza                | Nessun accesso esterno a PyPI in fase di build          |\n",
    "| Portabilit√†              | Stesse wheels riutilizzabili in ambienti diversi        |\n",
    "\n",
    "---\n",
    "\n",
    "## Come creare manualmente le wheels\n",
    "\n",
    "Puoi generare le wheels per un progetto o per una lista di dipendenze.\n",
    "\n",
    "Per un singolo progetto:\n",
    "\n",
    "```bash\n",
    "python setup.py bdist_wheel\n",
    "```\n",
    "\n",
    "Per tutte le dipendenze di `requirements.txt`:\n",
    "\n",
    "```bash\n",
    "pip wheel -r requirements.txt -w ./wheels\n",
    "```\n",
    "\n",
    "Questo crea la cartella `./wheels` che pu√≤ essere riutilizzata per installazioni offline o rapide.\n",
    "\n",
    "---\n",
    "\n",
    "## Riassunto finale\n",
    "\n",
    "* Una **wheel (.whl)** √® un pacchetto binario precompilato Python.\n",
    "* √à pi√π efficiente e veloce da installare rispetto al pacchetto sorgente.\n",
    "* Nei Dockerfile ‚Äúda produzione‚Äù, le wheels vengono create in uno *stage builder* e poi installate nello *stage runtime*.\n",
    "* Questo approccio riduce drasticamente i tempi di build e rende l‚Äôimmagine pi√π leggera e stabile.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a033dae-b933-40f0-9cf5-fce1d3e26460",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Cos‚Äô√® una ‚Äúbuild in pi√π step‚Äù\n",
    "\n",
    "Normalmente, un Dockerfile descrive **come costruire un‚Äôimmagine**:\n",
    "cio√® un ambiente con tutto ci√≤ che serve per eseguire il tuo programma.\n",
    "\n",
    "Esempio semplice:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Questo funziona, ma c‚Äô√® un problema:\n",
    "tutto quello che serve *durante la build* (come `pip`, compilatori, librerie di sviluppo, git, ecc.) rimane dentro l‚Äôimmagine finale.\n",
    "\n",
    "Quindi l‚Äôimmagine:\n",
    "\n",
    "* √® pi√π **pesante**,\n",
    "* contiene **strumenti non necessari all‚Äôesecuzione**,\n",
    "* pu√≤ avere pi√π **vulnerabilit√†**,\n",
    "* e rallenta la distribuzione.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Cosa si intende per ‚Äúbuild in pi√π step‚Äù\n",
    "\n",
    "Una **multi-stage build** significa dividere la costruzione in **pi√π fasi (step)**, ognuna con un compito specifico.\n",
    "Alla fine, Docker tiene **solo l‚Äôultimo step**, cio√® il risultato ‚Äúpulito‚Äù e pronto a essere eseguito.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* il **primo step** costruisce o prepara qualcosa (es. installa dipendenze, compila codice, genera pacchetti);\n",
    "* il **secondo step** copia solo ci√≤ che serve dal primo;\n",
    "* gli step intermedi vengono scartati (quindi l‚Äôimmagine finale resta leggera).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Esempio concreto\n",
    "\n",
    "Immagina un‚Äôapp Python che ha molte librerie da installare (Transformers, FastAPI, NumPy, ecc.).\n",
    "Alcune di queste hanno componenti C/C++ e richiedono `gcc` per essere compilate.\n",
    "\n",
    "### Soluzione sbagliata (un solo step)\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "```\n",
    "\n",
    "Problema: il compilatore (`build-essential`) e git rimangono nell‚Äôimmagine finale.\n",
    "Risultato: immagine grande e meno sicura.\n",
    "\n",
    "---\n",
    "\n",
    "### Soluzione corretta: multi-stage build\n",
    "\n",
    "```dockerfile\n",
    "# Step 1 - builder\n",
    "FROM python:3.11-slim AS builder\n",
    "WORKDIR /build\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "COPY requirements.txt .\n",
    "RUN pip install --upgrade pip wheel\n",
    "RUN pip wheel --no-deps -r requirements.txt -w /wheels\n",
    "\n",
    "# Step 2 - runtime\n",
    "FROM python:3.11-slim AS runtime\n",
    "WORKDIR /app\n",
    "COPY --from=builder /wheels /wheels\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-index --find-links=/wheels -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "```\n",
    "\n",
    "Vediamolo in parole semplici:\n",
    "\n",
    "1. **Nel primo step (‚Äúbuilder‚Äù)**\n",
    "\n",
    "   * Si installano gli strumenti pesanti (compilatori).\n",
    "   * Si scaricano e si ‚Äúprecompilano‚Äù tutte le librerie in formato `.whl` (wheel).\n",
    "\n",
    "2. **Nel secondo step (‚Äúruntime‚Äù)**\n",
    "\n",
    "   * Si parte da una nuova immagine pulita.\n",
    "   * Si copiano *solo* le wheel precompilate dal primo step.\n",
    "   * Si installano velocemente senza compilare nulla.\n",
    "   * Nessun compilatore o tool extra rimane nell‚Äôimmagine.\n",
    "\n",
    "Alla fine, il risultato √®:\n",
    "\n",
    "* un‚Äôimmagine pi√π leggera,\n",
    "* pi√π veloce da costruire,\n",
    "* pi√π sicura e portabile.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Come funziona tecnicamente\n",
    "\n",
    "Ogni volta che scrivi:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "```\n",
    "\n",
    "Docker crea **uno stage** con il nome ‚Äúbuilder‚Äù.\n",
    "\n",
    "Poi, quando scrivi:\n",
    "\n",
    "```dockerfile\n",
    "COPY --from=builder /wheels /wheels\n",
    "```\n",
    "\n",
    "Docker **copia solo quella cartella** dal builder allo stage successivo.\n",
    "\n",
    "Gli altri file, programmi e tool del builder non vengono copiati:\n",
    "vengono **eliminati completamente** al termine della build.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Vantaggi principali\n",
    "\n",
    "| Aspetto             | Senza multi-stage                | Con multi-stage                          |\n",
    "| ------------------- | -------------------------------- | ---------------------------------------- |\n",
    "| Dimensione immagine | Molto grande                     | Pi√π leggera                              |\n",
    "| Sicurezza           | Contiene tool inutili (gcc, git) | Contiene solo runtime                    |\n",
    "| Tempo di build      | Lento                            | Pi√π veloce (cache pip + precompilazione) |\n",
    "| Pulizia             | Tutto resta nel container        | Solo l‚Äôessenziale viene copiato          |\n",
    "| Deploy              | Pi√π pesante e fragile            | Pi√π stabile e rapido                     |\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Quando usarla\n",
    "\n",
    "Usa una multi-stage build in questi casi:\n",
    "\n",
    "* se l‚Äôapp richiede **librerie complesse o compilate** (es. PyTorch, NumPy);\n",
    "* se vuoi **immagini leggere e sicure**;\n",
    "* se devi **riutilizzare build** in pipeline CI/CD;\n",
    "* se usi **linguaggi con transpiler o build step** (Python, Node.js, Go, ecc.).\n",
    "\n",
    "Nei progetti AI (CrewAI, LangChain, FastAPI, Qdrant), √® sempre consigliata, perch√©:\n",
    "\n",
    "* molte librerie sono pesanti da compilare;\n",
    "* la cache pip migliora molto i tempi di rebuild;\n",
    "* l‚Äôimmagine runtime deve essere il pi√π snella possibile.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Come riconoscere uno ‚Äústep‚Äù\n",
    "\n",
    "Ogni istruzione `FROM ... AS nome` apre un nuovo step.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim AS builder\n",
    "...  # step 1\n",
    "\n",
    "FROM python:3.11-slim AS runtime\n",
    "...  # step 2\n",
    "\n",
    "FROM nginx:alpine AS proxy\n",
    "...  # step 3\n",
    "```\n",
    "\n",
    "Solo **l‚Äôultimo step** diventa l‚Äôimmagine finale.\n",
    "Gli altri vengono usati solo come ‚Äúfasi intermedie‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Controllare gli step\n",
    "\n",
    "Puoi anche fermarti a uno step intermedio per vedere cosa contiene:\n",
    "\n",
    "```bash\n",
    "docker build --target builder -t myapp:builder .\n",
    "docker run -it myapp:builder bash\n",
    "```\n",
    "\n",
    "Serve per il debug o per verificare i file generati (es. le wheel in `/wheels`).\n",
    "\n",
    "---\n",
    "\n",
    "# 9. In sintesi\n",
    "\n",
    "* **Cos‚Äô√®:** un modo per dividere la build in pi√π fasi, ognuna con un compito specifico.\n",
    "* **Perch√©:** per costruire immagini pi√π leggere, sicure e veloci.\n",
    "* **Come:** usando pi√π istruzioni `FROM` e copiando solo ci√≤ che serve dallo stage precedente.\n",
    "* **Risultato:** immagine finale pulita, con solo il codice e le librerie necessarie a eseguire l‚Äôapplicazione.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaba191-ebe3-4617-a850-fe1f3b85edba",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Cos‚Äô√® la cache in Docker\n",
    "\n",
    "Ogni volta che esegui:\n",
    "\n",
    "```bash\n",
    "docker build .\n",
    "```\n",
    "\n",
    "Docker **non ricostruisce tutto da zero**:\n",
    "memorizza (‚Äúcachizza‚Äù) i risultati delle istruzioni del Dockerfile per riutilizzarli in futuro.\n",
    "\n",
    "Ogni **istruzione** nel Dockerfile (`FROM`, `RUN`, `COPY`, ecc.) crea un **layer** nell‚Äôimmagine.\n",
    "Un layer √® come una fotografia dello stato del file system in quel momento.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Qui Docker crea i layer in questo ordine:\n",
    "\n",
    "1. Base image (`FROM`)\n",
    "2. Creazione cartella di lavoro (`WORKDIR`)\n",
    "3. Copia di `requirements.txt`\n",
    "4. Installazione delle dipendenze\n",
    "5. Copia del codice\n",
    "6. Comando finale\n",
    "\n",
    "Se ricostruisci l‚Äôimmagine e **Docker capisce che nulla √® cambiato** fino a un certo punto,\n",
    "riutilizza la cache dei layer precedenti e **ricostruisce solo quello che serve**.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Come Docker decide se usare la cache\n",
    "\n",
    "Docker controlla:\n",
    "\n",
    "* il **contenuto dei file copiati** (`COPY`, `ADD`),\n",
    "* i **comandi eseguiti** (`RUN`),\n",
    "* l‚Äôimmagine base (`FROM`).\n",
    "\n",
    "Se trova una corrispondenza, riutilizza la cache.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* Cambi un file `.py` nel progetto ‚Üí la cache si invalida **solo dopo** il `COPY . .`\n",
    "* Cambi `requirements.txt` ‚Üí la cache si invalida gi√† a met√† build (perch√© cambia la fase `RUN pip install ...`).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Perch√© la cache √® importante\n",
    "\n",
    "Senza cache, ogni build:\n",
    "\n",
    "* reinstallerebbe tutte le librerie da zero,\n",
    "* scaricherebbe ogni pacchetto ogni volta,\n",
    "* sarebbe lentissima.\n",
    "\n",
    "Con una cache corretta:\n",
    "\n",
    "* Docker riusa layer gi√† costruiti,\n",
    "* le dipendenze si installano solo la prima volta,\n",
    "* il tempo di build si riduce da minuti a pochi secondi.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Come sfruttarla in modo efficace\n",
    "\n",
    "L‚Äôordine delle istruzioni nel Dockerfile √® **fondamentale**.\n",
    "Docker costruisce in sequenza, quindi se una riga cambia, **tutti i layer dopo** vengono ricostruiti.\n",
    "\n",
    "### Esempio sbagliato:\n",
    "\n",
    "```dockerfile\n",
    "COPY . .\n",
    "RUN pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "‚Üí ogni volta che modifichi un file Python, anche il `pip install` viene rieseguito.\n",
    "\n",
    "### Esempio corretto:\n",
    "\n",
    "```dockerfile\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "```\n",
    "\n",
    "‚Üí se cambi solo il codice, la parte `pip install` resta in cache.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Cache locale: dove si trova\n",
    "\n",
    "Docker salva la cache sul tuo computer.\n",
    "La puoi vedere con:\n",
    "\n",
    "```bash\n",
    "docker image ls\n",
    "docker system df\n",
    "```\n",
    "\n",
    "Ogni immagine e layer rimane finch√© non lo elimini manualmente con:\n",
    "\n",
    "```bash\n",
    "docker system prune\n",
    "```\n",
    "\n",
    "oppure in modo pi√π mirato:\n",
    "\n",
    "```bash\n",
    "docker builder prune\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Cache dei pacchetti (pip, apt, npm‚Ä¶)\n",
    "\n",
    "C‚Äô√® un secondo tipo di cache: quella interna ai tool di installazione.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* `pip` salva i pacchetti in `~/.cache/pip`\n",
    "* `apt-get` salva i pacchetti in `/var/cache/apt`\n",
    "* `npm` salva i pacchetti in `~/.npm`\n",
    "\n",
    "Normalmente Docker **non conserva** queste cache tra build.\n",
    "Ma possiamo farlo ‚Äî e questo √® ci√≤ che si intende con *cache mount*.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Cache mount (con BuildKit)\n",
    "\n",
    "**BuildKit** √® la versione moderna del sistema di build di Docker.\n",
    "Permette di usare una cache ‚Äútemporanea‚Äù che non gonfia l‚Äôimmagine ma resta tra build successive.\n",
    "\n",
    "Per abilitarlo:\n",
    "\n",
    "```bash\n",
    "export DOCKER_BUILDKIT=1\n",
    "```\n",
    "\n",
    "Poi nel Dockerfile puoi scrivere:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Cos√¨:\n",
    "\n",
    "* la directory `/root/.cache/pip` viene riutilizzata tra build successive,\n",
    "* i pacchetti gi√† scaricati non vengono riscaricati,\n",
    "* ma la cache **non viene copiata dentro l‚Äôimmagine finale**.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Cache nel mondo reale (esempio con Python)\n",
    "\n",
    "Supponiamo di avere questo Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN --mount=type=cache,target=/root/.cache/pip \\\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Cosa succede:\n",
    "\n",
    "1. Al primo build, scarica tutto da zero.\n",
    "2. Al secondo build, se `requirements.txt` non √® cambiato, la cache pip viene riutilizzata ‚Üí molto pi√π veloce.\n",
    "3. Se cambi solo `main.py`, la cache `pip install` rimane valida.\n",
    "\n",
    "---\n",
    "\n",
    "# 9. `.dockerignore`: il primo livello di cache ‚Äúintelligente‚Äù\n",
    "\n",
    "Quando Docker costruisce un‚Äôimmagine, **invia tutto il contenuto della cartella** al daemon Docker.\n",
    "Se dentro ci sono file pesanti (dataset, modelli, `venv`, ecc.),\n",
    "la build diventa pi√π lenta e invalida la cache inutilmente.\n",
    "\n",
    "Crea un file `.dockerignore` per escluderli:\n",
    "\n",
    "```\n",
    ".git\n",
    "__pycache__/\n",
    "venv/\n",
    ".env\n",
    "data/\n",
    "models/\n",
    "```\n",
    "\n",
    "Questo non solo velocizza la build, ma impedisce a Docker di invalidare i layer quando cambiano file irrilevanti.\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Cache su pi√π macchine (CI/CD)\n",
    "\n",
    "Se costruisci l‚Äôimmagine su un server remoto (es. GitHub Actions),\n",
    "puoi ‚Äúspingere‚Äù e ‚Äútirare‚Äù la cache da un registry.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```bash\n",
    "docker buildx build \\\n",
    "  --cache-to=type=inline \\\n",
    "  --cache-from=type=inline \\\n",
    "  -t myimage:latest .\n",
    "```\n",
    "\n",
    "In questo modo, anche la pipeline remota riusa la cache creata in locale.\n",
    "\n",
    "---\n",
    "\n",
    "# 11. Quando la cache non serve (e va disattivata)\n",
    "\n",
    "A volte √® meglio forzare una build ‚Äúpulita‚Äù:\n",
    "\n",
    "```bash\n",
    "docker build --no-cache -t myimage .\n",
    "```\n",
    "\n",
    "Serve quando:\n",
    "\n",
    "* una dipendenza esterna √® cambiata,\n",
    "* un layer √® corrotto,\n",
    "* o vuoi testare il tempo di una build da zero.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. Buone pratiche generali\n",
    "\n",
    "| Cosa fare                                                        | Perch√©                                        |\n",
    "| ---------------------------------------------------------------- | --------------------------------------------- |\n",
    "| Copiare `requirements.txt` prima del codice                      | Mantiene in cache `pip install`               |\n",
    "| Abilitare BuildKit                                               | Usa cache pip e apt tra build                 |\n",
    "| Usare `.dockerignore`                                            | Evita cache invalidata da file inutili        |\n",
    "| Non cancellare cache utile (`docker system prune`) troppo spesso | Rallenta build successive                     |\n",
    "| Usare versioni precise nei requirements                          | Evita invalidazioni casuali                   |\n",
    "| Montare directory cache (`--mount=type=cache`)                   | Evita download ripetuti                       |\n",
    "| Usare multi-stage build                                          | Separa build e runtime, cache pi√π prevedibile |\n",
    "\n",
    "---\n",
    "\n",
    "# 13. Riepilogo visivo\n",
    "\n",
    "| Scenario                           | Cache usata                    | Tempo build  |\n",
    "| ---------------------------------- | ------------------------------ | ------------ |\n",
    "| Primo build                        | Nessuna cache                  | Lento        |\n",
    "| Secondo build, stessi file         | Cache layer Docker + cache pip | Molto veloce |\n",
    "| Modifico requirements.txt          | Cache invalidata da met√† build | Medio        |\n",
    "| Modifico solo codice               | Solo ultimi layer ricostruiti  | Veloce       |\n",
    "| Cache disattivata con `--no-cache` | Nessuna                        | Lento        |\n",
    "\n",
    "---\n",
    "\n",
    "# 14. In breve\n",
    "\n",
    "* **Docker salva i risultati di ogni istruzione come ‚Äúlayer‚Äù**.\n",
    "* **Se i file o i comandi non cambiano**, quei layer vengono riutilizzati.\n",
    "* **L‚Äôordine delle istruzioni** √® la chiave per sfruttare la cache.\n",
    "* **BuildKit** aggiunge una cache ‚Äútemporanea‚Äù per pip, apt e altri gestori di pacchetti.\n",
    "* **.dockerignore** evita di far ricostruire inutilmente i layer.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c1b86-c08e-4548-9447-f3997ebbff05",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Il concetto di ‚Äúroot‚Äù nei container\n",
    "\n",
    "Quando un container Docker viene avviato, **di default** usa l‚Äôutente `root`.\n",
    "\n",
    "Nel mondo Linux, `root` √® l‚Äôamministratore del sistema, quindi pu√≤:\n",
    "\n",
    "* modificare o cancellare qualsiasi file;\n",
    "* installare pacchetti;\n",
    "* eseguire comandi critici;\n",
    "* accedere a tutto il file system.\n",
    "\n",
    "Questo significa che, se un‚Äôapp dentro un container viene compromessa (ad esempio tramite una vulnerabilit√† o una libreria malevola), un utente malintenzionato potrebbe:\n",
    "\n",
    "* ottenere accesso **completo al container**;\n",
    "* e in certi casi anche al **sistema host** (soprattutto se ci sono volumi montati o permessi sbagliati).\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Perch√© evitare l‚Äôutente root\n",
    "\n",
    "In un ambiente di produzione, eseguire i container come root **√® una cattiva pratica** per vari motivi:\n",
    "\n",
    "| Rischio           | Descrizione                                                                         |\n",
    "| ----------------- | ----------------------------------------------------------------------------------- |\n",
    "| **Sicurezza**     | un exploit nel codice pu√≤ compromettere il sistema host                             |\n",
    "| **Isolamento**    | root nel container pu√≤ scrivere in volumi o directory condivise                     |\n",
    "| **Tracciabilit√†** | difficile distinguere le operazioni del container da quelle di sistema              |\n",
    "| **Compliance**    | molti standard di sicurezza (es. OWASP, CIS Docker Benchmark) vietano l‚Äôuso di root |\n",
    "\n",
    "Per questo motivo, √® buona norma **creare un utente dedicato e con permessi limitati** per eseguire l‚Äôapplicazione.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Come si crea un utente non-root nel Dockerfile\n",
    "\n",
    "Il modo pi√π semplice √® usare il comando `useradd` o `adduser` durante la build.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# 1. Crea un utente e una home directory\n",
    "RUN useradd -m -u 10001 appuser\n",
    "\n",
    "# 2. Imposta la cartella di lavoro\n",
    "WORKDIR /app\n",
    "\n",
    "# 3. Copia i file e assegna la propriet√† all‚Äôutente creato\n",
    "COPY . .\n",
    "RUN chown -R appuser:appuser /app\n",
    "\n",
    "# 4. Passa all‚Äôutente non-root\n",
    "USER appuser\n",
    "\n",
    "# 5. Esegui il comando finale\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "Vediamo cosa fa, riga per riga:\n",
    "\n",
    "* `useradd -m -u 10001 appuser`\n",
    "  Crea un utente chiamato `appuser` con ID `10001` (gli ID < 1000 sono solitamente riservati al sistema).\n",
    "\n",
    "* `WORKDIR /app`\n",
    "  Imposta la directory di lavoro del container.\n",
    "\n",
    "* `COPY . .`\n",
    "  Copia i file dell‚Äôapp.\n",
    "\n",
    "* `chown -R appuser:appuser /app`\n",
    "  Cambia il proprietario della cartella `/app`, in modo che l‚Äôutente `appuser` possa leggere/scrivere.\n",
    "\n",
    "* `USER appuser`\n",
    "  Indica a Docker che **tutti i comandi successivi** verranno eseguiti come `appuser`.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Come verificare che il container non sia root\n",
    "\n",
    "Dopo aver creato l‚Äôimmagine, puoi verificarlo con:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm nome_immagine whoami\n",
    "```\n",
    "\n",
    "Output previsto:\n",
    "\n",
    "```\n",
    "appuser\n",
    "```\n",
    "\n",
    "Oppure controllando l‚ÄôID utente:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm nome_immagine id\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "uid=10001(appuser) gid=10001(appuser) groups=10001(appuser)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Esempio reale in un‚Äôapp AI (FastAPI o CrewAI)\n",
    "\n",
    "Ecco un esempio pi√π realistico, che unisce sicurezza e praticit√†:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Installazione dipendenze\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Creazione utente non-root\n",
    "RUN useradd -m -u 10001 appuser\n",
    "\n",
    "# Copia codice e assegna permessi\n",
    "COPY . .\n",
    "RUN chown -R appuser:appuser /app\n",
    "\n",
    "# Passa all‚Äôutente non-root\n",
    "USER appuser\n",
    "\n",
    "# Porta e avvio app\n",
    "EXPOSE 8080\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "```\n",
    "\n",
    "Risultato:\n",
    "\n",
    "* l‚Äôapp gira come `appuser`;\n",
    "* non ha accesso a file di sistema;\n",
    "* anche se venisse compromessa, i danni resterebbero confinati al container.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Buone pratiche aggiuntive\n",
    "\n",
    "### 6.1 Imposta i permessi prima possibile\n",
    "\n",
    "Meglio eseguire `chown` nel builder, cos√¨ la copia nel runtime √® gi√† corretta:\n",
    "\n",
    "```dockerfile\n",
    "COPY --chown=appuser:appuser . .\n",
    "```\n",
    "\n",
    "### 6.2 Non eseguire comandi privilegiati dopo `USER`\n",
    "\n",
    "Dopo `USER appuser`, non puoi pi√π installare pacchetti o modificare file di sistema.\n",
    "Quindi crea l‚Äôutente **alla fine della build**, subito prima del `CMD`.\n",
    "\n",
    "### 6.3 Evita di lavorare nella home root\n",
    "\n",
    "Non salvare log o dati in `/root` o `/tmp` se non servono.\n",
    "Usa `/app`, `/data`, o una directory dedicata con permessi corretti.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Quando serve root (e come gestirlo)\n",
    "\n",
    "In alcuni casi, √® necessario usare root temporaneamente, ad esempio:\n",
    "\n",
    "* per installare pacchetti con `apt-get`;\n",
    "* per compilare estensioni C;\n",
    "* per configurare permessi speciali.\n",
    "\n",
    "Puoi farlo solo negli stage iniziali, e poi tornare non-root nello stage finale.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```dockerfile\n",
    "# Stage 1 (builder)\n",
    "FROM python:3.11-slim AS builder\n",
    "RUN apt-get update && apt-get install -y build-essential git\n",
    "WORKDIR /build\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Stage 2 (runtime)\n",
    "FROM python:3.11-slim\n",
    "RUN useradd -m -u 10001 appuser\n",
    "WORKDIR /app\n",
    "COPY --from=builder /build /app\n",
    "USER appuser\n",
    "CMD [\"python\", \"main.py\"]\n",
    "```\n",
    "\n",
    "In questo modo, il codice viene costruito come root (dove serve),\n",
    "ma **eseguito come utente non-root** nell‚Äôimmagine finale.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Controllare gli utenti attivi nel container\n",
    "\n",
    "Puoi ispezionare l‚Äôimmagine:\n",
    "\n",
    "```bash\n",
    "docker run -it nome_immagine bash\n",
    "cat /etc/passwd\n",
    "```\n",
    "\n",
    "Vedrai un elenco di utenti, tra cui il tuo:\n",
    "\n",
    "```\n",
    "appuser:x:10001:10001::/home/appuser:/bin/bash\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Eseguire container temporaneamente come root\n",
    "\n",
    "Se devi solo ‚Äúentrare‚Äù nel container per debug e non vuoi modificare il Dockerfile:\n",
    "\n",
    "```bash\n",
    "docker run -it --user root nome_immagine bash\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Riepilogo concettuale\n",
    "\n",
    "| Punto chiave           | Spiegazione                                                    |\n",
    "| ---------------------- | -------------------------------------------------------------- |\n",
    "| **Root**               | √à l‚Äôamministratore del sistema, ha accesso a tutto             |\n",
    "| **Problema**           | Se un‚Äôapp viene compromessa, anche l‚Äôhost √® a rischio          |\n",
    "| **Soluzione**          | Creare un utente limitato e passare a lui con `USER`           |\n",
    "| **Posizione corretta** | Dopo aver installato pacchetti e copiato il codice             |\n",
    "| **Beneficio**          | Maggiore sicurezza, isolamento e conformit√† alle best practice |\n",
    "\n",
    "---\n",
    "\n",
    "# 11. In sintesi\n",
    "\n",
    "* Docker, di default, esegue tutto come **root**.\n",
    "* Creare e usare un **utente non-root** √® una pratica essenziale per la sicurezza.\n",
    "* Serve a **limitare i danni** in caso di exploit o errore nel codice.\n",
    "* Si implementa con poche righe (`useradd`, `chown`, `USER`).\n",
    "* Nei progetti AI, dove si usano spesso file, dataset o modelli, riduce il rischio di modifiche indesiderate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550916c-5689-47ce-8348-532e059a415e",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Cos‚Äô√® un Healthcheck\n",
    "\n",
    "Un **healthcheck** √® un meccanismo che permette a Docker di **verificare automaticamente se un container √® ‚Äúsano‚Äù** (cio√® sta funzionando come previsto) oppure no.\n",
    "\n",
    "In pratica, Docker non si limita a vedere se il container ‚Äú√® in esecuzione‚Äù, ma controlla periodicamente se:\n",
    "\n",
    "* il servizio risponde su una porta (es. HTTP 8080);\n",
    "* un processo √® ancora attivo;\n",
    "* o una certa condizione √® vera (es. un file esiste o un comando restituisce `0`).\n",
    "\n",
    "Se il test fallisce, Docker **segnala che il container √® ‚Äúunhealthy‚Äù**.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Perch√© serve\n",
    "\n",
    "Senza un healthcheck, Docker considera il container ‚Äúup‚Äù finch√© il processo principale non termina.\n",
    "Ma in molti casi un‚Äôapp pu√≤ essere ‚Äúin esecuzione‚Äù ma non funzionare (esempio: un server FastAPI crasha internamente ma non chiude il processo).\n",
    "\n",
    "L‚Äôhealthcheck serve per:\n",
    "\n",
    "* far capire a Docker (e a Docker Compose, Kubernetes, Swarm, ecc.) se il container √® effettivamente funzionante;\n",
    "* permettere a sistemi esterni (come Compose o orchestratori) di **riavviare automaticamente** il servizio se non risponde;\n",
    "* sincronizzare la partenza di altri container che dipendono da lui (`depends_on` con `condition: service_healthy`).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Come si definisce nel Dockerfile\n",
    "\n",
    "La sintassi √®:\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK [OPTIONS] CMD comando_da_eseguire || exit 1\n",
    "```\n",
    "\n",
    "Le opzioni principali sono:\n",
    "\n",
    "* `--interval=30s` ‚Üí ogni quanto tempo eseguire il test (default 30s)\n",
    "* `--timeout=3s` ‚Üí tempo massimo per considerare il test riuscito\n",
    "* `--start-period=10s` ‚Üí tempo di ‚Äúgrace‚Äù dopo l‚Äôavvio, prima di iniziare a testare\n",
    "* `--retries=3` ‚Üí quante volte deve fallire prima di marcare ‚Äúunhealthy‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Esempio base: server FastAPI o CrewAI\n",
    "\n",
    "Se il tuo container espone un‚ÄôAPI HTTP (es. `http://localhost:8080/health`):\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\n",
    "  CMD curl -fsS http://localhost:8080/health || exit 1\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* `curl -fsS` tenta una richiesta HTTP silenziosa (fallisce se non riceve risposta);\n",
    "* `|| exit 1` fa fallire l‚Äôhealthcheck se `curl` non riesce a connettersi;\n",
    "* dopo 3 tentativi falliti, Docker segna il container come **unhealthy**.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Esempio con Streamlit o server su porta 8501\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK --interval=20s --timeout=3s --retries=3 \\\n",
    "  CMD wget --spider -q http://localhost:8501/_stcore/health || exit 1\n",
    "```\n",
    "\n",
    "Qui usiamo `wget` invece di `curl`.\n",
    "L‚Äôopzione `--spider -q` fa solo un ‚Äúping‚Äù HTTP senza scaricare il contenuto.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Esempio per container Python senza HTTP (task AI, script, ecc.)\n",
    "\n",
    "Se il container non espone una porta HTTP ma deve eseguire periodicamente un file Python, puoi usare:\n",
    "\n",
    "```dockerfile\n",
    "HEALTHCHECK --interval=1m CMD pgrep -f main.py > /dev/null || exit 1\n",
    "```\n",
    "\n",
    "* `pgrep -f main.py` controlla che il processo Python sia attivo;\n",
    "* se non trova nulla, l‚Äôhealthcheck fallisce.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Comportamento in runtime\n",
    "\n",
    "Puoi verificare lo stato di salute del container con:\n",
    "\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "E troverai una colonna ‚ÄúSTATUS‚Äù come:\n",
    "\n",
    "```\n",
    "Up 2 minutes (healthy)\n",
    "Up 1 minute (starting)\n",
    "Up 3 minutes (unhealthy)\n",
    "```\n",
    "\n",
    "Oppure con:\n",
    "\n",
    "```bash\n",
    "docker inspect nome_container --format='{{json .State.Health}}' | jq\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Come Docker interpreta gli stati\n",
    "\n",
    "| Stato         | Significato                                                              |\n",
    "| ------------- | ------------------------------------------------------------------------ |\n",
    "| **starting**  | Docker ha appena avviato il container, healthcheck non ancora effettuato |\n",
    "| **healthy**   | Il test √® passato                                                        |\n",
    "| **unhealthy** | Il test √® fallito per pi√π volte di seguito                               |\n",
    "| **none**      | Nessun healthcheck definito                                              |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94cd38-6873-4341-9899-598e9ff2b181",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Il problema: i segreti nella build\n",
    "\n",
    "Spesso, durante la costruzione di un‚Äôimmagine Docker, dobbiamo accedere a risorse private, ad esempio:\n",
    "\n",
    "* repository Git privati,\n",
    "* pacchetti Python privati (su un index interno o su Azure),\n",
    "* API key o token temporanei.\n",
    "\n",
    "Molti principianti commettono un errore grave:\n",
    "**scrivono queste credenziali direttamente nel Dockerfile**, ad esempio:\n",
    "\n",
    "```dockerfile\n",
    "RUN pip install --extra-index-url \"https://myuser:mytoken@pypi.example.com/simple\" mypackage\n",
    "```\n",
    "\n",
    "Questo √® pericoloso perch√©:\n",
    "\n",
    "* le credenziali vengono salvate **nei layer dell‚Äôimmagine**;\n",
    "* chiunque scarichi l‚Äôimmagine pu√≤ leggerle con:\n",
    "\n",
    "  ```bash\n",
    "  docker history --no-trunc nome_immagine\n",
    "  ```\n",
    "* anche se cancelli il file o sovrascrivi la variabile, rimane nei layer precedenti (immutabili).\n",
    "\n",
    "---\n",
    "\n",
    "# 2. La soluzione moderna: BuildKit\n",
    "\n",
    "**BuildKit** √® un sistema di build avanzato di Docker, sviluppato da Moby Project, che sostituisce il vecchio builder tradizionale.\n",
    "\n",
    "Offre molte funzionalit√†, tra cui:\n",
    "\n",
    "* parallelizzazione dei layer;\n",
    "* caching pi√π efficiente;\n",
    "* supporto a **mount temporanei** (`--mount=type=cache` e `--mount=type=secret`);\n",
    "* esportazione e importazione di cache tra macchine;\n",
    "* build deterministiche e sicure.\n",
    "\n",
    "Per abilitarlo:\n",
    "\n",
    "```bash\n",
    "export DOCKER_BUILDKIT=1\n",
    "```\n",
    "\n",
    "oppure scrivendo in `/etc/docker/daemon.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"features\": {\n",
    "    \"buildkit\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Come funzionano i segreti in BuildKit\n",
    "\n",
    "L‚Äôidea √® semplice:\n",
    "\n",
    "> invece di scrivere la chiave nel Dockerfile o copiare un file `.env`,\n",
    "> la fornisci **solo in fase di build**, come un file temporaneo accessibile al comando `RUN`.\n",
    "\n",
    "Docker la monta in `/run/secrets/<id>` e poi la rimuove automaticamente al termine di quello specifico step.\n",
    "Non rimane in nessun layer, quindi non √® mai visibile nell‚Äôimmagine finale.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Sintassi\n",
    "\n",
    "Nel Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "RUN --mount=type=secret,id=<nome_id> \\\n",
    "    <comando che usa il segreto>\n",
    "```\n",
    "\n",
    "Durante la build:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build \\\n",
    "  --secret id=<nome_id>,src=<path_al_file> .\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Esempio pratico: chiave Azure per CrewAI\n",
    "\n",
    "Supponiamo che il tuo progetto AI debba scaricare modelli o configurazioni da un‚Äôarea privata di Azure, usando una chiave salvata in:\n",
    "\n",
    "```\n",
    ".secrets/azure_key.txt\n",
    "```\n",
    "\n",
    "Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# syntax=docker/dockerfile:1.7\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "\n",
    "# Usa la chiave solo in fase di build\n",
    "RUN --mount=type=secret,id=azure_key \\\n",
    "    export AZURE_KEY=$(cat /run/secrets/azure_key) \\\n",
    " && python setup.py install\n",
    "```\n",
    "\n",
    "Comando di build:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build \\\n",
    "  --secret id=azure_key,src=.secrets/azure_key.txt \\\n",
    "  -t crewai-secure .\n",
    "```\n",
    "\n",
    "Durante questo comando:\n",
    "\n",
    "* la chiave viene letta solo da `/run/secrets/azure_key`;\n",
    "* √® disponibile solo mentre viene eseguito lo `RUN`;\n",
    "* viene distrutta subito dopo;\n",
    "* non resta nei layer, n√© nei log, n√© nella cache.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Verifica: non appare nella cronologia\n",
    "\n",
    "Dopo la build, se provi:\n",
    "\n",
    "```bash\n",
    "docker history crewai-secure\n",
    "```\n",
    "\n",
    "non vedrai mai la chiave in nessun layer.\n",
    "Questo √® il principale vantaggio rispetto all‚Äôuso di variabili d‚Äôambiente.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Esempio con pi√π segreti\n",
    "\n",
    "Puoi montare pi√π segreti contemporaneamente:\n",
    "\n",
    "```dockerfile\n",
    "RUN --mount=type=secret,id=azure_key \\\n",
    "    --mount=type=secret,id=hf_token \\\n",
    "    export AZURE_KEY=$(cat /run/secrets/azure_key) \\\n",
    "    && export HF_TOKEN=$(cat /run/secrets/hf_token) \\\n",
    "    && python download_model.py\n",
    "```\n",
    "\n",
    "E costruisci cos√¨:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build \\\n",
    "  --secret id=azure_key,src=.secrets/azure_key.txt \\\n",
    "  --secret id=hf_token,src=.secrets/huggingface_token.txt \\\n",
    "  -t ai-secure .\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Esempio con repository Git privato\n",
    "\n",
    "Se il tuo progetto clona un repo privato:\n",
    "\n",
    "```dockerfile\n",
    "RUN --mount=type=ssh git clone git@github.com:myorg/private-repo.git\n",
    "```\n",
    "\n",
    "Build:\n",
    "\n",
    "```bash\n",
    "DOCKER_BUILDKIT=1 docker build --ssh default .\n",
    "```\n",
    "\n",
    "In questo caso, BuildKit usa la tua chiave SSH locale (es. `~/.ssh/id_rsa`) in modo temporaneo e sicuro.\n",
    "Niente finisce nell‚Äôimmagine finale.\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Dove si trovano i file montati\n",
    "\n",
    "All‚Äôinterno dello step di build, i file dei segreti si trovano in:\n",
    "\n",
    "```\n",
    "/run/secrets/<id>\n",
    "```\n",
    "\n",
    "e vengono eliminati automaticamente alla fine di quello specifico `RUN`.\n",
    "Non sono visibili da altri comandi, n√© da altri container.\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Confronto: `--build-arg` vs `--secret`\n",
    "\n",
    "| Metodo                | Sicuro | Persistente nei layer  | Facile da usare   |\n",
    "| --------------------- | ------ | ---------------------- | ----------------- |\n",
    "| `--build-arg`         | ‚ùå No   | ‚úÖ S√¨ (resta nei layer) | ‚úÖ Semplice        |\n",
    "| Variabile `ENV`       | ‚ùå No   | ‚úÖ S√¨                   | ‚úÖ Semplice        |\n",
    "| `--mount=type=secret` | ‚úÖ S√¨   | ‚ùå No                   | üî∏ Serve BuildKit |\n",
    "\n",
    "Conclusione: usa `--secret` per chiavi, token o credenziali sensibili;\n",
    "usa `--build-arg` solo per valori pubblici o non critici.\n",
    "\n",
    "---\n",
    "\n",
    "# 11. Applicazioni pratiche in progetti AI\n",
    "\n",
    "Ecco alcuni casi reali in cui questo approccio √® utile:\n",
    "\n",
    "* **CrewAI o LangChain**: per fornire `AZURE_OPENAI_API_KEY` senza scriverla nel Dockerfile.\n",
    "* **Qdrant o Pinecone privati**: per passare token API in fase di setup o popolamento iniziale.\n",
    "* **HuggingFace**: per scaricare modelli privati (`HF_TOKEN`).\n",
    "* **Repo Git privati**: clonati tramite `--mount=type=ssh`.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. Buone pratiche\n",
    "\n",
    "1. **Mantieni tutti i segreti** in una cartella separata (es. `.secrets/`) esclusa dal `.dockerignore`.\n",
    "2. **Non usare `ARG` o `ENV` per chiavi sensibili.**\n",
    "3. **Usa sempre BuildKit** per i secret mounts.\n",
    "4. **Non scrivere mai i segreti nei log** o nei comandi con `echo`.\n",
    "5. **Dai nomi chiari ai secret id** (`azure_key`, `hf_token`, `pypi_auth`, ecc.).\n",
    "6. **Non copiare i file dei segreti nel container.**\n",
    "7. **Gestisci permessi stretti sui file dei segreti** (es. `chmod 600 .secrets/*`).\n",
    "\n",
    "---\n",
    "\n",
    "# 13. In sintesi\n",
    "\n",
    "| Concetto                | Descrizione                                                                |\n",
    "| ----------------------- | -------------------------------------------------------------------------- |\n",
    "| **Problema**            | Le chiavi scritte nel Dockerfile finiscono nei layer e restano accessibili |\n",
    "| **Soluzione**           | Usare BuildKit con `--mount=type=secret`                                   |\n",
    "| **Percorso temporaneo** | `/run/secrets/<id>`                                                        |\n",
    "| **Sicurezza**           | Il file √® visibile solo durante il comando `RUN`, poi viene rimosso        |\n",
    "| **Uso tipico**          | Token Azure, chiavi API, repo privati, credenziali PyPI                    |\n",
    "| **Vantaggio**           | Nessuna informazione sensibile resta nell‚Äôimmagine finale                  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c66fd-55c0-49ab-9efc-6a91518c3bc9",
   "metadata": {},
   "source": [
    "# **3.1 ‚Äì Introduzione a Docker Compose per AI stacks**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Perch√© esiste Docker Compose**\n",
    "\n",
    "Quando lavori con Docker, ogni container √® **isolato e indipendente**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "* Un container ospita il **backend FastAPI** (CrewAI).\n",
    "* Un altro container ospita **Qdrant**, il database vettoriale.\n",
    "* Un altro ancora la **UI Streamlit**.\n",
    "\n",
    "Con `docker run`, dovresti avviarli tutti **a mano**, collegarli a una **rete**, assegnare **porte**, gestire **volumi**, variabili, dipendenze, e ricordarti tutti i parametri ogni volta.\n",
    "\n",
    "Esempio di quanto diventa scomodo:\n",
    "\n",
    "```bash\n",
    "docker network create ai_net\n",
    "\n",
    "docker run -d --name qdrant \\\n",
    "  --network ai_net \\\n",
    "  -p 6333:6333 \\\n",
    "  -v qdrant_data:/qdrant/storage \\\n",
    "  qdrant/qdrant:v1.10.0\n",
    "\n",
    "docker run -d --name backend \\\n",
    "  --network ai_net \\\n",
    "  -p 8080:8080 \\\n",
    "  -e QDRANT_HOST=qdrant \\\n",
    "  -e QDRANT_PORT=6333 \\\n",
    "  myorg/crewai-backend:latest\n",
    "\n",
    "docker run -d --name ui \\\n",
    "  --network ai_net \\\n",
    "  -p 8501:8501 \\\n",
    "  -e API_BASE_URL=http://backend:8080 \\\n",
    "  myorg/streamlit-ui:latest\n",
    "```\n",
    "\n",
    "Funziona, ma √® **lungo, fragile e ripetitivo**.\n",
    "Serve un modo per **descrivere tutto questo in un solo file**, leggibile e versionabile.\n",
    "Quel file √® **`docker-compose.yml`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cos‚Äô√® Docker Compose**\n",
    "\n",
    "Docker Compose √® uno **strumento di orchestrazione locale**.\n",
    "Serve per **definire e gestire pi√π container come un‚Äôunica applicazione**.\n",
    "\n",
    "In pratica:\n",
    "\n",
    "* Scrivi **tutta la configurazione** (immagini, porte, variabili, volumi, reti, dipendenze)\n",
    "* in un file YAML chiamato `docker-compose.yml`\n",
    "* e poi avvii tutto con **un solo comando**:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Docker Compose:\n",
    "\n",
    "1. Crea automaticamente la rete interna tra i servizi.\n",
    "2. Crea i volumi definiti nel file.\n",
    "3. Costruisce le immagini se hai indicato `build:`.\n",
    "4. Lancia i container nell‚Äôordine giusto (`depends_on`).\n",
    "5. Permette di spegnere tutto con un solo `docker compose down`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Struttura logica di un file `docker-compose.yml`**\n",
    "\n",
    "Un file Compose segue questa **struttura ad albero**:\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"       # (opzionale)\n",
    "services:            # i container dell'applicazione\n",
    "  <nome_servizio>:\n",
    "    image: ...       # oppure build: ...\n",
    "    ports:\n",
    "    environment:\n",
    "    volumes:\n",
    "    depends_on:\n",
    "volumes:              # volumi persistenti\n",
    "networks:             # (opzionale) reti personalizzate\n",
    "```\n",
    "\n",
    "Ogni **servizio** rappresenta un container.\n",
    "Ogni container pu√≤ avere:\n",
    "\n",
    "* variabili d‚Äôambiente,\n",
    "* porte esposte,\n",
    "* volumi da montare,\n",
    "* dipendenze da altri servizi.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Esempio reale per uno stack AI**\n",
    "\n",
    "Immagina di avere un progetto con:\n",
    "\n",
    "* **CrewAI backend** (FastAPI),\n",
    "* **Qdrant** (vector DB),\n",
    "* **Streamlit UI**.\n",
    "\n",
    "Ecco come lo descriveresti:\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    ports:\n",
    "      - \"6333:6333\"\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "      interval: 10s\n",
    "      timeout: 3s\n",
    "      retries: 5\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    environment:\n",
    "      - QDRANT_HOST=qdrant\n",
    "      - QDRANT_PORT=6333\n",
    "    volumes:\n",
    "      - ./config:/app/config:ro\n",
    "      - ./models:/root/.cache/huggingface\n",
    "    depends_on:\n",
    "      qdrant:\n",
    "        condition: service_healthy\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    environment:\n",
    "      - API_BASE_URL=http://backend:8080\n",
    "    depends_on:\n",
    "      - backend\n",
    "\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Spiegazione riga per riga**\n",
    "\n",
    "### üîπ `version: \"3.9\"`\n",
    "\n",
    "Serve per indicare la versione dello schema Compose.\n",
    "Nelle versioni recenti √® **opzionale**: Compose la riconosce automaticamente.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `services:`\n",
    "\n",
    "√à la sezione principale.\n",
    "Ogni chiave al suo interno rappresenta un container (un servizio indipendente).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `qdrant:`\n",
    "\n",
    "Il nome del servizio.\n",
    "Diventa anche **hostname interno**: il backend potr√† connettersi a `http://qdrant:6333`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `image: qdrant/qdrant:v1.10.0`\n",
    "\n",
    "Specifica quale immagine Docker usare.\n",
    "Pu√≤ essere una:\n",
    "\n",
    "* immagine pubblica (`python:3.11`, `qdrant/qdrant`)\n",
    "* immagine privata (`myorg/backend:latest`)\n",
    "* o una da costruire localmente con `build:`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `build: ./backend`\n",
    "\n",
    "Indica che Compose deve costruire l‚Äôimmagine a partire dal Dockerfile nella cartella `backend/`.\n",
    "\n",
    "Se hai gi√† pubblicato la tua immagine (es. su Docker Hub o un registry interno), puoi usare:\n",
    "\n",
    "```yaml\n",
    "image: myorg/crewai-backend:1.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `ports:`\n",
    "\n",
    "Serve per **mappare** le porte del container verso l‚Äôhost.\n",
    "\n",
    "```yaml\n",
    "ports:\n",
    "  - \"8080:8080\"  # (host:container)\n",
    "```\n",
    "\n",
    "Esempio:\n",
    "`localhost:8080` ‚Üí porta 8080 dentro il container backend.\n",
    "Puoi aprire la tua UI su `localhost:8501` o le API su `localhost:8080`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `environment:`\n",
    "\n",
    "Definisce variabili d‚Äôambiente dentro il container.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "environment:\n",
    "  - QDRANT_HOST=qdrant\n",
    "  - QDRANT_PORT=6333\n",
    "```\n",
    "\n",
    "Nel codice Python:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.getenv(\"QDRANT_HOST\")  # => \"qdrant\"\n",
    "```\n",
    "\n",
    "Puoi anche leggerle da un file `.env` esterno (Compose lo supporta nativamente).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `volumes:`\n",
    "\n",
    "Serve per **montare directory persistenti** o **cartelle locali** nel container.\n",
    "\n",
    "Tipi di volume:\n",
    "\n",
    "* **Bind mount**: collega una cartella locale.\n",
    "\n",
    "  ```yaml\n",
    "  - ./config:/app/config:ro\n",
    "  ```\n",
    "\n",
    "  ‚Üí leggi i file YAML di CrewAI dal tuo computer (solo lettura).\n",
    "\n",
    "* **Volume gestito da Docker**:\n",
    "\n",
    "  ```yaml\n",
    "  - qdrant_data:/qdrant/storage\n",
    "  ```\n",
    "\n",
    "  ‚Üí storage persistente mantenuto da Docker (non sparisce a ogni `down`).\n",
    "\n",
    "La sezione finale:\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "crea il volume se non esiste.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `depends_on:`\n",
    "\n",
    "Definisce le **dipendenze di avvio**.\n",
    "Docker avvia prima i servizi da cui dipendi.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "depends_on:\n",
    "  qdrant:\n",
    "    condition: service_healthy\n",
    "```\n",
    "\n",
    "‚Üí il backend parte **solo quando Qdrant risponde al suo healthcheck**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `healthcheck:`\n",
    "\n",
    "Serve per dire a Docker come verificare che un servizio sia ‚Äúvivo‚Äù.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "healthcheck:\n",
    "  test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:6333/healthz\"]\n",
    "  interval: 10s\n",
    "  timeout: 3s\n",
    "  retries: 5\n",
    "```\n",
    "\n",
    "Docker controlla Qdrant ogni 10 secondi e aggiorna il suo stato interno (healthy/unhealthy).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `volumes:` (sezione finale)\n",
    "\n",
    "Qui definisci **tutti i volumi gestiti da Docker**.\n",
    "Ogni voce √® un volume persistente.\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "Serve per mantenere i dati anche dopo un `docker compose down`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Come funziona la rete in Compose**\n",
    "\n",
    "Compose crea automaticamente **una rete privata** per tutti i servizi del file.\n",
    "I container si vedono per **nome del servizio**, come se fosse un DNS.\n",
    "\n",
    "| Servizio | Nome DNS interno | Porta interna |\n",
    "| -------- | ---------------- | ------------- |\n",
    "| qdrant   | `qdrant`         | 6333          |\n",
    "| backend  | `backend`        | 8080          |\n",
    "| ui       | `ui`             | 8501          |\n",
    "\n",
    "Quindi nel backend puoi scrivere:\n",
    "\n",
    "```python\n",
    "client = QdrantClient(host=\"qdrant\", port=6333)\n",
    "```\n",
    "\n",
    "e non serve l‚ÄôIP.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Comandi principali**\n",
    "\n",
    "| Comando                            | Descrizione                         |\n",
    "| ---------------------------------- | ----------------------------------- |\n",
    "| `docker compose up -d`             | avvia tutti i servizi in background |\n",
    "| `docker compose ps`                | mostra i container attivi           |\n",
    "| `docker compose logs -f backend`   | visualizza i log del backend        |\n",
    "| `docker compose exec backend bash` | entra nel container backend         |\n",
    "| `docker compose down`              | ferma e rimuove tutto               |\n",
    "| `docker compose build backend`     | ricostruisce solo il backend        |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Benefici concreti per progetti AI**\n",
    "\n",
    "| Problema                      | Soluzione con Compose                           |\n",
    "| ----------------------------- | ----------------------------------------------- |\n",
    "| Setup manuale lungo           | Un solo comando `docker compose up`             |\n",
    "| Gestione reti e nomi          | DNS interno automatico (`backend`, `qdrant`)    |\n",
    "| Dati persi a ogni restart     | Volumi persistenti gestiti                      |\n",
    "| Avvio non sincronizzato       | `depends_on` + `healthcheck`                    |\n",
    "| Ambiente locale riproducibile | Tutto descritto in YAML, condivisibile nel repo |\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Esercizio pratico**\n",
    "\n",
    "1. Crea la struttura:\n",
    "\n",
    "   ```\n",
    "   project/\n",
    "   ‚îú‚îÄ backend/ (con Dockerfile e app.py)\n",
    "   ‚îú‚îÄ ui/ (Streamlit)\n",
    "   ‚îú‚îÄ docker-compose.yml\n",
    "   ‚îî‚îÄ config/\n",
    "   ```\n",
    "2. Copia il file Compose di esempio.\n",
    "3. Avvia:\n",
    "\n",
    "   ```bash\n",
    "   docker compose up -d\n",
    "   ```\n",
    "4. Apri la UI su `localhost:8501` e verifica che si connetta al backend (che parla con Qdrant).\n",
    "\n",
    "---\n",
    "\n",
    "## **10. In sintesi**\n",
    "\n",
    "* Docker Compose √® il **collante** dei container.\n",
    "* Descrive tutto in un unico file: servizi, reti, volumi, porte, variabili.\n",
    "* Ti permette di **avviare uno stack AI completo con un solo comando**.\n",
    "* √à lo standard per orchestrare ambienti **CrewAI + Qdrant + UI** in locale o in CI/CD.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc9eed-7d77-4ecf-b5ec-93e7b05a9bc1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **1. File di override (`docker-compose.override.yml`)**\n",
    "\n",
    "### **A cosa serve**\n",
    "\n",
    "Quando usi Docker Compose, il file principale √®:\n",
    "\n",
    "```\n",
    "docker-compose.yml\n",
    "```\n",
    "\n",
    "Ma puoi aggiungere un secondo file:\n",
    "\n",
    "```\n",
    "docker-compose.override.yml\n",
    "```\n",
    "\n",
    "che **modifica o aggiunge** impostazioni solo per l‚Äôambiente di sviluppo.\n",
    "\n",
    "Docker Compose lo riconosce **automaticamente**: non serve specificarlo.\n",
    "Quando lanci:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Compose unisce i due file:\n",
    "\n",
    "```\n",
    "docker-compose.yml  +  docker-compose.override.yml\n",
    "```\n",
    "\n",
    "e crea una configurazione unica.\n",
    "\n",
    "---\n",
    "\n",
    "### **Perch√© si usa**\n",
    "\n",
    "Perch√© ti permette di:\n",
    "\n",
    "* **mantenere il file principale pulito e stabile** (per la produzione),\n",
    "* e mettere le **modifiche temporanee o locali** (come hot-reload, porte extra, mount del codice) solo nel file di override.\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio**\n",
    "\n",
    "**docker-compose.yml (base)**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "```\n",
    "\n",
    "**docker-compose.override.yml (solo in dev)**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    volumes:\n",
    "      - ./backend:/app\n",
    "    environment:\n",
    "      - DEBUG=True\n",
    "    command: uvicorn main:app --reload --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "Cosa succede:\n",
    "\n",
    "* In produzione (`docker compose -f docker-compose.yml up`) ‚Üí parte senza reload, come un‚Äôimmagine stabile.\n",
    "* In sviluppo (`docker compose up`) ‚Üí viene aggiunto il mount locale e il reload automatico.\n",
    "\n",
    "---\n",
    "\n",
    "### **Regola base**\n",
    "\n",
    "* Se un campo √® un **valore singolo** (es. una stringa), l‚Äôoverride lo **sostituisce**.\n",
    "* Se √® una **mappa** (es. `environment`), viene **fuso**.\n",
    "* Se √® una **lista** (es. `ports`), l‚Äôoverride **la rimpiazza completamente**.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "# base\n",
    "ports:\n",
    "  - \"8080:8080\"\n",
    "\n",
    "# override\n",
    "ports:\n",
    "  - \"8090:8080\"   # la lista cambia interamente\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Profili (`profiles:`)**\n",
    "\n",
    "### **A cosa servono**\n",
    "\n",
    "I profili permettono di **attivare o disattivare certi servizi** nel file Compose.\n",
    "Questo √® molto utile quando vuoi che **alcuni container partano solo in certi casi**, per esempio:\n",
    "\n",
    "* la UI Streamlit solo in dev;\n",
    "* il monitoring solo in test;\n",
    "* o un job una tantum solo su richiesta.\n",
    "\n",
    "---\n",
    "\n",
    "### **Come funziona**\n",
    "\n",
    "Ogni servizio pu√≤ dichiarare uno o pi√π profili:\n",
    "\n",
    "```yaml\n",
    "profiles: [\"nome_del_profilo\"]\n",
    "```\n",
    "\n",
    "Se non attivi quel profilo, **il servizio non parte**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    profiles: [\"ui\"]\n",
    "```\n",
    "\n",
    "Se avvii:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "‚Üí partono **solo `qdrant` e `backend`** (perch√© non hanno profili).\n",
    "\n",
    "Se avvii:\n",
    "\n",
    "```bash\n",
    "docker compose --profile ui up -d\n",
    "```\n",
    "\n",
    "‚Üí parte anche la **UI** (perch√© hai attivato il profilo `ui`).\n",
    "\n",
    "Puoi anche attivare pi√π profili insieme:\n",
    "\n",
    "```bash\n",
    "docker compose --profile ui --profile gpu up -d\n",
    "```\n",
    "\n",
    "oppure:\n",
    "\n",
    "```bash\n",
    "COMPOSE_PROFILES=ui,gpu docker compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Esempio pratico completo**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    profiles: [\"ui\"]      # parte solo se attivo il profilo ui\n",
    "\n",
    "  monitoring:\n",
    "    image: grafana/grafana:latest\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    profiles: [\"ops\"]     # parte solo se attivo il profilo ops\n",
    "```\n",
    "\n",
    "Comandi:\n",
    "\n",
    "```bash\n",
    "# solo backend e qdrant\n",
    "docker compose up -d\n",
    "\n",
    "# aggiungi la UI\n",
    "docker compose --profile ui up -d\n",
    "\n",
    "# avvia tutto (anche grafana)\n",
    "docker compose --profile ui --profile ops up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Come usarli insieme (override + profili)**\n",
    "\n",
    "Puoi usare **entrambi**:\n",
    "\n",
    "* `override.yml` ‚Üí per cambiare configurazioni in locale;\n",
    "* `profiles` ‚Üí per decidere *quali* servizi avviare.\n",
    "\n",
    "Esempio pratico in un progetto AI:\n",
    "\n",
    "**docker-compose.yml**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports: [\"8080:8080\"]\n",
    "\n",
    "  ui:\n",
    "    build: ./ui\n",
    "    ports: [\"8501:8501\"]\n",
    "    profiles: [\"ui\"]\n",
    "```\n",
    "\n",
    "**docker-compose.override.yml**\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  backend:\n",
    "    volumes:\n",
    "      - ./backend:/app\n",
    "    command: uvicorn main:app --reload --host 0.0.0.0 --port 8080\n",
    "```\n",
    "\n",
    "Ora:\n",
    "\n",
    "* In produzione ‚Üí usi solo il file principale (senza override, senza profilo UI).\n",
    "* In sviluppo ‚Üí `docker compose --profile ui up -d` (e hai sia l‚ÄôUI sia il reload del backend).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. In sintesi**\n",
    "\n",
    "| Funzione          | Serve a                             | Attivazione                      | Esempio                            |\n",
    "| ----------------- | ----------------------------------- | -------------------------------- | ---------------------------------- |\n",
    "| **Override file** | Modificare configurazioni in locale | Automatico (`docker compose up`) | Aggiungere volumi, reload, log     |\n",
    "| **Profili**       | Accendere/spegnere servizi interi   | Manuale (`--profile`)            | Attivare la UI, GPU o monitoraggio |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c60289-9ed6-4f59-ba96-e323aab3db89",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1. Cos‚Äô√® Kubernetes**\n",
    "\n",
    "Kubernetes ‚Äî abbreviato **K8s** ‚Äî √® una **piattaforma di orchestrazione di container**.\n",
    "In parole semplici, serve a **gestire e coordinare molti container Docker** (o di altri runtime) in modo automatico, sicuro e scalabile.\n",
    "\n",
    "> Docker ti fa ‚Äúcorrere‚Äù i container.\n",
    "> Kubernetes ti permette di ‚Äúorganizzare‚Äù centinaia di container insieme.\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Il problema che risolve**\n",
    "\n",
    "Con Docker singolo o Docker Compose puoi:\n",
    "\n",
    "* avviare pi√π container (API, DB, UI, ecc.),\n",
    "* connetterli in rete,\n",
    "* usare volumi.\n",
    "\n",
    "Ma se vuoi andare in **produzione su un cluster di server**, e avere:\n",
    "\n",
    "* **scalabilit√†** (pi√π copie dello stesso servizio),\n",
    "* **auto-ripartenza automatica** se un container si blocca,\n",
    "* **load balancing** tra istanze multiple,\n",
    "* **aggiornamenti senza downtime (rolling updates)**,\n",
    "* **gestione risorse e limiti CPU/RAM**,\n",
    "  Docker da solo non basta.\n",
    "\n",
    "Qui entra in gioco Kubernetes.\n",
    "\n",
    "---\n",
    "\n",
    "# **3. Cosa fa Kubernetes in pratica**\n",
    "\n",
    "Kubernetes gestisce:\n",
    "\n",
    "1. **Il deployment** ‚Üí fa partire i container (pod) e li mantiene attivi.\n",
    "2. **Lo scaling** ‚Üí aumenta o riduce automaticamente il numero di copie.\n",
    "3. **Il networking** ‚Üí fa comunicare i container tra loro in modo sicuro.\n",
    "4. **Il bilanciamento del carico** ‚Üí distribuisce le richieste fra i pod.\n",
    "5. **Lo storage** ‚Üí collega volumi persistenti ai container.\n",
    "6. **La configurazione** ‚Üí passa variabili e segreti ai container.\n",
    "7. **L‚Äôautoguarigione** ‚Üí se un container crasha, Kubernetes lo ricrea.\n",
    "\n",
    "---\n",
    "\n",
    "# **4. Architettura base di Kubernetes**\n",
    "\n",
    "Immagina un **cluster Kubernetes** come un piccolo ‚Äúsistema operativo distribuito‚Äù:\n",
    "\n",
    "* un **Master Node** (controlla tutto),\n",
    "* uno o pi√π **Worker Node** (eseguono i container).\n",
    "\n",
    "Ogni worker node esegue:\n",
    "\n",
    "* **Pod** ‚Üí l‚Äôunit√† base, contiene uno o pi√π container;\n",
    "* **Kubelet** ‚Üí un agente che riceve ordini dal master;\n",
    "* **Kube Proxy** ‚Üí gestisce la rete dei container.\n",
    "\n",
    "---\n",
    "\n",
    "## **Componenti principali**\n",
    "\n",
    "| Concetto                      | Cosa fa                                               | Analogia                                |\n",
    "| ----------------------------- | ----------------------------------------------------- | --------------------------------------- |\n",
    "| **Pod**                       | Il contenitore logico che ospita uno o pi√π container  | Un singolo ‚Äúservizio in esecuzione‚Äù     |\n",
    "| **Deployment**                | Definisce *quanti* pod vogliamo e come gestirli       | Un ‚Äúsupervisore‚Äù che li mantiene attivi |\n",
    "| **Service**                   | Espone un gruppo di pod su una rete interna o esterna | Come il `ports:` di Docker              |\n",
    "| **Ingress**                   | Gestisce accessi HTTP esterni al cluster              | Come un reverse proxy Nginx             |\n",
    "| **ConfigMap / Secret**        | Memorizza configurazioni e chiavi                     | Come `.env` o variabili Compose         |\n",
    "| **Volume / PersistentVolume** | Gestisce file o storage persistenti                   | Come i volumi Docker                    |\n",
    "\n",
    "---\n",
    "\n",
    "# **5. Esempio semplice (AI-ready)**\n",
    "\n",
    "Immagina uno stack come:\n",
    "\n",
    "* un backend **FastAPI (CrewAI)**;\n",
    "* un database **Qdrant**;\n",
    "* una UI **Streamlit**.\n",
    "\n",
    "In Docker Compose sarebbe un unico file con 3 servizi.\n",
    "In Kubernetes, ciascun servizio diventa una **coppia di risorse**:\n",
    "\n",
    "| Servizio       | Deployment                | Service                |\n",
    "| -------------- | ------------------------- | ---------------------- |\n",
    "| CrewAI Backend | `backend-deployment.yaml` | `backend-service.yaml` |\n",
    "| Qdrant         | `qdrant-deployment.yaml`  | `qdrant-service.yaml`  |\n",
    "| Streamlit UI   | `ui-deployment.yaml`      | `ui-service.yaml`      |\n",
    "\n",
    "Ogni Deployment crea i **pod** (cio√® i container attivi).\n",
    "Ogni Service permette agli altri di raggiungerli in rete.\n",
    "\n",
    "---\n",
    "\n",
    "# **6. Un esempio concreto**\n",
    "\n",
    "### `backend-deployment.yaml`\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/crewai-backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "```\n",
    "\n",
    "### `backend-service.yaml`\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  type: ClusterIP\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 8080\n",
    "```\n",
    "\n",
    "Qui:\n",
    "\n",
    "* Kubernetes avvia **2 pod** del backend.\n",
    "* Il **Service** `backend` permette ad altri container (es. Qdrant, UI) di comunicare con lui su `backend:8080`.\n",
    "\n",
    "---\n",
    "\n",
    "# **7. Come si interagisce con Kubernetes**\n",
    "\n",
    "Una volta installato (in cloud o in locale con Minikube o Kind), si usa il comando:\n",
    "\n",
    "```bash\n",
    "kubectl\n",
    "```\n",
    "\n",
    "Esempi pratici:\n",
    "\n",
    "| Comando                                    | Cosa fa                       |\n",
    "| ------------------------------------------ | ----------------------------- |\n",
    "| `kubectl apply -f backend-deployment.yaml` | crea o aggiorna un deployment |\n",
    "| `kubectl get pods`                         | mostra i container attivi     |\n",
    "| `kubectl logs nome-pod`                    | visualizza i log              |\n",
    "| `kubectl delete -f file.yaml`              | rimuove una risorsa           |\n",
    "| `kubectl describe pod nome-pod`            | mostra dettagli di un pod     |\n",
    "\n",
    "---\n",
    "\n",
    "# **8. Come provare Kubernetes in locale**\n",
    "\n",
    "Per imparare e testare:\n",
    "\n",
    "### Opzione 1: **Minikube**\n",
    "\n",
    "Kubernetes locale su un solo computer:\n",
    "\n",
    "```bash\n",
    "minikube start\n",
    "kubectl get nodes\n",
    "```\n",
    "\n",
    "### Opzione 2: **Kind**\n",
    "\n",
    "Cluster Kubernetes dentro Docker:\n",
    "\n",
    "```bash\n",
    "kind create cluster\n",
    "```\n",
    "\n",
    "Entrambi creano un ‚Äúmini cluster‚Äù dove puoi provare i tuoi deployment.\n",
    "\n",
    "---\n",
    "\n",
    "# **9. Kubernetes e Docker Compose: differenze in sintesi**\n",
    "\n",
    "| Funzione              | Docker Compose          | Kubernetes                                         |\n",
    "| --------------------- | ----------------------- | -------------------------------------------------- |\n",
    "| **Scopo**             | Orchestrazione locale   | Orchestrazione distribuita                         |\n",
    "| **File**              | `docker-compose.yml`    | File YAML separati (`Deployment`, `Service`, ecc.) |\n",
    "| **Avvio**             | `docker compose up`     | `kubectl apply -f .`                               |\n",
    "| **Networking**        | rete privata automatica | rete interna + Service DNS                         |\n",
    "| **Scalabilit√†**       | manuale                 | automatica (`replicas:` o autoscaler)              |\n",
    "| **Tolleranza errore** | limitata                | auto-ripartenza e healthcheck                      |\n",
    "| **Uso tipico**        | sviluppo                | produzione e cloud                                 |\n",
    "\n",
    "---\n",
    "\n",
    "# **10. Kubernetes nel mondo AI**\n",
    "\n",
    "Kubernetes √® molto usato per orchestrare pipeline AI perch√©:\n",
    "\n",
    "* pu√≤ **gestire modelli in container separati** (es. inference server, retriever, database);\n",
    "* permette **autoscaling in base al carico** (es. pi√π istanze del modello se arrivano pi√π richieste);\n",
    "* pu√≤ integrare **GPU e volumi persistenti** per dataset e modelli;\n",
    "* consente di aggiornare un modello o un microservizio **senza downtime**.\n",
    "\n",
    "Esempio tipico:\n",
    "\n",
    "* 1 Pod: Qdrant (vector DB)\n",
    "* 1 Pod: CrewAI backend (FastAPI)\n",
    "* 1 Pod: Streamlit UI\n",
    "* 1 Pod: Worker (inference GPU)\n",
    "* 1 Pod: CronJob per update dataset\n",
    "\n",
    "Tutto orchestrato, scalabile e con auto-restart.\n",
    "\n",
    "---\n",
    "\n",
    "# **11. Dove gira Kubernetes**\n",
    "\n",
    "Puoi usarlo:\n",
    "\n",
    "* **in locale** (Minikube, Kind, Rancher Desktop)\n",
    "* **su cloud**:\n",
    "\n",
    "  * Google Kubernetes Engine (GKE)\n",
    "  * Azure Kubernetes Service (AKS)\n",
    "  * Amazon EKS\n",
    "* oppure **in ibrido** (cluster aziendali o su server dedicati).\n",
    "\n",
    "---\n",
    "\n",
    "# **12. In sintesi**\n",
    "\n",
    "| Concetto            | Significato                                               |\n",
    "| ------------------- | --------------------------------------------------------- |\n",
    "| **Kubernetes**      | sistema che gestisce e coordina container su pi√π macchine |\n",
    "| **Pod**             | unit√† minima: 1 o pi√π container                           |\n",
    "| **Deployment**      | controlla quanti pod devono essere in esecuzione          |\n",
    "| **Service**         | permette ai pod di comunicare                             |\n",
    "| **Ingress**         | apre l‚Äôaccesso esterno                                    |\n",
    "| **kubectl**         | il comando per interagire con il cluster                  |\n",
    "| **Minikube / Kind** | strumenti per provarlo in locale                          |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab052d1-edcc-41cd-9a47-d195f10b8a15",
   "metadata": {},
   "source": [
    "## 1. Cosa fa Kubernetes in pratica\n",
    "\n",
    "Kubernetes √® un sistema che gestisce pi√π container in modo coordinato.\n",
    "Non esegue direttamente i container (quello lo fa Docker o un container runtime), ma li controlla: decide **quanti** devono esserci, **dove** devono girare e **come** devono comunicare.\n",
    "\n",
    "Quando vuoi creare un'applicazione, in Kubernetes non scrivi comandi da terminale come in Docker (`docker run ...`), ma scrivi **file YAML** che descrivono cosa vuoi ottenere.\n",
    "Ogni file YAML rappresenta una risorsa, e Kubernetes si occupa di \"raggiungere\" quello stato.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Il ruolo dei file YAML\n",
    "\n",
    "Ogni file YAML ha sempre la stessa struttura di base:\n",
    "\n",
    "```yaml\n",
    "apiVersion: <versione API>\n",
    "kind: <tipo di risorsa>\n",
    "metadata:\n",
    "  name: <nome risorsa>\n",
    "spec:\n",
    "  ...specifiche della risorsa...\n",
    "```\n",
    "\n",
    "Esempi di risorse:\n",
    "\n",
    "* `Pod` ‚Üí un container o gruppo di container\n",
    "* `Deployment` ‚Üí un gruppo di pod gestiti automaticamente\n",
    "* `Service` ‚Üí il collegamento di rete tra i pod o verso l‚Äôesterno\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Il Pod: la base di tutto\n",
    "\n",
    "Un **Pod** √® l‚Äôunit√† minima di esecuzione in Kubernetes.\n",
    "Dentro un pod pu√≤ esserci uno o pi√π container, ma nella maggior parte dei casi ne ha uno solo.\n",
    "\n",
    "Esempio pratico di pod:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: simple-pod\n",
    "spec:\n",
    "  containers:\n",
    "    - name: web\n",
    "      image: nginx:latest\n",
    "      ports:\n",
    "        - containerPort: 80\n",
    "```\n",
    "\n",
    "Questo YAML dice:\n",
    "\n",
    "* crea un pod chiamato `simple-pod`;\n",
    "* dentro il pod esegui un container basato sull‚Äôimmagine `nginx:latest`;\n",
    "* esponi la porta 80 all‚Äôinterno del cluster.\n",
    "\n",
    "Applica il file:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f pod.yaml\n",
    "```\n",
    "\n",
    "Verifica lo stato:\n",
    "\n",
    "```bash\n",
    "kubectl get pods\n",
    "kubectl describe pod simple-pod\n",
    "```\n",
    "\n",
    "Visualizza i log:\n",
    "\n",
    "```bash\n",
    "kubectl logs simple-pod\n",
    "```\n",
    "\n",
    "Elimina il pod:\n",
    "\n",
    "```bash\n",
    "kubectl delete pod simple-pod\n",
    "```\n",
    "\n",
    "Problema: se questo pod si blocca o viene eliminato, scompare.\n",
    "Non c‚Äô√® alcun meccanismo che lo ricrei.\n",
    "Per questo serve il **Deployment**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Il Deployment: gestione automatica dei pod\n",
    "\n",
    "Un **Deployment** √® un oggetto che gestisce uno o pi√π pod identici.\n",
    "Serve per mantenere attivo un certo numero di copie e aggiornare l‚Äôapplicazione senza interruzioni.\n",
    "\n",
    "Esempio di Deployment per un backend FastAPI:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend-deployment\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "```\n",
    "\n",
    "Spiegazione pratica:\n",
    "\n",
    "* `replicas: 3` indica che vogliamo tre pod attivi contemporaneamente;\n",
    "* `selector.matchLabels` e `template.metadata.labels` collegano il Deployment ai pod che crea;\n",
    "* nella sezione `containers` si definiscono i container come in un pod normale.\n",
    "\n",
    "Crea il Deployment:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f backend-deployment.yaml\n",
    "```\n",
    "\n",
    "Controlla cosa ha creato:\n",
    "\n",
    "```bash\n",
    "kubectl get deployments\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "Se uno dei pod si blocca, Kubernetes lo ricrea automaticamente.\n",
    "Se aggiorni l‚Äôimmagine nel file YAML e riesegui `kubectl apply`, Kubernetes effettua un **rolling update**: aggiorna i pod uno alla volta, senza downtime.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Il Service: collegare i pod in rete\n",
    "\n",
    "Ogni pod in Kubernetes ha un indirizzo IP, ma questo IP cambia ogni volta che il pod viene ricreato.\n",
    "Quindi non puoi fare affidamento sugli IP.\n",
    "Serve un **Service**, che √® un punto di accesso stabile.\n",
    "\n",
    "Esempio di Service per il backend:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 8080\n",
    "      targetPort: 8080\n",
    "  type: ClusterIP\n",
    "```\n",
    "\n",
    "Spiegazione:\n",
    "\n",
    "* `selector.app: backend` collega il Service ai pod che hanno l‚Äôetichetta `app=backend` (cio√® quelli del Deployment);\n",
    "* `port` √® la porta del Service (come viene visto dagli altri servizi);\n",
    "* `targetPort` √® la porta interna dei pod;\n",
    "* `type: ClusterIP` significa che il servizio √® accessibile solo all‚Äôinterno del cluster.\n",
    "\n",
    "Applica il file:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f backend-service.yaml\n",
    "```\n",
    "\n",
    "Verifica:\n",
    "\n",
    "```bash\n",
    "kubectl get services\n",
    "```\n",
    "\n",
    "Ora altri pod (ad esempio un frontend) possono comunicare con questo backend usando:\n",
    "\n",
    "```\n",
    "http://backend-service:8080\n",
    "```\n",
    "\n",
    "Non serve conoscere gli IP.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Esporre un servizio all‚Äôesterno\n",
    "\n",
    "Per poter accedere da fuori (dal tuo computer, browser o client API) devi usare `type: NodePort` o `LoadBalancer`.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-service\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 8080\n",
    "      nodePort: 30080\n",
    "```\n",
    "\n",
    "`nodePort: 30080` espone la porta 8080 dei pod sulla porta 30080 della macchina fisica del cluster.\n",
    "\n",
    "Avvia il servizio:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f backend-service.yaml\n",
    "```\n",
    "\n",
    "Controlla:\n",
    "\n",
    "```bash\n",
    "kubectl get services\n",
    "```\n",
    "\n",
    "Apri nel browser:\n",
    "\n",
    "```\n",
    "http://<ip-del-nodo>:30080\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Come collegare pi√π componenti (esempio AI semplice)\n",
    "\n",
    "Supponiamo di avere un backend FastAPI e un database Qdrant.\n",
    "\n",
    "### qdrant-deployment.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: qdrant\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: qdrant\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: qdrant\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: qdrant\n",
    "          image: qdrant/qdrant:v1.10.0\n",
    "          ports:\n",
    "            - containerPort: 6333\n",
    "```\n",
    "\n",
    "### qdrant-service.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: qdrant-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: qdrant\n",
    "  ports:\n",
    "    - port: 6333\n",
    "      targetPort: 6333\n",
    "  type: ClusterIP\n",
    "```\n",
    "\n",
    "### backend-deployment.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/crewai-backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "          env:\n",
    "            - name: QDRANT_HOST\n",
    "              value: qdrant-service\n",
    "            - name: QDRANT_PORT\n",
    "              value: \"6333\"\n",
    "```\n",
    "\n",
    "### backend-service.yaml\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: backend\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 8080\n",
    "  type: NodePort\n",
    "```\n",
    "\n",
    "Applica tutto:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f qdrant-deployment.yaml\n",
    "kubectl apply -f qdrant-service.yaml\n",
    "kubectl apply -f backend-deployment.yaml\n",
    "kubectl apply -f backend-service.yaml\n",
    "```\n",
    "\n",
    "Verifica:\n",
    "\n",
    "```bash\n",
    "kubectl get all\n",
    "```\n",
    "\n",
    "Il backend parler√† con Qdrant tramite il nome DNS interno `qdrant-service:6333`.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Comandi fondamentali per lavorare con YAML\n",
    "\n",
    "| Azione                           | Comando                                       |\n",
    "| -------------------------------- | --------------------------------------------- |\n",
    "| Creare o aggiornare risorse      | `kubectl apply -f file.yaml`                  |\n",
    "| Mostrare risorse attive          | `kubectl get all`                             |\n",
    "| Mostrare dettagli di una risorsa | `kubectl describe <tipo> <nome>`              |\n",
    "| Entrare in un container          | `kubectl exec -it <pod> -- bash`              |\n",
    "| Mostrare i log                   | `kubectl logs <pod>`                          |\n",
    "| Eliminare una risorsa            | `kubectl delete -f file.yaml`                 |\n",
    "| Testare senza applicare          | `kubectl apply --dry-run=client -f file.yaml` |\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Schema logico completo\n",
    "\n",
    "1. Scrivi un **Deployment** per ogni applicazione.\n",
    "2. Assegna **etichette (labels)** ai pod nel template.\n",
    "3. Crea un **Service** con un **selector** che punta alle stesse etichette.\n",
    "4. Usa `kubectl apply` per creare tutto.\n",
    "5. Controlla che i pod siano attivi con `kubectl get pods`.\n",
    "6. Se serve accesso esterno, usa `type: NodePort` o `LoadBalancer`.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. In sintesi\n",
    "\n",
    "* **Pod** ‚Üí √® un contenitore (uno o pi√π container) in esecuzione.\n",
    "* **Deployment** ‚Üí crea e mantiene un gruppo di pod uguali, li aggiorna e li ricrea se cadono.\n",
    "* **Service** ‚Üí fornisce un nome fisso per raggiungere i pod, anche se gli IP cambiano.\n",
    "* Tutto viene descritto in **file YAML** che dichiari lo stato desiderato.\n",
    "* Kubernetes si occupa di mantenerlo reale.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90eb61-a807-4a76-b7de-71d9eee6bd69",
   "metadata": {},
   "source": [
    "# Installazione\n",
    "\n",
    "## 1. Requisiti preliminari\n",
    "\n",
    "Prima di iniziare, assicurati che:\n",
    "\n",
    "* **Docker Desktop** sia gi√† installato e avviato (serve come driver per Minikube).\n",
    "  Verifica aprendo Docker Desktop: deve risultare ‚ÄúRunning‚Äù.\n",
    "* Stai usando **Windows 10 o 11 (64 bit)**.\n",
    "* Hai i **permessi da amministratore**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Scaricare Minikube dal sito ufficiale\n",
    "\n",
    "1. Vai sul sito ufficiale di Minikube:\n",
    "   **[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)**\n",
    "2. Scorri alla sezione **Windows**.\n",
    "3. Clicca sul link di download per l‚Äôeseguibile:\n",
    "   **[https://github.com/kubernetes/minikube/releases/latest](https://github.com/kubernetes/minikube/releases/latest)**\n",
    "4. Nella pagina GitHub, trova la sezione **Assets** e scarica il file:\n",
    "\n",
    "   ```\n",
    "   minikube-installer.exe\n",
    "   ```\n",
    "\n",
    "   (Non scaricare i file `.sha256` o `.asc` ‚Äì serve solo il `.exe`)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Installazione con `minikube-installer.exe`\n",
    "\n",
    "1. Dopo aver scaricato il file, **clicca due volte** su:\n",
    "\n",
    "   ```\n",
    "   minikube-installer.exe\n",
    "   ```\n",
    "\n",
    "2. Segui il processo guidato:\n",
    "\n",
    "   * accetta i termini di licenza;\n",
    "   * lascia il percorso predefinito (es. `C:\\Program Files (x86)\\Kubernetes\\Minikube`);\n",
    "   * assicurati che l‚Äôopzione per aggiungere Minikube al **PATH di sistema** sia selezionata;\n",
    "   * clicca su **Install**.\n",
    "\n",
    "3. Attendi il completamento (pochi secondi/minuti).\n",
    "\n",
    "4. Quando finisce, puoi gi√† aprire un **Prompt dei comandi** o **PowerShell** e digitare:\n",
    "\n",
    "   ```powershell\n",
    "   minikube version\n",
    "   ```\n",
    "\n",
    "   Se risponde con la versione (es. `minikube version: v1.33.0`), l‚Äôinstallazione √® andata a buon fine.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Verifica che `kubectl` sia incluso\n",
    "\n",
    "Il pacchetto installer `.exe` di Minikube include **kubectl**, quindi non serve installarlo a parte.\n",
    "\n",
    "Verifica con:\n",
    "\n",
    "```powershell\n",
    "kubectl version --client\n",
    "```\n",
    "\n",
    "Dovresti vedere qualcosa come:\n",
    "\n",
    "```\n",
    "Client Version: v1.30.0\n",
    "Kustomize Version: v5.0.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Avviare Minikube con Docker Desktop\n",
    "\n",
    "1. Assicurati che Docker Desktop sia **in esecuzione**.\n",
    "\n",
    "2. Apri **PowerShell** come amministratore.\n",
    "\n",
    "3. Avvia Minikube con Docker come driver:\n",
    "\n",
    "   ```powershell\n",
    "   minikube start --driver=docker\n",
    "   ```\n",
    "\n",
    "   Questo comando:\n",
    "\n",
    "   * crea un cluster Kubernetes locale;\n",
    "   * configura kubectl automaticamente;\n",
    "   * utilizza Docker Desktop come motore.\n",
    "\n",
    "4. Controlla lo stato:\n",
    "\n",
    "   ```powershell\n",
    "   minikube status\n",
    "   ```\n",
    "\n",
    "   Output atteso:\n",
    "\n",
    "   ```\n",
    "   host: Running\n",
    "   kubelet: Running\n",
    "   apiserver: Running\n",
    "   kubeconfig: Configured\n",
    "   ```\n",
    "\n",
    "5. Controlla i nodi del cluster:\n",
    "\n",
    "   ```powershell\n",
    "   kubectl get nodes\n",
    "   ```\n",
    "\n",
    "   Dovresti vedere:\n",
    "\n",
    "   ```\n",
    "   NAME       STATUS   ROLES           AGE   VERSION\n",
    "   minikube   Ready    control-plane   1m    v1.30.0\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. (Facoltativo) Aggiungere il supporto Ingress\n",
    "\n",
    "Se vuoi pubblicare servizi web tramite domini locali (`myapp.local`, ecc.):\n",
    "\n",
    "```powershell\n",
    "minikube addons enable ingress\n",
    "```\n",
    "\n",
    "Verifica:\n",
    "\n",
    "```powershell\n",
    "kubectl get pods -n ingress-nginx\n",
    "```\n",
    "\n",
    "Deve risultare in esecuzione un pod simile a `ingress-nginx-controller`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Avvio, stop e reset del cluster\n",
    "\n",
    "* **Avviare Minikube**:\n",
    "\n",
    "  ```powershell\n",
    "  minikube start --driver=docker\n",
    "  ```\n",
    "\n",
    "* **Fermarlo temporaneamente**:\n",
    "\n",
    "  ```powershell\n",
    "  minikube stop\n",
    "  ```\n",
    "\n",
    "* **Eliminare tutto (reset completo)**:\n",
    "\n",
    "  ```powershell\n",
    "  minikube delete\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Test rapido\n",
    "\n",
    "Proviamo un semplice pod:\n",
    "\n",
    "```powershell\n",
    "kubectl run test-nginx --image=nginx --port=80\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "Esporre il pod:\n",
    "\n",
    "```powershell\n",
    "kubectl expose pod test-nginx --type=NodePort --port=80\n",
    "kubectl get svc\n",
    "```\n",
    "\n",
    "Apri il servizio nel browser:\n",
    "\n",
    "```powershell\n",
    "minikube service test-nginx\n",
    "```\n",
    "\n",
    "Se si apre una pagina ‚ÄúWelcome to nginx‚Äù, il cluster √® funzionante.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Installare Kompose (conversione Docker Compose ‚Üí Kubernetes)\n",
    "\n",
    "Ora puoi installare Kompose, per convertire progetti Compose in Kubernetes.\n",
    "\n",
    "1. Vai su:\n",
    "   **[https://github.com/kubernetes/kompose/releases/latest](https://github.com/kubernetes/kompose/releases/latest)**\n",
    "\n",
    "2. Scarica:\n",
    "\n",
    "   ```\n",
    "   kompose-windows-amd64.exe\n",
    "   ```\n",
    "\n",
    "3. Rinominalo in:\n",
    "\n",
    "   ```\n",
    "   kompose.exe\n",
    "   ```\n",
    "\n",
    "4. Spostalo in una cartella presente nel tuo PATH, ad esempio:\n",
    "\n",
    "   ```\n",
    "   C:\\Program Files\\Kubernetes\\Minikube\\\n",
    "   ```\n",
    "\n",
    "   oppure aggiungi la cartella dove l‚Äôhai salvato al PATH di Windows (Pannello di controllo ‚Üí Sistema ‚Üí Variabili d‚Äôambiente).\n",
    "\n",
    "5. Verifica l‚Äôinstallazione:\n",
    "\n",
    "   ```powershell\n",
    "   kompose version\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Riassunto comandi chiave\n",
    "\n",
    "| Scopo                   | Comando                            |\n",
    "| ----------------------- | ---------------------------------- |\n",
    "| Avviare il cluster      | `minikube start --driver=docker`   |\n",
    "| Fermarlo                | `minikube stop`                    |\n",
    "| Eliminare tutto         | `minikube delete`                  |\n",
    "| Vedere lo stato         | `minikube status`                  |\n",
    "| Aprire la dashboard web | `minikube dashboard`               |\n",
    "| Mostrare i nodi         | `kubectl get nodes`                |\n",
    "| Mostrare i pod          | `kubectl get pods`                 |\n",
    "| Aprire un servizio web  | `minikube service <nome-servizio>` |\n",
    "\n",
    "---\n",
    "\n",
    "## 11. In sintesi\n",
    "\n",
    "Dopo l‚Äôinstallazione con `minikube-installer.exe`:\n",
    "\n",
    "* Kubernetes √® gi√† pronto e configurato (non serve installare `kubectl` separatamente).\n",
    "* Puoi usare Docker Desktop come driver.\n",
    "* Con Kompose puoi convertire i tuoi file `docker-compose.yml` in manifest Kubernetes con:\n",
    "\n",
    "  ```powershell\n",
    "  kompose convert -f .\\docker-compose.yml --service-nodeport\n",
    "  kubectl apply -f .\n",
    "  minikube service nome-servizio\n",
    "  ```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe982d-a485-4fc9-babe-94dc7cf3135f",
   "metadata": {},
   "source": [
    "# Da Kompose a K8s\n",
    "---\n",
    "\n",
    "## 1) Punto di partenza: `docker-compose.yml`\n",
    "\n",
    "Esempio minimale (backend FastAPI + Qdrant):\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:v1.10.0\n",
    "    ports: [\"6333:6333\"]\n",
    "    volumes:\n",
    "      - qdrant_data:/qdrant/storage\n",
    "\n",
    "  backend:\n",
    "    image: myorg/crewai-backend:latest\n",
    "    environment:\n",
    "      QDRANT_HOST: qdrant\n",
    "      QDRANT_PORT: \"6333\"\n",
    "    ports: [\"8080:8080\"]\n",
    "\n",
    "volumes:\n",
    "  qdrant_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Conversione con Kompose\n",
    "\n",
    "Se hai Windows + Minikube:\n",
    "\n",
    "```powershell\n",
    "# (facoltativo) fonde compose + override + .env in un solo file\n",
    "docker compose config > compose.merged.yml\n",
    "\n",
    "# conversione; --service-nodeport per esporre facilmente i servizi in Minikube\n",
    "kompose convert -f .\\compose.merged.yml --service-nodeport\n",
    "# oppure: kompose convert -f .\\docker-compose.yml --service-nodeport\n",
    "```\n",
    "\n",
    "**Cosa ottieni** nella cartella:\n",
    "\n",
    "```\n",
    "backend-deployment.yaml\n",
    "backend-service.yaml\n",
    "qdrant-deployment.yaml\n",
    "qdrant-service.yaml\n",
    "qdrant-data-persistentvolumeclaim.yaml   # se rileva il volume nominato\n",
    "```\n",
    "\n",
    "Kompose ha gi√† mappato:\n",
    "\n",
    "* `image`, `environment`, `ports` ‚Üí nei `Deployment`/`Service`\n",
    "* `volumes` ‚Üí in `PersistentVolumeClaim + volumeMounts`\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Scegli il numero di copie (repliche)\n",
    "\n",
    "Kompose crea di default **1 replica**.\n",
    "Per scalare, **modifica il Deployment** (o usa `kubectl scale`).\n",
    "\n",
    "Apri `backend-deployment.yaml` e imposta:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: backend\n",
    "spec:\n",
    "  replicas: 3                # <-- scegli tu quante copie\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      io.kompose.service: backend\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        io.kompose.service: backend\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: backend\n",
    "          image: myorg/crewai-backend:latest\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "          env:\n",
    "            - name: QDRANT_HOST\n",
    "              value: qdrant\n",
    "            - name: QDRANT_PORT\n",
    "              value: \"6333\"\n",
    "```\n",
    "\n",
    "Se vuoi, puoi anche cambiare il **tipo di Service** (es. `NodePort` o `LoadBalancer`) nel file `backend-service.yaml`.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Applica al cluster\n",
    "\n",
    "```powershell\n",
    "kubectl apply -f .\n",
    "kubectl get deploy,svc,pods,pvc\n",
    "```\n",
    "\n",
    "Apri il backend o la UI da Minikube:\n",
    "\n",
    "```powershell\n",
    "minikube service backend\n",
    "# (se hai generato anche la ui: minikube service ui)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Operazioni tipiche dopo la conversione\n",
    "\n",
    "### A) Scalare senza editare file\n",
    "\n",
    "```powershell\n",
    "kubectl scale deployment backend --replicas=5\n",
    "kubectl get deploy backend\n",
    "```\n",
    "\n",
    "### B) Aggiornare l‚Äôimmagine (rolling update)\n",
    "\n",
    "Modifica `image:` nel file `backend-deployment.yaml` **oppure**:\n",
    "\n",
    "```powershell\n",
    "kubectl set image deployment/backend backend=myorg/crewai-backend:1.1.0\n",
    "kubectl rollout status deployment/backend\n",
    "```\n",
    "\n",
    "### C) Aggiungere readiness/liveness probe (consigliato)\n",
    "\n",
    "Kompose non traduce `healthcheck` di Compose in probe K8s. Aggiungile tu:\n",
    "\n",
    "```yaml\n",
    "# dentro spec.template.spec.containers[0]\n",
    "readinessProbe:\n",
    "  httpGet:\n",
    "    path: /health\n",
    "    port: 8080\n",
    "  initialDelaySeconds: 5\n",
    "  periodSeconds: 10\n",
    "livenessProbe:\n",
    "  httpGet:\n",
    "    path: /health\n",
    "    port: 8080\n",
    "  initialDelaySeconds: 15\n",
    "  periodSeconds: 20\n",
    "```\n",
    "\n",
    "### D) Risorse minime (soprattutto su laptop)\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  requests:\n",
    "    cpu: \"250m\"\n",
    "    memory: \"256Mi\"\n",
    "  limits:\n",
    "    cpu: \"1\"\n",
    "    memory: \"1Gi\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Cosa ‚Äúautomatizza‚Äù davvero Kompose e cosa no\n",
    "\n",
    "* **S√¨**: genera automaticamente i manifest **Deployment**, **Service** e **PVC** a partire da `docker-compose.yml`.\n",
    "* **No**: non gestisce l‚Äôordine di avvio tipo `depends_on` (in Kubernetes si usano **readinessProbe**), non crea automaticamente **Ingress**, non aggiunge limiti risorse o probe avanzate. Queste parti le imposti tu dopo la conversione.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Sequenza riassuntiva\n",
    "\n",
    "```powershell\n",
    "# 1) (opzionale) fondi i compose con .env\n",
    "docker compose config > compose.merged.yml\n",
    "\n",
    "# 2) converti\n",
    "kompose convert -f .\\compose.merged.yml --service-nodeport\n",
    "\n",
    "# 3) opzionale: modifica replicas/resources/probe nei Deployment\n",
    "# 4) applica\n",
    "kubectl apply -f .\n",
    "\n",
    "# 5) verifica e apri\n",
    "kubectl get all\n",
    "minikube service backend\n",
    "\n",
    "# 6) scala o aggiorna\n",
    "kubectl scale deployment backend --replicas=5\n",
    "kubectl set image deployment/backend backend=myorg/crewai-backend:1.1.0\n",
    "```\n",
    "\n",
    "Questo √® il flusso tipico: **Kompose ti genera la base Kubernetes**, tu scegli **repliche** e aggiungi i dettagli operativi (probe, risorse, tipi di Service).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
